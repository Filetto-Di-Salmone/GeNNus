{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> GeNNus\n",
    "### <center> CNN on Waveforms\n",
    "\n",
    "This is the code for the step 3, the one in which we experimented with Convolutional Neural Networks on Waveforms.\n",
    "\n",
    "See project report and presentation for deeper thoughts about this stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "import torchaudio\n",
    "import torchaudio.transforms\n",
    "\n",
    "import torchvision\n",
    "\n",
    "\n",
    "import sys, os\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "from tqdm.autonotebook import tqdm\n",
    "\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import librosa\n",
    "import librosa.display\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import gc\n",
    "\n",
    "MANUAL_SEED = 69\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "from datetime import date\n",
    "from datetime import datetime\n",
    "\n",
    "import os.path\n",
    "from os import path\n",
    "  \n",
    "import json\n",
    "\n",
    "import time\n",
    "\n",
    "import copy\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "plt.rcParams['figure.dpi'] = 200\n",
    "plt.rcParams['savefig.dpi'] = 200\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import random\n",
    "\n",
    "from pprint import pformat\n",
    "\n",
    "import math\n",
    "import pathlib\n",
    "\n",
    "from torchaudio_augmentations import * \n",
    "\n",
    "import wandb\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enabling notebook extension jupyter-js-widgets/extension...\n",
      "      - Validating: \u001b[32mOK\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbextension enable --py widgetsnbextension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "NVIDIA GeForce RTX 2070\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(device)\n",
    "print(\n",
    "  torch.cuda.get_device_name(device) if torch.cuda.is_available() else \"cpu\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dir_if_absent(dir_path):\n",
    "  \n",
    "  if not os.path.exists(dir_path):\n",
    "    os.makedirs(dir_path)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ComposeTransform:\n",
    "    def __init__(self, transforms, p_boosting_factors, epoch_steps):\n",
    "        self.transforms = transforms\n",
    "        self.p_boosting_factors = p_boosting_factors \n",
    "        self.epoch_steps = epoch_steps\n",
    "\n",
    "        self.step_has_been_called_once = False\n",
    "\n",
    "    def step(self, epoch):\n",
    "\n",
    "        if self.epoch_steps is not None and epoch in self.epoch_steps:\n",
    "\n",
    "            if not self.step_has_been_called_once:\n",
    "                \n",
    "                self.pbar_step_desc = tqdm(\n",
    "                    total=0, position=4, bar_format='{desc}'\n",
    "                )\n",
    "\n",
    "                self.pbar_step_desc.set_description_str(\n",
    "                    f\"ComposeTransform.p = {-1}\"\n",
    "                )\n",
    "\n",
    "                self.step_has_been_called_once = True\n",
    "            \n",
    "            for t, i in zip(self.transforms, range(len(self.transforms))):\n",
    "                if \"RandomApply\" in t.__class__.__name__:\n",
    "\n",
    "                    try:\n",
    "                        t.p = self.p_boosting_factors[epoch]\n",
    "\n",
    "                        # if i == 0:\n",
    "                        self.pbar_step_desc.set_description_str(\n",
    "                            f\"ComposeTransform.p = {t.p}\"\n",
    "                        )\n",
    "                \n",
    "                        # print(self.epoch_steps[epoch], t.p)\n",
    "                    \n",
    "                    except Exception as e:\n",
    "\n",
    "                        # print(\"Caught the following exception, continuing to whatever comes next!\")\n",
    "                        # print(e)\n",
    "\n",
    "                        pass\n",
    "\n",
    "    def get_p_at_epoch(self, epoch):\n",
    "        try:\n",
    "            return self.p_boosting_factors[epoch]\n",
    "        except:\n",
    "            return -0.01\n",
    "\n",
    "    def __call__(self, audio_data):\n",
    "        for t in self.transforms:\n",
    "            audio_data = t(audio_data)\n",
    "        return audio_data\n",
    "    \n",
    "    def __repr__(self):\n",
    "        repr_list = []\n",
    "\n",
    "        for t in self.transforms:\n",
    "            repr_list.append(t.__repr__())\n",
    "\n",
    "        repr_list.append(\n",
    "            {\n",
    "                \"p_boosting_factors\": self.p_boosting_factors,\n",
    "                \"epoch_steps\": self.epoch_steps\n",
    "            }\n",
    "        )\n",
    "\n",
    "        return str(repr_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IdentityTransform:\n",
    "  def __init__(self):\n",
    "    pass\n",
    "\n",
    "  def __call__(self, audio_data):\n",
    "    return audio_data\n",
    "\n",
    "  def __repr__(self):\n",
    "    \n",
    "    return str( { \"transform_name\": \"IdentityTransform\" } )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StandardizeTransform:\n",
    "  def __init__(self, mean, std):\n",
    "    self.mean = mean\n",
    "    self.std = std\n",
    "\n",
    "  def __call__(self, audio_data):\n",
    "\n",
    "    return (audio_data - self.mean) / self.std\n",
    "\n",
    "  def __repr__(self):\n",
    "    \n",
    "    return str(\n",
    "      {\n",
    "        \"transform_name\": \"StandardizeTransform\",\n",
    "        \"mean\": self.mean,\n",
    "        \"std\": self.std \n",
    "      }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FMADataset(Dataset):\n",
    "\n",
    "  def __init__(\n",
    "    self, path, data_transforms_train, data_transforms_eval, data_type\n",
    "  ):\n",
    "    self.path = path\n",
    "    self.data_type = data_type,\n",
    "    self.stage = None\n",
    "    self.data_transforms_train = data_transforms_train\n",
    "    self.data_transforms_eval = data_transforms_eval\n",
    "    self.data_paths = self._load_audio_list()\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.data_paths)\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "\n",
    "    data = torch.load(self.data_paths[idx])\n",
    "\n",
    "    if self.stage == \"train\" and self.data_transforms_train is not None:\n",
    "      data = self.data_transforms_train(data)\n",
    "\n",
    "    if (\n",
    "      self.stage == \"val\" or self.stage == \"test\"\n",
    "    ) and self.data_transforms_eval is not None:\n",
    "      data = self.data_transforms_eval(data)\n",
    "\n",
    "    label_one_hot = self._label_from_str_to_one_hot(\n",
    "      self.data_paths[idx].split(\"/\")[-2]\n",
    "    )\n",
    "\n",
    "    return data, label_one_hot\n",
    "\n",
    "  \n",
    "  def _label_from_str_to_one_hot(self, label_str: str): \n",
    "  \n",
    "    if label_str == \"Pop\":\n",
    "      return torch.tensor([1, 0, 0, 0, 0, 0]).float()\n",
    "    \n",
    "    if label_str == \"Hip-Hop\":\n",
    "      return torch.tensor([0, 1, 0, 0, 0, 0]).float()\n",
    "    \n",
    "    if label_str == \"Electronic\":\n",
    "      return torch.tensor([0, 0, 1, 0, 0, 0]).float()\n",
    "    \n",
    "    if label_str == \"Rock\":\n",
    "      return torch.tensor([0, 0, 0, 1, 0, 0]).float()\n",
    "\n",
    "    if label_str == \"Folk\":\n",
    "      return torch.tensor([0, 0, 0, 0, 1, 0]).float()\n",
    "\n",
    "    if label_str == \"Jazz\":\n",
    "      return torch.tensor([0, 0, 0, 0, 0, 1]).float()\n",
    "    \n",
    "  \n",
    "  def _load_audio_list(self):\n",
    "    \n",
    "    audio_path_list = []\n",
    "    \n",
    "    for path, subdirs, files in os.walk(self.path):\n",
    "      for name in files:\n",
    "          \n",
    "        file_audio_path = os.path.join(path, name)\n",
    "        \n",
    "        audio_path_list.append(file_audio_path)\n",
    "\n",
    "    return sorted(audio_path_list, reverse=True)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_SIZE = \"s\"\n",
    "DATASET_TYPE = \"waveform\"\n",
    "DATASET_FOLDER = f\"./data/{DATASET_TYPE}\"\n",
    "\n",
    "DATASET_NUM_SAMPLES_PER_SECOND = 8000\n",
    "DATASET_NUM_CHANNELS = 1\n",
    "\n",
    "DATASET_NAME = f\"fma_{DATASET_SIZE}_resampled_{DATASET_NUM_SAMPLES_PER_SECOND}_rechanneled_{DATASET_NUM_CHANNELS}\"\n",
    "\n",
    "dataset_path = f\"{DATASET_FOLDER}/{DATASET_NAME}\"\n",
    "\n",
    "SUMMARY_STATISTICS_PATH = f\"./data/summary_statistics/{DATASET_NAME}/{DATASET_NAME}_summary_statistics.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_statistics_json = open(SUMMARY_STATISTICS_PATH)\n",
    "\n",
    "summary_statistics_dict = json.load(summary_statistics_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "identity_transform = IdentityTransform()\n",
    "\n",
    "standardize_transform = StandardizeTransform(\n",
    "  mean=summary_statistics_dict[f\"{DATASET_TYPE}_mean\"],\n",
    "  std=summary_statistics_dict[f\"{DATASET_TYPE}_std\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "90\n"
     ]
    }
   ],
   "source": [
    "COMPOSE_TRANSFORMS_P_BOOSTING_FACTORS = np.hstack(\n",
    "  (\n",
    "    np.linspace(0.0, 0.0, 90)\n",
    "  )\n",
    ").tolist()\n",
    "\n",
    "# COMPOSE_TRANSFORMS_P_BOOSTING_FACTORS = np.pad(\n",
    "#   p_concat, (15, 0), \"constant\"\n",
    "# ).tolist()\n",
    "\n",
    "\n",
    "# ascent = np.linspace(0.1, 0.25, 16)\n",
    "# descent = np.linspace(0.25, 0.15, 66)\n",
    "# middle = np.hstack((ascent, descent))\n",
    "# COMPOSE_TRANSFORMS_P_BOOSTING_FACTORS = np.pad(\n",
    "#   middle, (15,0), \"constant\", \n",
    "# ).tolist()\n",
    "\n",
    "# COMPOSE_TRANSFORMS_P_BOOSTING_FACTORS = None\n",
    "# COMPOSE_TRANSFORMS_P_BOOSTING_FACTORS = np.linspace(5, 10, 199)\n",
    "print(COMPOSE_TRANSFORMS_P_BOOSTING_FACTORS)\n",
    "\n",
    "print(len(COMPOSE_TRANSFORMS_P_BOOSTING_FACTORS) if COMPOSE_TRANSFORMS_P_BOOSTING_FACTORS is not None else \" \")\n",
    "\n",
    "COMPOSE_TRANSFORMS_EPOCH_STEPS = list(range(1, 900))\n",
    "# COMPOSE_TRANSFORMS_EPOCH_STEPS = None \n",
    "\n",
    "COMPOSE_TRANSFORMS_P = 0.00\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "fma_data_transforms_train = ComposeTransform(\n",
    "  transforms=[ \n",
    "    standardize_transform,\n",
    "\n",
    "    RandomApply([PolarityInversion()], p=COMPOSE_TRANSFORMS_P),\n",
    "    RandomApply([Noise(min_snr=0.001, max_snr=0.005)], p=COMPOSE_TRANSFORMS_P),\n",
    "    RandomApply([Gain()], p=COMPOSE_TRANSFORMS_P),  \n",
    "    # RandomResizedCrop(n_samples=2), # shape error :(\n",
    "    RandomApply([Delay(sample_rate=DATASET_NUM_SAMPLES_PER_SECOND)], p=COMPOSE_TRANSFORMS_P),\n",
    "    # RandomApply([PitchShift(\n",
    "    #   n_samples=5*DATASET_NUM_SAMPLES_PER_SECOND,\n",
    "    #   sample_rate=DATASET_NUM_SAMPLES_PER_SECOND\n",
    "    # )], p=0.2), # very very computationally expensive :(\n",
    "    # RandomApply([Reverb(sample_rate=DATASET_NUM_SAMPLES_PER_SECOND)], p=COMPOSE_TRANSFORMS_P) # very computationally expensive :(\n",
    "  ], \n",
    "  p_boosting_factors=COMPOSE_TRANSFORMS_P_BOOSTING_FACTORS, \n",
    "  epoch_steps=COMPOSE_TRANSFORMS_EPOCH_STEPS\n",
    ")\n",
    "\n",
    "fma_data_transforms_eval = ComposeTransform(\n",
    "  transforms=[standardize_transform],\n",
    "  p_boosting_factors=None, \n",
    "  epoch_steps=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "fma_dataset = FMADataset(\n",
    "  path=dataset_path, \n",
    "  data_transforms_train=fma_data_transforms_train,\n",
    "  data_transforms_eval=fma_data_transforms_eval,\n",
    "  data_type=DATASET_TYPE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_VAL_PERCENTAGE = 0.9\n",
    "\n",
    "full_size = len(fma_dataset)\n",
    "train_val_size = int(TRAIN_VAL_PERCENTAGE * full_size)\n",
    "test_size = full_size - train_val_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator=torch.Generator().manual_seed(MANUAL_SEED)\n",
    "\n",
    "fma_dataset_train_val, fma_dataset_test = torch.utils.data.random_split(\n",
    "  fma_dataset, [train_val_size, test_size], generator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PERCENTAGE = 0.8\n",
    "\n",
    "full_size = train_val_size\n",
    "train_size = int(TRAIN_PERCENTAGE * full_size)\n",
    "val_size = full_size - train_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "fma_dataset_train, fma_dataset_val = torch.utils.data.random_split(\n",
    "  fma_dataset_train_val, [train_size, val_size], generator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "NUM_WORKERS = 16\n",
    "\n",
    "data_logs = {\n",
    "  \"data_type\": DATASET_TYPE,\n",
    "  \"dataset_size\": DATASET_SIZE,\n",
    "  \"batch_size\": BATCH_SIZE,\n",
    "  \"num_samples_per_second\": DATASET_NUM_SAMPLES_PER_SECOND,\n",
    "  \"num_channels\": DATASET_NUM_CHANNELS,\n",
    "  \"data_transforms_train\": fma_data_transforms_train\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_num_trainable_parameters(model):\n",
    "  return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_train_id():\n",
    "  return datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_dict_to_disk(dict, full_path):\n",
    "\n",
    "  make_dir_if_absent(\"/\".join(full_path.split(\"/\")[:-1]))\n",
    "\n",
    "  with open(full_path, 'w') as fp:\n",
    "    json.dump(dict, fp)\n",
    "\n",
    "def load_dict_from_disk(full_path):\n",
    "  \n",
    "  with open(full_path) as json_file:\n",
    "    dict_from_disk = json.load(json_file)\n",
    "  \n",
    "  return dict_from_disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_ckp(\n",
    "  model, optimizer, ckp_dir, ckp_name, epoch, loss_train, loss_val, loss_test\n",
    "):\n",
    "\n",
    "  model_copy = copy.deepcopy(model)\n",
    "  \n",
    "  full_path_pickle = f\"{ckp_dir}/{ckp_name}_epoch_{epoch}.pth\"\n",
    "  \n",
    "  make_dir_if_absent(dir_path=\"/\".join(full_path_pickle.split('/')[:-1]))\n",
    "  \n",
    "  torch.save(\n",
    "    {\n",
    "      'epoch': epoch,\n",
    "      'model_state_dict': model_copy.cpu().state_dict(),\n",
    "      'optimizer_state_dict': optimizer.state_dict(),\n",
    "      'loss_train': loss_train,\n",
    "      'loss_val': loss_val,\n",
    "      'loss_test': loss_test,\n",
    "    }, \n",
    "    full_path_pickle\n",
    "  )\n",
    "  \n",
    "  torch.save(\n",
    "    model_copy.cpu(), \n",
    "    full_path_pickle\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_ckp(ckp_path, perform_loading_sanity_check):\n",
    "\n",
    "  loaded_model = torch.load(ckp_path)\n",
    "\n",
    "  if perform_loading_sanity_check:\n",
    "\n",
    "    loaded_model.eval()\n",
    "\n",
    "    sanity_check_out = loaded_model(torch.rand((16, 1, 238000)))\n",
    "\n",
    "  return loaded_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num_correct_preds(outputs, labels):\n",
    "  \n",
    "  output_pred_ind = torch.argmax(outputs, dim=1)\n",
    "  labels_ind = torch.argmax(labels, dim=1)\n",
    "  \n",
    "  matching_mask = (output_pred_ind == labels_ind).float()\n",
    "  \n",
    "  num_correct_preds = matching_mask.sum()\n",
    "  \n",
    "  return num_correct_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(\n",
    "  model, optimizer, criterion,\n",
    "  batch_size, train_dl, val_dl, test_dl, \n",
    "  num_epochs, \n",
    "  lr_scheduler,\n",
    "  device, \n",
    "  print_freq, ckp_freq, \n",
    "  ckp_dir, ckp_name,\n",
    "  should_close_tqdm_prog_bars_when_done,\n",
    "  limit_num_batches_train,\n",
    "  limit_num_batches_val,\n",
    "  limit_num_batches_test,\n",
    "):\n",
    "\n",
    "  train_id = gen_train_id()\n",
    "  \n",
    "  training_logs = {\n",
    "    \"train_id\": train_id,\n",
    "    \"accuracies\": {},\n",
    "    \"losses\": {}\n",
    "  }\n",
    "\n",
    "  model = model.to(device)\n",
    "\n",
    "  wandb.init(\n",
    "      project=\"GeNNus_CNN_waveform\", entity=\"filetto-di-salmone\"\n",
    "    )\n",
    "  wandb.watch(model)\n",
    "  \n",
    "  pbar_epochs = tqdm(range(num_epochs), colour=\"#9400d3\", position=1)\n",
    "  pbar_batches_train = tqdm(\n",
    "    iter(train_dl), colour=\"#4169e1\", leave=False, position=4\n",
    "  )\n",
    "  pbar_batches_val = tqdm(\n",
    "    iter(val_dl), colour=\"#008080\", leave=False, position=5\n",
    "  )\n",
    "  pbar_best_epoch_desc = tqdm(\n",
    "    total=0, position=2, bar_format='{desc}', colour=\"green\"\n",
    "  )\n",
    "  pbar_epoch_desc = tqdm(\n",
    "    total=0, position=3, bar_format='{desc}', colour=\"#9400d3\"\n",
    "  )\n",
    "  \n",
    "  training_start_time = time.time()\n",
    "\n",
    "  best_loss_val = np.Inf\n",
    "\n",
    "  for epoch in range(num_epochs):\n",
    "\n",
    "    running_loss_train = 0.0\n",
    "    running_loss_val   = 0.0\n",
    "    running_loss_test  = -1.0\n",
    "    \n",
    "    num_correct_preds_train = 0.0\n",
    "    num_preds_train = 0.0\n",
    "    accuracy_train = 0.0\n",
    "    \n",
    "    num_correct_preds_val = 0.0\n",
    "    num_preds_val = 0.0\n",
    "    accuracy_val = 0.0\n",
    "    \n",
    "    num_correct_preds_test = 0.0\n",
    "    num_preds_test = 0.000000001\n",
    "    accuracy_test = 0.0\n",
    "\n",
    "    num_batches_train = 0\n",
    "    num_batches_val = 0\n",
    "    num_batches_test = 0\n",
    "        \n",
    "    ## BEGIN training step\n",
    "    \n",
    "    model.train()\n",
    "\n",
    "    train_dl.dataset.dataset.stage=\"train\"\n",
    "    train_dl.dataset.dataset.data_transforms_train.step(epoch=epoch)\n",
    "    \n",
    "    pbar_batches_train.reset()\n",
    "    pbar_batches_val.reset()\n",
    "    \n",
    "    pbar_epochs.set_description(f\"epoch {epoch}\")\n",
    "    pbar_batches_train.set_description(f\"epoch {epoch}\")\n",
    "    pbar_batches_val.set_description  (f\"epoch {epoch}\")\n",
    "    \n",
    "    for batch_x, batch_y in iter(train_dl):\n",
    "\n",
    "      if num_batches_train <= limit_num_batches_train:\n",
    "\n",
    "        inputs, labels = batch_x, batch_y\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        outputs = outputs.squeeze(-1)\n",
    "        \n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss_train += loss.item() * batch_x.shape[0]\n",
    "        \n",
    "        num_correct_preds_train += get_num_correct_preds(outputs, labels)\n",
    "        num_preds_train += outputs.shape[0]\n",
    "      \n",
    "      num_batches_train += 1\n",
    "      \n",
    "      pbar_batches_train.update(1)\n",
    "      \n",
    "    \n",
    "    ## END training step\n",
    "    \n",
    "    ## BEGIN validation step\n",
    "    \n",
    "    with torch.no_grad():\n",
    "      \n",
    "      model.eval()\n",
    "\n",
    "      train_dl.dataset.dataset.stage=\"val\"\n",
    "      \n",
    "      for batch_x, batch_y in iter(val_dl):\n",
    "\n",
    "        if num_batches_val <= limit_num_batches_val:\n",
    "\n",
    "          inputs, labels = batch_x, batch_y\n",
    "          inputs, labels = inputs.to(device), labels.to(device)\n",
    "          \n",
    "          outputs = model(inputs)\n",
    "          outputs = outputs.squeeze(-1)\n",
    "          \n",
    "          loss = criterion(outputs, labels)\n",
    "          \n",
    "          running_loss_val += loss.item() * batch_x.shape[0]\n",
    "          \n",
    "          num_correct_preds_val += get_num_correct_preds(outputs, labels)\n",
    "          num_preds_val += outputs.shape[0]\n",
    "        \n",
    "        num_batches_val += 1\n",
    "\n",
    "        pbar_batches_val.update(1)\n",
    "        \n",
    "    ## END validation step\n",
    "\n",
    "    if lr_scheduler is not None:\n",
    "      if \"ReduceLROnPlateau\" in lr_scheduler.__class__.__name__:\n",
    "        lr_scheduler.step(running_loss_train) \n",
    "      else:\n",
    "        lr_scheduler.step()\n",
    "    \n",
    "    ## BEGIN test step\n",
    "    \n",
    "    if (epoch + 1 == num_epochs):\n",
    "      \n",
    "      pbar_batches_test = tqdm(\n",
    "        iter(test_dl), colour=\"#808000\", leave=False,\n",
    "      )\n",
    "      pbar_batches_test.set_description  (f\"epoch {epoch}\")\n",
    "    \n",
    "      with torch.no_grad():\n",
    "        \n",
    "        model.eval()\n",
    "\n",
    "        train_dl.dataset.dataset.stage=\"test\"\n",
    "        \n",
    "        for batch_x, batch_y in iter(test_dl):\n",
    "\n",
    "          if num_batches_test <= limit_num_batches_test:\n",
    "\n",
    "            inputs, labels = batch_x, batch_y\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            outputs = outputs.squeeze(-1)\n",
    "            \n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            running_loss_test += loss.item() * batch_x.shape[0]\n",
    "            \n",
    "            num_correct_preds_test += get_num_correct_preds(outputs, labels)\n",
    "            num_preds_test += outputs.shape[0]\n",
    "          \n",
    "          num_batches_test += 1\n",
    "          \n",
    "          pbar_batches_test.update(1)\n",
    "        \n",
    "    ## END test step\n",
    "    \n",
    "    accuracy_train = num_correct_preds_train / num_preds_train\n",
    "    accuracy_val = num_correct_preds_val / num_preds_val\n",
    "    accuracy_test = num_correct_preds_test / num_preds_test\n",
    "    \n",
    "    training_logs[\"accuracies\"][str(epoch)] = {\n",
    "      \"accuracy_train\": accuracy_train.cpu().item(),\n",
    "      \"accuracy_val\": accuracy_val.cpu().item(),\n",
    "    }\n",
    "    training_logs[\"losses\"][str(epoch)] = {\n",
    "      \"loss_train\": running_loss_train,\n",
    "      \"loss_val\": running_loss_val,\n",
    "    }\n",
    "\n",
    "    \n",
    "    # if ((epoch + 1) % print_freq == 0):\n",
    "    if running_loss_val < best_loss_val:  \n",
    "      pbar_best_epoch_desc.set_description_str(\n",
    "        f\"[best] epoch: {(str(epoch + 1)).zfill(3)}, \" + \n",
    "        f\"train loss: {str(round(running_loss_train, 2)).zfill(6)}, train acc: {str(round(accuracy_train.cpu().item(), 2))}, \" + \n",
    "        f\"val loss  : {str(round(running_loss_val, 2)).zfill(6)} , val acc  : {str(round(accuracy_val.cpu().item(), 2))}, \" + \n",
    "        f\"val loss delta change: {best_loss_val - running_loss_val}\"\n",
    "      )\n",
    "\n",
    "      best_loss_val = running_loss_val\n",
    "\n",
    "    pbar_epoch_desc.set_description_str(\n",
    "      f\"[curr] epoch: {(str(epoch + 1)).zfill(3)}, \" + \n",
    "      f\"train loss: {str(round(running_loss_train, 2)).zfill(6)}, train acc: {str(round(accuracy_train.cpu().item(), 2))}, \" + \n",
    "      f\"val loss  : {str(round(running_loss_val, 2)).zfill(6)} , val acc  : {str(round(accuracy_val.cpu().item(), 2))}\"\n",
    "      \n",
    "    )\n",
    "\n",
    "    pbar_epochs.update(1)\n",
    "\n",
    "    wandb.log(\n",
    "      {\n",
    "        \"epoch\": epoch, \n",
    "        \"loss/train\": round(running_loss_train, 2),\n",
    "        \"loss/val\": round(running_loss_val, 2),\n",
    "        \"acc/train\": round(accuracy_train.cpu().item(), 2),\n",
    "        \"acc/val\": round(accuracy_val.cpu().item(), 2),\n",
    "        \"transform_p\": train_dl.dataset.dataset.data_transforms_train.get_p_at_epoch(epoch)\n",
    "      }\n",
    "    )\n",
    "    \n",
    "    if ((epoch + 1) == num_epochs):\n",
    "      tqdm.write(\n",
    "        f\"epoch: {(str(epoch + 1)).zfill(3)}\\n\" + \n",
    "        f\"  train loss: {str(round(running_loss_train, 2)).zfill(6)}, train acc: {str(round(accuracy_train.cpu().item(), 2))}\\n\" + \n",
    "        f\"  val loss  : {str(round(running_loss_val, 2)).zfill(6)}, val acc  : {str(round(accuracy_val.cpu().item(), 2))}\\n\" + \n",
    "        f\"  test loss : {round(running_loss_test, 2)} , test acc: {round(accuracy_test.cpu().item(), 2)}\\n\"\n",
    "      )\n",
    "      \n",
    "      training_logs[\"accuracies\"][str(epoch)][\n",
    "        \"accuracy_test\"\n",
    "      ] = accuracy_test.cpu().item()\n",
    "      \n",
    "      training_logs[\"losses\"][str(epoch)][\n",
    "        \"loss_test\"\n",
    "      ] = running_loss_test\n",
    "      \n",
    "    if (ckp_freq != None and (epoch + 1) % ckp_freq == 0):\n",
    "      \n",
    "      store_ckp(\n",
    "        model=model, optimizer=optimizer, \n",
    "        ckp_dir=ckp_dir, ckp_name=ckp_name, epoch=epoch, \n",
    "        loss_train=running_loss_train, \n",
    "        loss_val=running_loss_val, \n",
    "        loss_test=running_loss_test\n",
    "      )\n",
    "  \n",
    "  training_end_time = time.time()\n",
    "\n",
    "  training_logs[\"training_time_secs\"] = training_end_time - training_start_time\n",
    "\n",
    "  if (should_close_tqdm_prog_bars_when_done):\n",
    "    pbar_epochs.container.close()\n",
    "    pbar_batches_train.close()\n",
    "    pbar_batches_val.close()\n",
    "    pbar_batches_test.close()\n",
    "  \n",
    "  return training_logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Design motivations\n",
    "\n",
    "First layers --> neural compression layers --> dimensionality reduction to roughly match dimensions of this paper https://arxiv.org/pdf/1703.01789.pdf\n",
    "\n",
    "Mid and final layers --> taken 1:1 from the paper linked above\n",
    "\n",
    "Batch norm placed BEFORE the activation function, as described in the og paper https://arxiv.org/abs/1502.03167 and explained by Bengio in his DL book https://www.deeplearningbook.org/contents/optimization.html in section 8.7.1\n",
    "\n",
    "Dropout placed according to the og paper: https://arxiv.org/pdf/1207.0580.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "  def __init__(\n",
    "    self, \n",
    "    num_layers, \n",
    "    kernel_sizes, strides, \n",
    "    in_channels, num_filters,\n",
    "    pool_sizes, pool_strides,\n",
    "    dropout_p_conv, dropout_p_linear,\n",
    "    conv_to_fc_in_features\n",
    "  ):\n",
    "    super().__init__()\n",
    "\n",
    "    self.num_layers = num_layers \n",
    "    self.kernel_sizes = kernel_sizes \n",
    "    self.strides = strides \n",
    "    self.in_channels = in_channels \n",
    "    self.num_filters = num_filters\n",
    "    self.pool_sizes = pool_sizes \n",
    "    self.pool_strides = pool_strides\n",
    "    \n",
    "    self.dropout_p_conv = dropout_p_conv\n",
    "    self.dropout_p_linear = dropout_p_linear\n",
    "\n",
    "    self.conv_to_fc_in_features = conv_to_fc_in_features\n",
    "    \n",
    "    self.conv_layers = nn.Sequential()\n",
    "    self.fc_layers = nn.Sequential()\n",
    "    \n",
    "    for i in range(num_layers):\n",
    "      \n",
    "      conv_layer = nn.Conv1d(\n",
    "        kernel_size=self.kernel_sizes[i],\n",
    "        stride=self.strides[i],\n",
    "        in_channels=in_channels,\n",
    "        out_channels=self.num_filters[i]\n",
    "      )\n",
    "      torch.nn.init.xavier_uniform_(conv_layer.weight)\n",
    "\n",
    "      \n",
    "      pooling_layer = nn.MaxPool1d(\n",
    "        kernel_size=self.pool_sizes[i],\n",
    "        stride=self.pool_strides[i],\n",
    "      )\n",
    "      \n",
    "      in_channels = self.num_filters[i]\n",
    "      \n",
    "      self.conv_layers.add_module(name=f\"conv_{i}\", module=conv_layer)\n",
    "      \n",
    "      self.conv_layers.add_module(name=f\"pool_{i}\", module=pooling_layer)\n",
    "        \n",
    "      self.conv_layers.add_module(\n",
    "        name=f\"batchnorm_{i}\", \n",
    "        module=nn.BatchNorm1d(num_features=self.num_filters[i])\n",
    "      )\n",
    "        \n",
    "      self.conv_layers.add_module(name=f\"activ_{i}\", module=nn.ReLU())\n",
    "\n",
    "      self.conv_layers.add_module(\n",
    "        name=f\"dropout_{i}\", module=nn.Dropout(p=self.dropout_p_conv)\n",
    "      )\n",
    "\n",
    "    fc_1 = nn.Linear(\n",
    "      in_features=self.conv_to_fc_in_features, out_features=6\n",
    "    )\n",
    "    torch.nn.init.xavier_uniform_(fc_1.weight)\n",
    "\n",
    "    self.fc_layers.add_module(name=\"fc_1_linear\", module=fc_1)\n",
    "\n",
    "    self.fc_layers.add_module(\n",
    "      name=\"fc_1_dropout\", module=nn.Dropout(p=self.dropout_p_linear)\n",
    "    )\n",
    "    \n",
    "    self.fc_layers.add_module(name=\"fc_1_activ\", module=nn.Softmax())\n",
    "  \n",
    "  def forward(self, x):    \n",
    "    x = self.conv_layers(x)\n",
    "\n",
    "    x = torch.flatten(x, 1)\n",
    "\n",
    "    x = self.fc_layers(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "  def get_model_setup(self):\n",
    "    \n",
    "    return {\n",
    "      \"num_layers\": self.num_layers, \n",
    "      \"kernel_sizes\": self.kernel_sizes, \n",
    "      \"strides\": self.strides, \n",
    "      \"in_channels\": self.in_channels, \n",
    "      \"num_filters\": self.num_filters,\n",
    "      \"pool_sizes\": self.pool_sizes, \n",
    "      \"pool_strides\": self.pool_strides,\n",
    "      \"dropout_p_conv\": self.dropout_p_conv,\n",
    "      \"dropout_p_linear\": self.dropout_p_linear,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss_curves(stats):\n",
    "  epochs = stats[\"training_logs\"][\"losses\"].keys()\n",
    "  \n",
    "  loss_train = [\n",
    "    j[\"loss_train\"] for j in stats[\"training_logs\"][\"losses\"].values()\n",
    "  ]\n",
    "  \n",
    "  loss_val = [j[\"loss_val\"] for j in stats[\"training_logs\"][\"losses\"].values()]\n",
    "\n",
    "  sns.lineplot(\n",
    "    x=epochs,\n",
    "    y=loss_train,\n",
    "    legend=\"full\",\n",
    "    label=\"train loss\"\n",
    "  )\n",
    "\n",
    "  sns.lineplot(\n",
    "    x=epochs,\n",
    "    y=loss_val,\n",
    "    legend=\"full\",\n",
    "    label=\"val loss\"\n",
    "  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-fold cross validation for hyperparameter search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_fold_cv_kernel_sizes = [   3,    3,   3,   3,   3]\n",
    "k_fold_cv_pool_sizes   = [   3,    3,   3,   3,   3]\n",
    "k_fold_cv_strides      = [   3,    3,   3,   2,   2]\n",
    "k_fold_cv_pool_strides = [   3,    3,   3,   2,   2]\n",
    "k_fold_cv_num_filters  = [  32,   64,  96, 128, 160]\n",
    "# k_fold_cv_num_filters  = [  24,   36,  54,  68,  88]\n",
    "\n",
    "k_fold_cv_num_layers = len(k_fold_cv_num_filters)\n",
    "\n",
    "k_fold_cv_conv_to_fc_in_features = 160 * 19\n",
    "\n",
    "k_fold_cv_in_channels   = 1 if DATASET_TYPE == \"waveform\" else 2\n",
    "\n",
    "K_FOLD_CV_DROPOUT_P_CONV = 0.0\n",
    "K_FOLD_CV_DROPOUT_P_LINEAR = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_factory(\n",
    "  num_layers,\n",
    "  kernel_sizes,\n",
    "  strides,\n",
    "  in_channels,\n",
    "  num_filters,\n",
    "  pool_sizes,\n",
    "  pool_strides,\n",
    "  dropout_p_conv, \n",
    "  dropout_p_linear,\n",
    "  conv_to_fc_in_features,\n",
    "):\n",
    "  return CNN(\n",
    "  num_layers=num_layers,\n",
    "  kernel_sizes=kernel_sizes, \n",
    "  strides=strides, \n",
    "  in_channels=in_channels, \n",
    "  num_filters=num_filters,\n",
    "  pool_sizes=pool_sizes,\n",
    "  pool_strides=pool_strides,\n",
    "  dropout_p_conv=dropout_p_conv,\n",
    "  dropout_p_linear=dropout_p_linear,\n",
    "  conv_to_fc_in_features=conv_to_fc_in_features\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = 0.002\n",
    "MOMENTUM = 0.9\n",
    "WEIGHT_DECAY = 1e-2\n",
    "OPTIMIZER_NAME = \"Adam\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimizer_factory(optimizer_name, model, lr, momentum, weight_decay):\n",
    "\n",
    "  if optimizer_name == \"SGD\":\n",
    "    optimizer = optim.SGD(\n",
    "      model.parameters(), \n",
    "      lr=lr, \n",
    "      momentum=momentum,\n",
    "      nesterov=True,\n",
    "      weight_decay=weight_decay\n",
    "    )\n",
    "\n",
    "    optimizer_config = {\n",
    "    \"lr\": lr, \n",
    "    \"momentum\": momentum, \n",
    "    \"weight_decay\": weight_decay,\n",
    "    \"nesterov\": True\n",
    "  }  \n",
    "\n",
    "  elif optimizer_name == \"Adam\":\n",
    "\n",
    "    optimizer = optim.Adam(\n",
    "      model.parameters(),\n",
    "      lr=lr,\n",
    "      weight_decay=weight_decay\n",
    "    )\n",
    "\n",
    "    optimizer_config = {\n",
    "    \"lr\": lr, \n",
    "    \"weight_decay\": weight_decay\n",
    "  }  \n",
    "    \n",
    "\n",
    "  return optimizer, optimizer_config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_lr_factory(optimizer, step_size, gamma, last_epoch, verbose):\n",
    "  return torch.optim.lr_scheduler.StepLR(\n",
    "    optimizer, step_size, gamma, last_epoch, verbose\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_lr_on_plateau_factory(\n",
    "  optimizer, mode='min', factor=0.1, patience=10, threshold=0.0001, \n",
    "  threshold_mode='rel', cooldown=0, min_lr=0, eps=1e-08, verbose=False\n",
    "):\n",
    "  return torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer=optimizer, mode=mode, factor=factor, patience=patience, \n",
    "    threshold=threshold, threshold_mode=threshold_mode, cooldown=cooldown, \n",
    "    min_lr=min_lr, eps=eps, verbose=verbose\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "K_FOLD_CV_NUM_FOLDS = 5\n",
    "K_FOLD_CV_LIMIT_NUM_FOLDS = 1\n",
    "\n",
    "K_FOLD_CV_BATCH_SIZE = 64\n",
    "K_FOLD_CV_LIMIT_NUM_BATCHES_PERCENTAGE_TRAIN = 0.2\n",
    "K_FOLD_CV_LIMIT_NUM_BATCHES_PERCENTAGE_VAL = K_FOLD_CV_LIMIT_NUM_BATCHES_PERCENTAGE_TRAIN * 0.9\n",
    "K_FOLD_CV_LIMIT_NUM_BATCHES_PERCENTAGE_TEST = K_FOLD_CV_LIMIT_NUM_BATCHES_PERCENTAGE_TRAIN * 0.5\n",
    "# K_FOLD_CV_LIMIT_NUM_BATCHES_PERCENTAGE_TRAIN = 1\n",
    "# K_FOLD_CV_LIMIT_NUM_BATCHES_PERCENTAGE_VAL = 1\n",
    "# K_FOLD_CV_LIMIT_NUM_BATCHES_PERCENTAGE_TEST = 1\n",
    "\n",
    "K_FOLD_CV_NUM_EPOCHS = 90\n",
    "# K_FOLD_CV_PRINT_FREQ = int(K_FOLD_CV_NUM_EPOCHS * 0.1)\n",
    "K_FOLD_CV_PRINT_FREQ = 1\n",
    "\n",
    "K_FOLD_CV_CKP_FREQ = int(K_FOLD_CV_NUM_EPOCHS * 0.1)\n",
    "\n",
    "K_FOLD_CV_LOGS_FOLDER = f\"./k_fold_cv/cnn/{DATASET_TYPE}\"\n",
    "\n",
    "K_FOLD_CV_CKP_FOLDER = K_FOLD_CV_LOGS_FOLDER\n",
    "\n",
    "K_FOLD_CV_SHOULD_CLOSE_TQDM_PROG_BARS_WHEN_DONE=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LR_SCHEDULER_TYPE = \"step\"\n",
    "# LR_SCHEDULER_TYPE = \"reduce_on_plateau\"\n",
    "LR_SCHEDULER_TYPE = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR_SCHEDULER_STEP_SIZE = 30\n",
    "LR_SCHEDULER_GAMMA = 0.02\n",
    "LR_SCHEDULER_LAST_EPOCH = -1\n",
    "LR_SCHEDULER_VERBOSE = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "REDUCE_LR_ON_PLATEAU_FACTOR = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_models = [\n",
    "\n",
    "  cnn_factory(\n",
    "    num_layers=k_fold_cv_num_layers,\n",
    "    kernel_sizes=k_fold_cv_kernel_sizes, \n",
    "    strides=k_fold_cv_strides, \n",
    "    in_channels=k_fold_cv_in_channels, \n",
    "    num_filters=k_fold_cv_num_filters,\n",
    "    pool_sizes=k_fold_cv_pool_sizes,\n",
    "    pool_strides=k_fold_cv_pool_strides,\n",
    "    dropout_p_conv=K_FOLD_CV_DROPOUT_P_CONV,\n",
    "    dropout_p_linear=K_FOLD_CV_DROPOUT_P_LINEAR,\n",
    "    conv_to_fc_in_features=k_fold_cv_conv_to_fc_in_features\n",
    "  ) for _ in range(0, K_FOLD_CV_NUM_FOLDS)\n",
    "\n",
    "]\n",
    "\n",
    "cv_criterions = [nn.CrossEntropyLoss() for _ in range(0, K_FOLD_CV_NUM_FOLDS)]\n",
    "\n",
    "cv_opts = [\n",
    "  optimizer_factory(\n",
    "    optimizer_name=OPTIMIZER_NAME,\n",
    "    model=cv_models[i],\n",
    "    lr=LR,\n",
    "    momentum=MOMENTUM,\n",
    "    weight_decay=WEIGHT_DECAY\n",
    "  ) for i in range(0, K_FOLD_CV_NUM_FOLDS)\n",
    "]\n",
    "\n",
    "cv_optimizers = [opt for opt, _ in cv_opts]\n",
    "cv_optimizers_configs = [opt_conf for _, opt_conf in cv_opts]\n",
    "\n",
    "cv_lr_schedulers = []\n",
    "if LR_SCHEDULER_TYPE is not None:\n",
    "  for i in range(0, len(cv_optimizers)):\n",
    "    \n",
    "    if LR_SCHEDULER_TYPE == \"step\":\n",
    "      lr_scheduler = step_lr_factory(\n",
    "        optimizer=cv_optimizers[i],\n",
    "        step_size=LR_SCHEDULER_STEP_SIZE,\n",
    "        gamma=LR_SCHEDULER_GAMMA,\n",
    "        last_epoch=LR_SCHEDULER_LAST_EPOCH,\n",
    "        verbose=LR_SCHEDULER_VERBOSE\n",
    "      )\n",
    "    \n",
    "    elif LR_SCHEDULER_TYPE == \"reduce_on_plateau\":\n",
    "      lr_scheduler = reduce_lr_on_plateau_factory(\n",
    "        optimizer=cv_optimizers[i],\n",
    "        factor=REDUCE_LR_ON_PLATEAU_FACTOR\n",
    "      )\n",
    "    \n",
    "    cv_lr_schedulers.append(lr_scheduler)\n",
    "\n",
    "cv_lr_schedulers_config = {\n",
    "  \"lr_scheduler_type\": LR_SCHEDULER_TYPE,\n",
    "  \"lr_scheduler_step_size\": LR_SCHEDULER_STEP_SIZE,\n",
    "  \"lr_scheduler_gamma\": LR_SCHEDULER_GAMMA,\n",
    "  \"lr_scheduler_last_epoch\": LR_SCHEDULER_LAST_EPOCH,\n",
    "}\n",
    "\n",
    "cv_train_dls = []\n",
    "cv_val_dls = []\n",
    "cv_test_dls = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_fold = KFold(n_splits=K_FOLD_CV_NUM_FOLDS, shuffle=True)\n",
    "\n",
    "cv_train_idxs = []\n",
    "\n",
    "for fold, (train_idxs, val_idxs) in enumerate(k_fold.split(fma_dataset_train_val)):\n",
    "\n",
    "  train_subsampler = torch.utils.data.SubsetRandomSampler(train_idxs)\n",
    "  val_subsampler = torch.utils.data.SubsetRandomSampler(val_idxs)\n",
    "\n",
    "  cv_train_dls.append(\n",
    "    torch.utils.data.DataLoader(\n",
    "      fma_dataset_train_val, batch_size=K_FOLD_CV_BATCH_SIZE, sampler=train_subsampler\n",
    "    )\n",
    "  )\n",
    "  cv_train_idxs.append(train_idxs)\n",
    "\n",
    "  cv_val_dls.append(\n",
    "    torch.utils.data.DataLoader(\n",
    "      fma_dataset_train_val, batch_size=K_FOLD_CV_BATCH_SIZE, sampler=val_subsampler\n",
    "    )\n",
    "  )\n",
    "\n",
    "  cv_test_dls.append(\n",
    "    torch.utils.data.DataLoader(\n",
    "      fma_dataset_test, batch_size=K_FOLD_CV_BATCH_SIZE\n",
    "    )\n",
    "  )\n",
    "\n",
    "k_fold_cv_limit_num_batches_train = int(\n",
    "  len(list(cv_train_dls[0])) * K_FOLD_CV_LIMIT_NUM_BATCHES_PERCENTAGE_TRAIN\n",
    ") + 1\n",
    "\n",
    "k_fold_cv_limit_num_batches_val = int(\n",
    "  len(list(cv_val_dls[0])) * K_FOLD_CV_LIMIT_NUM_BATCHES_PERCENTAGE_VAL\n",
    ") + 1\n",
    "\n",
    "k_fold_cv_limit_num_batches_test = int(\n",
    "  len(list(cv_test_dls[0])) * K_FOLD_CV_LIMIT_NUM_BATCHES_PERCENTAGE_TEST\n",
    ") + 1\n",
    "\n",
    "cv_data_logs = {\n",
    "  \"data_type\": DATASET_TYPE,\n",
    "  \"dataset_size\": DATASET_SIZE,\n",
    "  \"batch_size\": K_FOLD_CV_BATCH_SIZE,\n",
    "  \"num_samples_per_second\": DATASET_NUM_SAMPLES_PER_SECOND,\n",
    "  \"num_channels\": DATASET_NUM_CHANNELS,\n",
    "  \"train_transforms\": fma_data_transforms_train.__repr__()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_k_fold_cv(\n",
    "  cv_id,\n",
    "\n",
    "  cv_num_folds,\n",
    "  cv_models, cv_optimizers, cv_criterions,\n",
    "  batch_size, \n",
    "  cv_train_dls, cv_train_idxs, cv_val_dls, cv_test_dls, \n",
    "  cv_num_epochs, \n",
    "  cv_lr_schedulers,\n",
    "  cv_device, \n",
    "  cv_print_freq, cv_ckp_freq, \n",
    "  cv_ckp_dir,\n",
    "  cv_should_close_tqdm_prog_bars_when_done,\n",
    "  cv_limit_num_folds,\n",
    "  cv_limit_num_batches_train,\n",
    "  cv_limit_num_batches_val,\n",
    "  cv_limit_num_batches_test,\n",
    "\n",
    "):\n",
    "\n",
    "  cv_training_logs = {}\n",
    "\n",
    "  pbar_folds = tqdm(range(cv_num_folds), colour=\"#b22222\")\n",
    "\n",
    "  for fold in pbar_folds:\n",
    "    pbar_folds.set_description(f\"fold {fold}\")\n",
    "\n",
    "    cv_ckp_fold_dir = f\"{cv_ckp_dir}/fold_{fold}\"\n",
    "\n",
    "    if fold < cv_limit_num_folds:\n",
    "\n",
    "      wandb.config = {\n",
    "        \"k_folds_cv_num_folds\": K_FOLD_CV_NUM_FOLDS,\n",
    "        \"k_folds_cv_fold\": fold,\n",
    "        \"data_logs\": cv_data_logs,\n",
    "        \"optimizer_config\": cv_optimizers_configs[0], # all the same, one is enough\n",
    "        \"model_setup\": cv_models[fold].get_model_setup(), # all the same, one is enough\n",
    "        \"lr_scheduler_configr\": cv_lr_schedulers_config\n",
    "      }\n",
    "\n",
    "      \n",
    "\n",
    "      training_log = train_model(\n",
    "        model=cv_models[fold], \n",
    "        optimizer=cv_optimizers[fold], criterion=cv_criterions[fold],\n",
    "        batch_size=batch_size,\n",
    "        train_dl=cv_train_dls[fold], val_dl=cv_val_dls[fold], test_dl=cv_test_dls[fold],\n",
    "        num_epochs=cv_num_epochs, \n",
    "        lr_scheduler=cv_lr_schedulers[fold] if len(cv_lr_schedulers) > 0 else None,\n",
    "        device=cv_device,\n",
    "        print_freq=cv_print_freq, ckp_freq=cv_ckp_freq, \n",
    "        ckp_dir=cv_ckp_fold_dir, ckp_name=f\"{cv_id}_fold_{fold}\",\n",
    "        should_close_tqdm_prog_bars_when_done=cv_should_close_tqdm_prog_bars_when_done,\n",
    "        limit_num_batches_train=cv_limit_num_batches_train,\n",
    "        limit_num_batches_val=cv_limit_num_batches_val,\n",
    "        limit_num_batches_test=cv_limit_num_batches_test,\n",
    "      )\n",
    "\n",
    "    cv_training_logs[str(fold)] = training_log\n",
    "\n",
    "    pbar_folds.update(1)\n",
    "\n",
    "  return cv_training_logs\n",
    "  \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_k_fold_cv_curves(\n",
    "  k_fold_cv_stats, curve_name_singular, curve_name_plural, plot_title, \n",
    "  limit_to_n_folds=None\n",
    "):\n",
    "  \n",
    "  num_folds = len(list(k_fold_cv_stats[\"training_logs\"].keys()))\n",
    "  num_folds_og = num_folds\n",
    "  \n",
    "  if limit_to_n_folds is not None and limit_to_n_folds <= num_folds:\n",
    "    num_folds = limit_to_n_folds\n",
    "  \n",
    "\n",
    "  for fold in range(0, num_folds):\n",
    "\n",
    "    fold_str = str(fold)\n",
    "\n",
    "    losses_dict = k_fold_cv_stats[\"training_logs\"][fold_str][curve_name_plural]\n",
    "\n",
    "    epochs = losses_dict.keys()\n",
    "    \n",
    "    curve_train = [ j[f\"{curve_name_singular}_train\"] for j in losses_dict.values() ]\n",
    "\n",
    "    curve_val = [ j[f\"{curve_name_singular}_val\"] for j in losses_dict.values() ]\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    sns.lineplot(\n",
    "      x=epochs,\n",
    "      y=curve_train,\n",
    "      legend=\"full\",\n",
    "      label=f\"train {curve_name_singular}\", \n",
    "      ax=ax\n",
    "    )\n",
    "\n",
    "    sns.lineplot(\n",
    "      x=epochs,\n",
    "      y=curve_val,\n",
    "      legend=\"full\",\n",
    "      label=f\"val {curve_name_singular}\", \n",
    "      ax=ax\n",
    "    )\n",
    "\n",
    "    fig.suptitle(plot_title)\n",
    "    ax.set_title(f\"{num_folds_og}-fold CV, fold {fold + 1}\")\n",
    "    \n",
    "    epochs_as_list = list(epochs)\n",
    "    PERCENTAGE_X_AXIS_TICKS = 0.2\n",
    "    epoch_axis_display = epochs_as_list[\n",
    "      ::int(len(epochs_as_list) * PERCENTAGE_X_AXIS_TICKS)\n",
    "    ]\n",
    "    ax.set_xticklabels(epoch_axis_display)\n",
    "    ax.set_xticks(epoch_axis_display)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_avg_fold_cv_curves(\n",
    "  k_fold_cv_stats, curve_name_singular, curve_name_plural, plot_title\n",
    "):\n",
    "  \n",
    "  num_folds = len(list(k_fold_cv_stats[\"training_logs\"].keys()))\n",
    "\n",
    "  curves_train = []\n",
    "  curves_val = []\n",
    "\n",
    "  for fold in range(0, num_folds):\n",
    "\n",
    "    fold_str = str(fold)\n",
    "\n",
    "    losses_dict = k_fold_cv_stats[\"training_logs\"][fold_str][curve_name_plural]\n",
    "\n",
    "    epochs = losses_dict.keys()\n",
    "    \n",
    "    curves_train.append(\n",
    "      [ j[f\"{curve_name_singular}_train\"] for j in losses_dict.values() ]\n",
    "    )\n",
    "\n",
    "    curves_val.append(\n",
    "      [ j[f\"{curve_name_singular}_val\"] for j in losses_dict.values() ]\n",
    "    )\n",
    "  \n",
    "  curves_train_np = np.asarray(curves_train)\n",
    "  curves_val_np = np.asarray(curves_val)\n",
    "\n",
    "  curve_train = np.average(curves_train_np, axis=0)\n",
    "  curve_val = np.average(curves_val_np, axis=0)\n",
    "\n",
    "  fig, ax = plt.subplots()\n",
    "\n",
    "  sns.lineplot(\n",
    "    x=epochs,\n",
    "    y=curve_train,\n",
    "    legend=\"full\",\n",
    "    label=f\"train {curve_name_singular}\", \n",
    "    ax=ax\n",
    "  )\n",
    "\n",
    "  sns.lineplot(\n",
    "    x=epochs,\n",
    "    y=curve_val,\n",
    "    legend=\"full\",\n",
    "    label=f\"val {curve_name_singular}\", \n",
    "    ax=ax\n",
    "  )\n",
    "\n",
    "  fig.suptitle(plot_title)\n",
    "  \n",
    "  epochs_as_list = list(epochs)\n",
    "  PERCENTAGE_X_AXIS_TICKS = 0.2\n",
    "  epoch_axis_display = epochs_as_list[\n",
    "    ::int(len(epochs_as_list) * PERCENTAGE_X_AXIS_TICKS)\n",
    "  ]\n",
    "  ax.set_xticklabels(epoch_axis_display)\n",
    "  ax.set_xticks(epoch_axis_display)\n",
    "\n",
    "  fig, ax =plt.subplots(2, 1)\n",
    "  sns.lineplot(\n",
    "    x=epochs,y=curve_train,legend=\"full\",\n",
    "    label=f\"train {curve_name_singular}\", ax=ax[0]\n",
    "  )\n",
    "  sns.lineplot(\n",
    "    x=epochs,y=curve_val,legend=\"full\",\n",
    "    label=f\"val {curve_name_singular}\", ax=ax[1], color=\"orange\"\n",
    "  )\n",
    "\n",
    "  ax[0].set_xticklabels(epoch_axis_display)\n",
    "  ax[1].set_xticklabels(epoch_axis_display)\n",
    "  ax[0].set_xticks(epoch_axis_display)\n",
    "  ax[1].set_xticks(epoch_axis_display)\n",
    "  fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "K_FOLD_CV_RUN = True\n",
    "\n",
    "K_FOLD_CV_PRINT_LOSS_CURVES_ACROSS_FOLDS = False\n",
    "K_FOLD_CV_PRINT_ACC_CURVES_ACROSS_FOLDS  = False\n",
    "\n",
    "K_FOLD_CV_PRINT_LOSS_CURVES_AVG_FOLDS = False\n",
    "K_FOLD_CV_PRINT_ACC_CURVES_AVG_FOLDS  = False\n",
    "\n",
    "K_FOLD_CV_PLOTS_LIMIT_TO_N_FOLDS = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tot num trainable params: 349146\n",
      "k_fold_cv_limit_num_batches_train: 7\n",
      "k_fold_cv_limit_num_batches_val: 2\n",
      "k_fold_cv_limit_num_batches_test: 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4eaf2a26cfe411297051d901ad33e59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:247cxs7f) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7650a87e61e9442ab984edbaa95fe1b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.003 MB of 0.003 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">grateful-cloud-192</strong>: <a href=\"https://wandb.ai/filetto-di-salmone/GeNNus_CNN_waveform/runs/247cxs7f\" target=\"_blank\">https://wandb.ai/filetto-di-salmone/GeNNus_CNN_waveform/runs/247cxs7f</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20221216_080523-247cxs7f/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:247cxs7f). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82b761e925574221965fe3d2883f9357",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016668143249989952, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/dansolombrino/GitHub/FDS/GeNNus/wandb/run-20221216_081030-19xihx15</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/filetto-di-salmone/GeNNus_CNN_waveform/runs/19xihx15\" target=\"_blank\">lucky-frog-193</a></strong> to <a href=\"https://wandb.ai/filetto-di-salmone/GeNNus_CNN_waveform\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3fa5164bdb94824aab2cd94f048083a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/90 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06cb67746b18419cb9b736a29a43c332",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55f241e4292e48708887a4809ee93f76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "929cf345b01541229e9a161911e200cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6711c829c004fd290df3d4f2c3aa9a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 930.00 MiB (GPU 0; 7.79 GiB total capacity; 4.73 GiB already allocated; 670.94 MiB free; 4.80 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/dansolombrino/GitHub/FDS/GeNNus/GeNNus_CNN_waveform.ipynb Cell 48\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/dansolombrino/GitHub/FDS/GeNNus/GeNNus_CNN_waveform.ipynb#X65sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mprint\u001b[39m(\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/dansolombrino/GitHub/FDS/GeNNus/GeNNus_CNN_waveform.ipynb#X65sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m   \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mTot num trainable params: \u001b[39m\u001b[39m{\u001b[39;00mcount_num_trainable_parameters(cv_models[\u001b[39m0\u001b[39m])\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/dansolombrino/GitHub/FDS/GeNNus/GeNNus_CNN_waveform.ipynb#X65sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m )\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/dansolombrino/GitHub/FDS/GeNNus/GeNNus_CNN_waveform.ipynb#X65sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mprint\u001b[39m(\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dansolombrino/GitHub/FDS/GeNNus/GeNNus_CNN_waveform.ipynb#X65sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m   \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mk_fold_cv_limit_num_batches_train: \u001b[39m\u001b[39m{\u001b[39;00mk_fold_cv_limit_num_batches_train\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dansolombrino/GitHub/FDS/GeNNus/GeNNus_CNN_waveform.ipynb#X65sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m   \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mk_fold_cv_limit_num_batches_val: \u001b[39m\u001b[39m{\u001b[39;00mk_fold_cv_limit_num_batches_val\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dansolombrino/GitHub/FDS/GeNNus/GeNNus_CNN_waveform.ipynb#X65sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m   \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mk_fold_cv_limit_num_batches_test: \u001b[39m\u001b[39m{\u001b[39;00mk_fold_cv_limit_num_batches_test\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dansolombrino/GitHub/FDS/GeNNus/GeNNus_CNN_waveform.ipynb#X65sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m )\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/dansolombrino/GitHub/FDS/GeNNus/GeNNus_CNN_waveform.ipynb#X65sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m k_fold_cv_training_logs \u001b[39m=\u001b[39m perform_k_fold_cv(\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dansolombrino/GitHub/FDS/GeNNus/GeNNus_CNN_waveform.ipynb#X65sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m   cv_id\u001b[39m=\u001b[39;49mk_fold_cv_id,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dansolombrino/GitHub/FDS/GeNNus/GeNNus_CNN_waveform.ipynb#X65sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m   cv_num_folds\u001b[39m=\u001b[39;49mK_FOLD_CV_NUM_FOLDS,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dansolombrino/GitHub/FDS/GeNNus/GeNNus_CNN_waveform.ipynb#X65sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m   cv_models\u001b[39m=\u001b[39;49mcv_models, cv_optimizers\u001b[39m=\u001b[39;49mcv_optimizers, cv_criterions\u001b[39m=\u001b[39;49mcv_criterions,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dansolombrino/GitHub/FDS/GeNNus/GeNNus_CNN_waveform.ipynb#X65sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m   batch_size\u001b[39m=\u001b[39;49mK_FOLD_CV_BATCH_SIZE, \n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dansolombrino/GitHub/FDS/GeNNus/GeNNus_CNN_waveform.ipynb#X65sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m   cv_train_dls\u001b[39m=\u001b[39;49mcv_train_dls, cv_train_idxs\u001b[39m=\u001b[39;49mcv_train_idxs, \n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dansolombrino/GitHub/FDS/GeNNus/GeNNus_CNN_waveform.ipynb#X65sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m   cv_val_dls\u001b[39m=\u001b[39;49mcv_val_dls, cv_test_dls\u001b[39m=\u001b[39;49mcv_test_dls,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dansolombrino/GitHub/FDS/GeNNus/GeNNus_CNN_waveform.ipynb#X65sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m   cv_num_epochs\u001b[39m=\u001b[39;49mK_FOLD_CV_NUM_EPOCHS, \n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dansolombrino/GitHub/FDS/GeNNus/GeNNus_CNN_waveform.ipynb#X65sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m   cv_lr_schedulers\u001b[39m=\u001b[39;49mcv_lr_schedulers,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dansolombrino/GitHub/FDS/GeNNus/GeNNus_CNN_waveform.ipynb#X65sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m   cv_device\u001b[39m=\u001b[39;49mdevice, \n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dansolombrino/GitHub/FDS/GeNNus/GeNNus_CNN_waveform.ipynb#X65sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m   cv_print_freq\u001b[39m=\u001b[39;49mK_FOLD_CV_PRINT_FREQ, cv_ckp_freq\u001b[39m=\u001b[39;49mK_FOLD_CV_CKP_FREQ, \n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dansolombrino/GitHub/FDS/GeNNus/GeNNus_CNN_waveform.ipynb#X65sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m   cv_ckp_dir\u001b[39m=\u001b[39;49m\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m{\u001b[39;49;00mK_FOLD_CV_CKP_FOLDER\u001b[39m}\u001b[39;49;00m\u001b[39m/\u001b[39;49m\u001b[39m{\u001b[39;49;00mk_fold_cv_id\u001b[39m}\u001b[39;49;00m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dansolombrino/GitHub/FDS/GeNNus/GeNNus_CNN_waveform.ipynb#X65sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m   cv_should_close_tqdm_prog_bars_when_done\u001b[39m=\u001b[39;49mK_FOLD_CV_SHOULD_CLOSE_TQDM_PROG_BARS_WHEN_DONE,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dansolombrino/GitHub/FDS/GeNNus/GeNNus_CNN_waveform.ipynb#X65sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m   cv_limit_num_folds\u001b[39m=\u001b[39;49mK_FOLD_CV_LIMIT_NUM_FOLDS,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dansolombrino/GitHub/FDS/GeNNus/GeNNus_CNN_waveform.ipynb#X65sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m   cv_limit_num_batches_train\u001b[39m=\u001b[39;49mk_fold_cv_limit_num_batches_train,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dansolombrino/GitHub/FDS/GeNNus/GeNNus_CNN_waveform.ipynb#X65sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m   cv_limit_num_batches_val\u001b[39m=\u001b[39;49mk_fold_cv_limit_num_batches_val,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dansolombrino/GitHub/FDS/GeNNus/GeNNus_CNN_waveform.ipynb#X65sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m   cv_limit_num_batches_test\u001b[39m=\u001b[39;49mk_fold_cv_limit_num_batches_test\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dansolombrino/GitHub/FDS/GeNNus/GeNNus_CNN_waveform.ipynb#X65sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dansolombrino/GitHub/FDS/GeNNus/GeNNus_CNN_waveform.ipynb#X65sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m k_fold_cv_stats \u001b[39m=\u001b[39m {\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dansolombrino/GitHub/FDS/GeNNus/GeNNus_CNN_waveform.ipynb#X65sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m   \u001b[39m\"\u001b[39m\u001b[39mk_fold_cv_id\u001b[39m\u001b[39m\"\u001b[39m: k_fold_cv_id,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dansolombrino/GitHub/FDS/GeNNus/GeNNus_CNN_waveform.ipynb#X65sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m   \u001b[39m\"\u001b[39m\u001b[39mstats_type\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mk_fold_cross_validation\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dansolombrino/GitHub/FDS/GeNNus/GeNNus_CNN_waveform.ipynb#X65sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m   \u001b[39m\"\u001b[39m\u001b[39mlr_scheduler_configr\u001b[39m\u001b[39m\"\u001b[39m: cv_lr_schedulers_config\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dansolombrino/GitHub/FDS/GeNNus/GeNNus_CNN_waveform.ipynb#X65sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m }\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dansolombrino/GitHub/FDS/GeNNus/GeNNus_CNN_waveform.ipynb#X65sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m save_dict_to_disk(\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dansolombrino/GitHub/FDS/GeNNus/GeNNus_CNN_waveform.ipynb#X65sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m   \u001b[39mdict\u001b[39m\u001b[39m=\u001b[39mk_fold_cv_stats,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dansolombrino/GitHub/FDS/GeNNus/GeNNus_CNN_waveform.ipynb#X65sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m   full_path\u001b[39m=\u001b[39m\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mK_FOLD_CV_LOGS_FOLDER\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mk_fold_cv_id\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mk_fold_cv_id\u001b[39m}\u001b[39;00m\u001b[39m_stats.json\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dansolombrino/GitHub/FDS/GeNNus/GeNNus_CNN_waveform.ipynb#X65sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m )\n",
      "\u001b[1;32m/home/dansolombrino/GitHub/FDS/GeNNus/GeNNus_CNN_waveform.ipynb Cell 48\u001b[0m in \u001b[0;36mperform_k_fold_cv\u001b[0;34m(cv_id, cv_num_folds, cv_models, cv_optimizers, cv_criterions, batch_size, cv_train_dls, cv_train_idxs, cv_val_dls, cv_test_dls, cv_num_epochs, cv_lr_schedulers, cv_device, cv_print_freq, cv_ckp_freq, cv_ckp_dir, cv_should_close_tqdm_prog_bars_when_done, cv_limit_num_folds, cv_limit_num_batches_train, cv_limit_num_batches_val, cv_limit_num_batches_test)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dansolombrino/GitHub/FDS/GeNNus/GeNNus_CNN_waveform.ipynb#X65sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m \u001b[39mif\u001b[39;00m fold \u001b[39m<\u001b[39m cv_limit_num_folds:\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dansolombrino/GitHub/FDS/GeNNus/GeNNus_CNN_waveform.ipynb#X65sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m   wandb\u001b[39m.\u001b[39mconfig \u001b[39m=\u001b[39m {\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dansolombrino/GitHub/FDS/GeNNus/GeNNus_CNN_waveform.ipynb#X65sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mk_folds_cv_num_folds\u001b[39m\u001b[39m\"\u001b[39m: K_FOLD_CV_NUM_FOLDS,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dansolombrino/GitHub/FDS/GeNNus/GeNNus_CNN_waveform.ipynb#X65sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mk_folds_cv_fold\u001b[39m\u001b[39m\"\u001b[39m: fold,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dansolombrino/GitHub/FDS/GeNNus/GeNNus_CNN_waveform.ipynb#X65sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mlr_scheduler_configr\u001b[39m\u001b[39m\"\u001b[39m: cv_lr_schedulers_config\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dansolombrino/GitHub/FDS/GeNNus/GeNNus_CNN_waveform.ipynb#X65sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m   }\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/dansolombrino/GitHub/FDS/GeNNus/GeNNus_CNN_waveform.ipynb#X65sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m   training_log \u001b[39m=\u001b[39m train_model(\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dansolombrino/GitHub/FDS/GeNNus/GeNNus_CNN_waveform.ipynb#X65sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m     model\u001b[39m=\u001b[39;49mcv_models[fold], \n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dansolombrino/GitHub/FDS/GeNNus/GeNNus_CNN_waveform.ipynb#X65sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m     optimizer\u001b[39m=\u001b[39;49mcv_optimizers[fold], criterion\u001b[39m=\u001b[39;49mcv_criterions[fold],\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dansolombrino/GitHub/FDS/GeNNus/GeNNus_CNN_waveform.ipynb#X65sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m     batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dansolombrino/GitHub/FDS/GeNNus/GeNNus_CNN_waveform.ipynb#X65sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m     train_dl\u001b[39m=\u001b[39;49mcv_train_dls[fold], val_dl\u001b[39m=\u001b[39;49mcv_val_dls[fold], test_dl\u001b[39m=\u001b[39;49mcv_test_dls[fold],\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dansolombrino/GitHub/FDS/GeNNus/GeNNus_CNN_waveform.ipynb#X65sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m     num_epochs\u001b[39m=\u001b[39;49mcv_num_epochs, \n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dansolombrino/GitHub/FDS/GeNNus/GeNNus_CNN_waveform.ipynb#X65sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m     lr_scheduler\u001b[39m=\u001b[39;49mcv_lr_schedulers[fold] \u001b[39mif\u001b[39;49;00m \u001b[39mlen\u001b[39;49m(cv_lr_schedulers) \u001b[39m>\u001b[39;49m \u001b[39m0\u001b[39;49m \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dansolombrino/GitHub/FDS/GeNNus/GeNNus_CNN_waveform.ipynb#X65sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m     device\u001b[39m=\u001b[39;49mcv_device,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dansolombrino/GitHub/FDS/GeNNus/GeNNus_CNN_waveform.ipynb#X65sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m     print_freq\u001b[39m=\u001b[39;49mcv_print_freq, ckp_freq\u001b[39m=\u001b[39;49mcv_ckp_freq, \n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dansolombrino/GitHub/FDS/GeNNus/GeNNus_CNN_waveform.ipynb#X65sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m     ckp_dir\u001b[39m=\u001b[39;49mcv_ckp_fold_dir, ckp_name\u001b[39m=\u001b[39;49m\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m{\u001b[39;49;00mcv_id\u001b[39m}\u001b[39;49;00m\u001b[39m_fold_\u001b[39;49m\u001b[39m{\u001b[39;49;00mfold\u001b[39m}\u001b[39;49;00m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dansolombrino/GitHub/FDS/GeNNus/GeNNus_CNN_waveform.ipynb#X65sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m     should_close_tqdm_prog_bars_when_done\u001b[39m=\u001b[39;49mcv_should_close_tqdm_prog_bars_when_done,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dansolombrino/GitHub/FDS/GeNNus/GeNNus_CNN_waveform.ipynb#X65sZmlsZQ%3D%3D?line=53'>54</a>\u001b[0m     limit_num_batches_train\u001b[39m=\u001b[39;49mcv_limit_num_batches_train,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dansolombrino/GitHub/FDS/GeNNus/GeNNus_CNN_waveform.ipynb#X65sZmlsZQ%3D%3D?line=54'>55</a>\u001b[0m     limit_num_batches_val\u001b[39m=\u001b[39;49mcv_limit_num_batches_val,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dansolombrino/GitHub/FDS/GeNNus/GeNNus_CNN_waveform.ipynb#X65sZmlsZQ%3D%3D?line=55'>56</a>\u001b[0m     limit_num_batches_test\u001b[39m=\u001b[39;49mcv_limit_num_batches_test,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dansolombrino/GitHub/FDS/GeNNus/GeNNus_CNN_waveform.ipynb#X65sZmlsZQ%3D%3D?line=56'>57</a>\u001b[0m   )\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dansolombrino/GitHub/FDS/GeNNus/GeNNus_CNN_waveform.ipynb#X65sZmlsZQ%3D%3D?line=58'>59</a>\u001b[0m cv_training_logs[\u001b[39mstr\u001b[39m(fold)] \u001b[39m=\u001b[39m training_log\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dansolombrino/GitHub/FDS/GeNNus/GeNNus_CNN_waveform.ipynb#X65sZmlsZQ%3D%3D?line=60'>61</a>\u001b[0m pbar_folds\u001b[39m.\u001b[39mupdate(\u001b[39m1\u001b[39m)\n",
      "\u001b[1;32m/home/dansolombrino/GitHub/FDS/GeNNus/GeNNus_CNN_waveform.ipynb Cell 48\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, optimizer, criterion, batch_size, train_dl, val_dl, test_dl, num_epochs, lr_scheduler, device, print_freq, ckp_freq, ckp_dir, ckp_name, should_close_tqdm_prog_bars_when_done, limit_num_batches_train, limit_num_batches_val, limit_num_batches_test)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dansolombrino/GitHub/FDS/GeNNus/GeNNus_CNN_waveform.ipynb#X65sZmlsZQ%3D%3D?line=88'>89</a>\u001b[0m inputs, labels \u001b[39m=\u001b[39m inputs\u001b[39m.\u001b[39mto(device), labels\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dansolombrino/GitHub/FDS/GeNNus/GeNNus_CNN_waveform.ipynb#X65sZmlsZQ%3D%3D?line=90'>91</a>\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/dansolombrino/GitHub/FDS/GeNNus/GeNNus_CNN_waveform.ipynb#X65sZmlsZQ%3D%3D?line=92'>93</a>\u001b[0m outputs \u001b[39m=\u001b[39m model(inputs)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dansolombrino/GitHub/FDS/GeNNus/GeNNus_CNN_waveform.ipynb#X65sZmlsZQ%3D%3D?line=93'>94</a>\u001b[0m outputs \u001b[39m=\u001b[39m outputs\u001b[39m.\u001b[39msqueeze(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dansolombrino/GitHub/FDS/GeNNus/GeNNus_CNN_waveform.ipynb#X65sZmlsZQ%3D%3D?line=95'>96</a>\u001b[0m loss \u001b[39m=\u001b[39m criterion(outputs, labels)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32m/home/dansolombrino/GitHub/FDS/GeNNus/GeNNus_CNN_waveform.ipynb Cell 48\u001b[0m in \u001b[0;36mCNN.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dansolombrino/GitHub/FDS/GeNNus/GeNNus_CNN_waveform.ipynb#X65sZmlsZQ%3D%3D?line=74'>75</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):    \n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/dansolombrino/GitHub/FDS/GeNNus/GeNNus_CNN_waveform.ipynb#X65sZmlsZQ%3D%3D?line=75'>76</a>\u001b[0m   x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv_layers(x)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dansolombrino/GitHub/FDS/GeNNus/GeNNus_CNN_waveform.ipynb#X65sZmlsZQ%3D%3D?line=77'>78</a>\u001b[0m   x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mflatten(x, \u001b[39m1\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dansolombrino/GitHub/FDS/GeNNus/GeNNus_CNN_waveform.ipynb#X65sZmlsZQ%3D%3D?line=79'>80</a>\u001b[0m   x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc_layers(x)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/container.py:139\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    138\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 139\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    140\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py:307\u001b[0m, in \u001b[0;36mConv1d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    306\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 307\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py:303\u001b[0m, in \u001b[0;36mConv1d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    299\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    300\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv1d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[1;32m    301\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[1;32m    302\u001b[0m                     _single(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[0;32m--> 303\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv1d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[1;32m    304\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 930.00 MiB (GPU 0; 7.79 GiB total capacity; 4.73 GiB already allocated; 670.94 MiB free; 4.80 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "if K_FOLD_CV_RUN:\n",
    "\n",
    "  k_fold_cv_id = gen_train_id()\n",
    "\n",
    "  print(\n",
    "    f\"Tot num trainable params: {count_num_trainable_parameters(cv_models[0])}\"\n",
    "  )\n",
    "\n",
    "  print(\n",
    "    f\"k_fold_cv_limit_num_batches_train: {k_fold_cv_limit_num_batches_train}\\n\"\n",
    "    f\"k_fold_cv_limit_num_batches_val: {k_fold_cv_limit_num_batches_val}\\n\"\n",
    "    f\"k_fold_cv_limit_num_batches_test: {k_fold_cv_limit_num_batches_test}\"\n",
    "  )\n",
    "\n",
    "  k_fold_cv_training_logs = perform_k_fold_cv(\n",
    "    cv_id=k_fold_cv_id,\n",
    "    cv_num_folds=K_FOLD_CV_NUM_FOLDS,\n",
    "    cv_models=cv_models, cv_optimizers=cv_optimizers, cv_criterions=cv_criterions,\n",
    "    batch_size=K_FOLD_CV_BATCH_SIZE, \n",
    "    cv_train_dls=cv_train_dls, cv_train_idxs=cv_train_idxs, \n",
    "    cv_val_dls=cv_val_dls, cv_test_dls=cv_test_dls,\n",
    "    cv_num_epochs=K_FOLD_CV_NUM_EPOCHS, \n",
    "    cv_lr_schedulers=cv_lr_schedulers,\n",
    "    cv_device=device, \n",
    "    cv_print_freq=K_FOLD_CV_PRINT_FREQ, cv_ckp_freq=K_FOLD_CV_CKP_FREQ, \n",
    "    cv_ckp_dir=f\"{K_FOLD_CV_CKP_FOLDER}/{k_fold_cv_id}\",\n",
    "    cv_should_close_tqdm_prog_bars_when_done=K_FOLD_CV_SHOULD_CLOSE_TQDM_PROG_BARS_WHEN_DONE,\n",
    "    cv_limit_num_folds=K_FOLD_CV_LIMIT_NUM_FOLDS,\n",
    "    cv_limit_num_batches_train=k_fold_cv_limit_num_batches_train,\n",
    "    cv_limit_num_batches_val=k_fold_cv_limit_num_batches_val,\n",
    "    cv_limit_num_batches_test=k_fold_cv_limit_num_batches_test\n",
    "  )\n",
    "\n",
    "  k_fold_cv_stats = {\n",
    "    \"k_fold_cv_id\": k_fold_cv_id,\n",
    "    \"stats_type\": \"k_fold_cross_validation\",\n",
    "    \"k_folds_cv_num_folds\": K_FOLD_CV_NUM_FOLDS,\n",
    "    \"data_logs\": cv_data_logs,\n",
    "    \"optimizer_config\": cv_optimizers_configs[0], # all the same, one is enough\n",
    "    \"model_setup\": cv_models[0].get_model_setup(), # all the same, one is enough\n",
    "    \"training_logs\": k_fold_cv_training_logs,\n",
    "    \"lr_scheduler_configr\": cv_lr_schedulers_config\n",
    "  }\n",
    "\n",
    "  save_dict_to_disk(\n",
    "    dict=k_fold_cv_stats,\n",
    "    full_path=f\"{K_FOLD_CV_LOGS_FOLDER}/{k_fold_cv_id}/{k_fold_cv_id}_stats.json\"\n",
    "  )\n",
    "\n",
    "  if K_FOLD_CV_PRINT_LOSS_CURVES_ACROSS_FOLDS:\n",
    "    print_k_fold_cv_curves(\n",
    "      k_fold_cv_stats=k_fold_cv_stats, \n",
    "      curve_name_plural=\"losses\", curve_name_singular=\"loss\",\n",
    "      plot_title=f\"Loss curves\", \n",
    "      limit_to_n_folds=K_FOLD_CV_PLOTS_LIMIT_TO_N_FOLDS\n",
    "    )\n",
    "  \n",
    "  if K_FOLD_CV_PRINT_ACC_CURVES_ACROSS_FOLDS:\n",
    "    print_k_fold_cv_curves(\n",
    "      k_fold_cv_stats=k_fold_cv_stats, \n",
    "      curve_name_plural=\"accuracies\", curve_name_singular=\"accuracy\",\n",
    "      plot_title=f\"Accuracy curves\", \n",
    "      limit_to_n_folds=K_FOLD_CV_PLOTS_LIMIT_TO_N_FOLDS\n",
    "    )\n",
    "  if K_FOLD_CV_PRINT_LOSS_CURVES_AVG_FOLDS:\n",
    "    print_avg_fold_cv_curves(\n",
    "      k_fold_cv_stats=k_fold_cv_stats, \n",
    "      curve_name_singular=\"loss\", curve_name_plural=\"losses\", \n",
    "      plot_title=f\"Loss curves\\naverage across {K_FOLD_CV_NUM_FOLDS} folds\"\n",
    "    )\n",
    "  if K_FOLD_CV_PRINT_ACC_CURVES_AVG_FOLDS:  \n",
    "    print_avg_fold_cv_curves(\n",
    "      k_fold_cv_stats=k_fold_cv_stats, \n",
    "      curve_name_singular=\"accuracy\", curve_name_plural=\"accuracies\", \n",
    "      plot_title=f\"Accuracy curves\\naverage across {K_FOLD_CV_NUM_FOLDS} folds\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not K_FOLD_CV_RUN:\n",
    "\n",
    "  k_fold_cv_id = \"2022_12_12_00_38_23\"\n",
    "  \n",
    "  k_fold_cv_stats_from_disk = load_dict_from_disk(\n",
    "    full_path=f\"{K_FOLD_CV_LOGS_FOLDER}/{k_fold_cv_id}/{k_fold_cv_id}_stats.json\"\n",
    "  )\n",
    "\n",
    "  k_fold_cv_num_folds = k_fold_cv_stats_from_disk[\"k_folds_cv_num_folds\"]\n",
    "\n",
    "  if K_FOLD_CV_PRINT_LOSS_CURVES_ACROSS_FOLDS:\n",
    "    print_k_fold_cv_curves(\n",
    "      k_fold_cv_stats=k_fold_cv_stats_from_disk, \n",
    "      curve_name_plural=\"losses\", curve_name_singular=\"loss\",\n",
    "      plot_title=f\"Loss curves\", \n",
    "      limit_to_n_folds=K_FOLD_CV_PLOTS_LIMIT_TO_N_FOLDS\n",
    "    )\n",
    "  \n",
    "  if K_FOLD_CV_PRINT_ACC_CURVES_ACROSS_FOLDS:\n",
    "    print_k_fold_cv_curves(\n",
    "      k_fold_cv_stats=k_fold_cv_stats_from_disk, \n",
    "      curve_name_plural=\"accuracies\", curve_name_singular=\"accuracy\",\n",
    "      plot_title=f\"Accuracy curves\", \n",
    "      limit_to_n_folds=K_FOLD_CV_PLOTS_LIMIT_TO_N_FOLDS\n",
    "    )\n",
    "  if K_FOLD_CV_PRINT_LOSS_CURVES_AVG_FOLDS:\n",
    "    print_avg_fold_cv_curves(\n",
    "      k_fold_cv_stats=k_fold_cv_stats_from_disk, \n",
    "      curve_name_singular=\"loss\", curve_name_plural=\"losses\", \n",
    "      plot_title=f\"Loss curves\\naverage across {k_fold_cv_num_folds} folds\"\n",
    "    )\n",
    "  if K_FOLD_CV_PRINT_ACC_CURVES_AVG_FOLDS:  \n",
    "    print_avg_fold_cv_curves(\n",
    "      k_fold_cv_stats=k_fold_cv_stats_from_disk, \n",
    "      curve_name_singular=\"accuracy\", curve_name_plural=\"accuracies\", \n",
    "      plot_title=f\"Accuracy curves\\naverage across {k_fold_cv_num_folds} folds\"\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4 (main, Apr  2 2022, 09:04:19) [GCC 11.2.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
