{"k_fold_cv_id": "2022_12_15_14_21_39", "stats_type": "k_fold_cross_validation", "k_folds_cv_num_folds": 5, "data_logs": {"data_type": "waveform", "dataset_size": "s", "batch_size": 64, "num_samples_per_second": 8000, "num_channels": 1, "train_transforms": "[\"{'transform_name': 'StandardizeTransform', 'mean': -7.975741027621552e-05, 'std': 0.2950393557548523}\", 'RandomApply(\\n    p=0.0\\n    PolarityInversion()\\n)', 'RandomApply(\\n    p=0.0\\n    Noise()\\n)', 'RandomApply(\\n    p=0.0\\n    Gain()\\n)', 'RandomApply(\\n    p=0.0\\n    Delay()\\n)', {'p_boosting_factors': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'epoch_steps': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89]}]"}, "optimizer_config": {"lr": 0.01, "momentum": 0.9, "weight_decay": 1e-05, "nesterov": true}, "model_setup": {"num_layers": 5, "kernel_sizes": [3, 3, 3, 3, 3], "strides": [3, 3, 3, 2, 2], "in_channels": 1, "num_filters": [48, 64, 128, 256, 512], "pool_sizes": [3, 3, 3, 3, 3], "pool_strides": [3, 3, 3, 2, 2], "dropout_p_conv": 0.0, "dropout_p_linear": 0.0}, "training_logs": {"0": {"train_id": "2022_12_15_14_21_39", "accuracies": {"0": {"accuracy_train": 0.224609375, "accuracy_val": 0.171875}, "1": {"accuracy_train": 0.3125, "accuracy_val": 0.15625}, "2": {"accuracy_train": 0.32421875, "accuracy_val": 0.1458333432674408}, "3": {"accuracy_train": 0.306640625, "accuracy_val": 0.2083333432674408}, "4": {"accuracy_train": 0.3515625, "accuracy_val": 0.2135416716337204}, "5": {"accuracy_train": 0.36328125, "accuracy_val": 0.2604166865348816}, "6": {"accuracy_train": 0.365234375, "accuracy_val": 0.2552083432674408}, "7": {"accuracy_train": 0.388671875, "accuracy_val": 0.2864583432674408}, "8": {"accuracy_train": 0.37109375, "accuracy_val": 0.234375}, "9": {"accuracy_train": 0.392578125, "accuracy_val": 0.2708333432674408}, "10": {"accuracy_train": 0.326171875, "accuracy_val": 0.28125}, "11": {"accuracy_train": 0.333984375, "accuracy_val": 0.25}, "12": {"accuracy_train": 0.318359375, "accuracy_val": 0.2916666865348816}, "13": {"accuracy_train": 0.29296875, "accuracy_val": 0.3177083432674408}, "14": {"accuracy_train": 0.3359375, "accuracy_val": 0.3072916865348816}, "15": {"accuracy_train": 0.3359375, "accuracy_val": 0.3489583432674408}, "16": {"accuracy_train": 0.333984375, "accuracy_val": 0.296875}, "17": {"accuracy_train": 0.3359375, "accuracy_val": 0.3177083432674408}, "18": {"accuracy_train": 0.35546875, "accuracy_val": 0.28125}, "19": {"accuracy_train": 0.34375, "accuracy_val": 0.265625}, "20": {"accuracy_train": 0.44921875, "accuracy_val": 0.34375}, "21": {"accuracy_train": 0.51171875, "accuracy_val": 0.2604166865348816}, "22": {"accuracy_train": 0.46875, "accuracy_val": 0.328125}, "23": {"accuracy_train": 0.501953125, "accuracy_val": 0.3072916865348816}, "24": {"accuracy_train": 0.5078125, "accuracy_val": 0.375}, "25": {"accuracy_train": 0.560546875, "accuracy_val": 0.390625}, "26": {"accuracy_train": 0.556640625, "accuracy_val": 0.3333333432674408}, "27": {"accuracy_train": 0.603515625, "accuracy_val": 0.4010416865348816}, "28": {"accuracy_train": 0.599609375, "accuracy_val": 0.3072916865348816}, "29": {"accuracy_train": 0.623046875, "accuracy_val": 0.3541666865348816}, "30": {"accuracy_train": 0.416015625, "accuracy_val": 0.328125}, "31": {"accuracy_train": 0.4375, "accuracy_val": 0.3541666865348816}, "32": {"accuracy_train": 0.435546875, "accuracy_val": 0.3020833432674408}, "33": {"accuracy_train": 0.3828125, "accuracy_val": 0.3125}, "34": {"accuracy_train": 0.443359375, "accuracy_val": 0.3645833432674408}, "35": {"accuracy_train": 0.453125, "accuracy_val": 0.2708333432674408}, "36": {"accuracy_train": 0.44921875, "accuracy_val": 0.3697916865348816}, "37": {"accuracy_train": 0.44140625, "accuracy_val": 0.3125}, "38": {"accuracy_train": 0.439453125, "accuracy_val": 0.2916666865348816}, "39": {"accuracy_train": 0.486328125, "accuracy_val": 0.2760416865348816}, "40": {"accuracy_train": 0.58984375, "accuracy_val": 0.3125}, "41": {"accuracy_train": 0.64453125, "accuracy_val": 0.359375}, "42": {"accuracy_train": 0.6796875, "accuracy_val": 0.390625}, "43": {"accuracy_train": 0.701171875, "accuracy_val": 0.3802083432674408}, "44": {"accuracy_train": 0.685546875, "accuracy_val": 0.328125}, "45": {"accuracy_train": 0.66796875, "accuracy_val": 0.3958333432674408}, "46": {"accuracy_train": 0.701171875, "accuracy_val": 0.3541666865348816}, "47": {"accuracy_train": 0.73046875, "accuracy_val": 0.328125}, "48": {"accuracy_train": 0.71875, "accuracy_val": 0.3697916865348816}, "49": {"accuracy_train": 0.75, "accuracy_val": 0.3645833432674408}, "50": {"accuracy_train": 0.49609375, "accuracy_val": 0.2864583432674408}, "51": {"accuracy_train": 0.541015625, "accuracy_val": 0.3385416865348816}, "52": {"accuracy_train": 0.5078125, "accuracy_val": 0.3020833432674408}, "53": {"accuracy_train": 0.505859375, "accuracy_val": 0.2916666865348816}, "54": {"accuracy_train": 0.541015625, "accuracy_val": 0.296875}, "55": {"accuracy_train": 0.51171875, "accuracy_val": 0.3177083432674408}, "56": {"accuracy_train": 0.5234375, "accuracy_val": 0.2916666865348816}, "57": {"accuracy_train": 0.533203125, "accuracy_val": 0.34375}, "58": {"accuracy_train": 0.484375, "accuracy_val": 0.3177083432674408}, "59": {"accuracy_train": 0.5390625, "accuracy_val": 0.2760416865348816}, "60": {"accuracy_train": 0.7109375, "accuracy_val": 0.2604166865348816}, "61": {"accuracy_train": 0.73828125, "accuracy_val": 0.3177083432674408}, "62": {"accuracy_train": 0.7890625, "accuracy_val": 0.2760416865348816}, "63": {"accuracy_train": 0.783203125, "accuracy_val": 0.34375}, "64": {"accuracy_train": 0.796875, "accuracy_val": 0.3802083432674408}, "65": {"accuracy_train": 0.791015625, "accuracy_val": 0.328125}, "66": {"accuracy_train": 0.79296875, "accuracy_val": 0.4114583432674408}, "67": {"accuracy_train": 0.82421875, "accuracy_val": 0.3541666865348816}, "68": {"accuracy_train": 0.82421875, "accuracy_val": 0.3489583432674408}, "69": {"accuracy_train": 0.849609375, "accuracy_val": 0.3802083432674408}, "70": {"accuracy_train": 0.607421875, "accuracy_val": 0.3802083432674408}, "71": {"accuracy_train": 0.5703125, "accuracy_val": 0.3489583432674408}, "72": {"accuracy_train": 0.595703125, "accuracy_val": 0.28125}, "73": {"accuracy_train": 0.599609375, "accuracy_val": 0.3385416865348816}, "74": {"accuracy_train": 0.564453125, "accuracy_val": 0.3020833432674408}, "75": {"accuracy_train": 0.603515625, "accuracy_val": 0.3020833432674408}, "76": {"accuracy_train": 0.552734375, "accuracy_val": 0.28125}, "77": {"accuracy_train": 0.6015625, "accuracy_val": 0.3385416865348816}, "78": {"accuracy_train": 0.564453125, "accuracy_val": 0.3072916865348816}, "79": {"accuracy_train": 0.623046875, "accuracy_val": 0.3333333432674408}, "80": {"accuracy_train": 0.818359375, "accuracy_val": 0.3645833432674408}, "81": {"accuracy_train": 0.826171875, "accuracy_val": 0.3333333432674408}, "82": {"accuracy_train": 0.861328125, "accuracy_val": 0.3125}, "83": {"accuracy_train": 0.8671875, "accuracy_val": 0.390625}, "84": {"accuracy_train": 0.892578125, "accuracy_val": 0.3854166865348816}, "85": {"accuracy_train": 0.875, "accuracy_val": 0.4427083432674408}, "86": {"accuracy_train": 0.89453125, "accuracy_val": 0.3697916865348816}, "87": {"accuracy_train": 0.91796875, "accuracy_val": 0.40625}, "88": {"accuracy_train": 0.88671875, "accuracy_val": 0.3541666865348816}, "89": {"accuracy_train": 0.88671875, "accuracy_val": 0.3697916865348816, "accuracy_test": 0.34375}}, "losses": {"0": {"loss_train": 904.2518310546875, "loss_val": 343.9059295654297}, "1": {"loss_train": 884.4242172241211, "loss_val": 344.3298034667969}, "2": {"loss_train": 875.9946823120117, "loss_val": 344.56243896484375}, "3": {"loss_train": 882.2473678588867, "loss_val": 339.6109161376953}, "4": {"loss_train": 864.5685958862305, "loss_val": 341.22635650634766}, "5": {"loss_train": 855.9064788818359, "loss_val": 333.93506622314453}, "6": {"loss_train": 849.7932052612305, "loss_val": 336.45428466796875}, "7": {"loss_train": 835.3338775634766, "loss_val": 332.4544677734375}, "8": {"loss_train": 852.8197174072266, "loss_val": 339.9851760864258}, "9": {"loss_train": 844.85546875, "loss_val": 331.0592498779297}, "10": {"loss_train": 870.3359985351562, "loss_val": 330.17198944091797}, "11": {"loss_train": 864.4323425292969, "loss_val": 334.62776947021484}, "12": {"loss_train": 866.4737548828125, "loss_val": 330.55777740478516}, "13": {"loss_train": 879.4442901611328, "loss_val": 325.52291107177734}, "14": {"loss_train": 866.2133407592773, "loss_val": 330.3463668823242}, "15": {"loss_train": 864.9250030517578, "loss_val": 328.2007522583008}, "16": {"loss_train": 853.6245422363281, "loss_val": 332.7667465209961}, "17": {"loss_train": 864.3803176879883, "loss_val": 327.81349182128906}, "18": {"loss_train": 857.6162261962891, "loss_val": 333.7392807006836}, "19": {"loss_train": 861.505615234375, "loss_val": 335.1261291503906}, "20": {"loss_train": 822.2963180541992, "loss_val": 323.64781188964844}, "21": {"loss_train": 795.5245361328125, "loss_val": 336.4839401245117}, "22": {"loss_train": 804.6677093505859, "loss_val": 325.9162292480469}, "23": {"loss_train": 789.2748107910156, "loss_val": 327.1102066040039}, "24": {"loss_train": 786.4285659790039, "loss_val": 316.3163604736328}, "25": {"loss_train": 768.3442306518555, "loss_val": 317.53729248046875}, "26": {"loss_train": 764.2136917114258, "loss_val": 323.23240661621094}, "27": {"loss_train": 756.2015151977539, "loss_val": 316.2109375}, "28": {"loss_train": 749.6882553100586, "loss_val": 328.47899627685547}, "29": {"loss_train": 738.181884765625, "loss_val": 319.29380798339844}, "30": {"loss_train": 824.5692977905273, "loss_val": 321.4378204345703}, "31": {"loss_train": 821.3006973266602, "loss_val": 326.1012725830078}, "32": {"loss_train": 816.4933471679688, "loss_val": 326.8603210449219}, "33": {"loss_train": 843.8744125366211, "loss_val": 326.7417907714844}, "34": {"loss_train": 818.7517471313477, "loss_val": 319.9722213745117}, "35": {"loss_train": 816.655891418457, "loss_val": 333.3405227661133}, "36": {"loss_train": 813.1977462768555, "loss_val": 318.9175262451172}, "37": {"loss_train": 815.2419509887695, "loss_val": 326.61448669433594}, "38": {"loss_train": 813.9753112792969, "loss_val": 329.5320510864258}, "39": {"loss_train": 804.7759780883789, "loss_val": 330.74908447265625}, "40": {"loss_train": 752.1691131591797, "loss_val": 328.7879333496094}, "41": {"loss_train": 733.5280532836914, "loss_val": 328.1194152832031}, "42": {"loss_train": 717.2090911865234, "loss_val": 316.85889434814453}, "43": {"loss_train": 699.2594909667969, "loss_val": 322.2451858520508}, "44": {"loss_train": 703.6794281005859, "loss_val": 322.06214904785156}, "45": {"loss_train": 711.5606384277344, "loss_val": 316.6670837402344}, "46": {"loss_train": 696.823616027832, "loss_val": 321.5372085571289}, "47": {"loss_train": 682.066780090332, "loss_val": 325.55699920654297}, "48": {"loss_train": 687.7016830444336, "loss_val": 320.9182815551758}, "49": {"loss_train": 675.4723663330078, "loss_val": 317.1319046020508}, "50": {"loss_train": 786.8911209106445, "loss_val": 332.819580078125}, "51": {"loss_train": 774.2339706420898, "loss_val": 325.0603790283203}, "52": {"loss_train": 776.7124176025391, "loss_val": 327.84083557128906}, "53": {"loss_train": 785.4104614257812, "loss_val": 329.6678695678711}, "54": {"loss_train": 767.5594100952148, "loss_val": 328.45465087890625}, "55": {"loss_train": 785.8466949462891, "loss_val": 327.02821350097656}, "56": {"loss_train": 782.6178665161133, "loss_val": 334.2803421020508}, "57": {"loss_train": 783.260627746582, "loss_val": 320.63260650634766}, "58": {"loss_train": 793.3590393066406, "loss_val": 327.14696502685547}, "59": {"loss_train": 772.288330078125, "loss_val": 331.65592193603516}, "60": {"loss_train": 692.2711791992188, "loss_val": 327.1093063354492}, "61": {"loss_train": 680.9780502319336, "loss_val": 324.31138610839844}, "62": {"loss_train": 663.9458465576172, "loss_val": 331.3945617675781}, "63": {"loss_train": 661.6594924926758, "loss_val": 319.7230682373047}, "64": {"loss_train": 652.3440093994141, "loss_val": 318.3365707397461}, "65": {"loss_train": 655.6103591918945, "loss_val": 323.3797836303711}, "66": {"loss_train": 650.3124008178711, "loss_val": 315.8776397705078}, "67": {"loss_train": 639.0149536132812, "loss_val": 323.1212844848633}, "68": {"loss_train": 637.0407257080078, "loss_val": 323.38392639160156}, "69": {"loss_train": 628.3450622558594, "loss_val": 317.8788375854492}, "70": {"loss_train": 745.7345352172852, "loss_val": 320.8122329711914}, "71": {"loss_train": 752.6943588256836, "loss_val": 319.5256881713867}, "72": {"loss_train": 749.4153594970703, "loss_val": 334.9149703979492}, "73": {"loss_train": 749.3226928710938, "loss_val": 323.67113494873047}, "74": {"loss_train": 763.0223999023438, "loss_val": 329.52197265625}, "75": {"loss_train": 742.6539001464844, "loss_val": 327.53539276123047}, "76": {"loss_train": 766.1312561035156, "loss_val": 329.6587448120117}, "77": {"loss_train": 748.077880859375, "loss_val": 324.9258117675781}, "78": {"loss_train": 756.6057891845703, "loss_val": 328.49620056152344}, "79": {"loss_train": 743.4046249389648, "loss_val": 325.08458709716797}, "80": {"loss_train": 646.1676712036133, "loss_val": 320.81321716308594}, "81": {"loss_train": 639.3153915405273, "loss_val": 321.60731506347656}, "82": {"loss_train": 621.5939788818359, "loss_val": 325.2786636352539}, "83": {"loss_train": 616.6573486328125, "loss_val": 318.329345703125}, "84": {"loss_train": 606.2113647460938, "loss_val": 319.32667541503906}, "85": {"loss_train": 610.863395690918, "loss_val": 311.85575103759766}, "86": {"loss_train": 603.3075256347656, "loss_val": 321.3097610473633}, "87": {"loss_train": 590.0063934326172, "loss_val": 315.8719940185547}, "88": {"loss_train": 597.0676803588867, "loss_val": 321.66104888916016}, "89": {"loss_train": 600.0902786254883, "loss_val": 319.9428482055664, "loss_test": 212.54141235351562}}, "training_time_secs": 475.46050214767456}, "1": {"train_id": "2022_12_15_14_21_39", "accuracies": {"0": {"accuracy_train": 0.224609375, "accuracy_val": 0.171875}, "1": {"accuracy_train": 0.3125, "accuracy_val": 0.15625}, "2": {"accuracy_train": 0.32421875, "accuracy_val": 0.1458333432674408}, "3": {"accuracy_train": 0.306640625, "accuracy_val": 0.2083333432674408}, "4": {"accuracy_train": 0.3515625, "accuracy_val": 0.2135416716337204}, "5": {"accuracy_train": 0.36328125, "accuracy_val": 0.2604166865348816}, "6": {"accuracy_train": 0.365234375, "accuracy_val": 0.2552083432674408}, "7": {"accuracy_train": 0.388671875, "accuracy_val": 0.2864583432674408}, "8": {"accuracy_train": 0.37109375, "accuracy_val": 0.234375}, "9": {"accuracy_train": 0.392578125, "accuracy_val": 0.2708333432674408}, "10": {"accuracy_train": 0.326171875, "accuracy_val": 0.28125}, "11": {"accuracy_train": 0.333984375, "accuracy_val": 0.25}, "12": {"accuracy_train": 0.318359375, "accuracy_val": 0.2916666865348816}, "13": {"accuracy_train": 0.29296875, "accuracy_val": 0.3177083432674408}, "14": {"accuracy_train": 0.3359375, "accuracy_val": 0.3072916865348816}, "15": {"accuracy_train": 0.3359375, "accuracy_val": 0.3489583432674408}, "16": {"accuracy_train": 0.333984375, "accuracy_val": 0.296875}, "17": {"accuracy_train": 0.3359375, "accuracy_val": 0.3177083432674408}, "18": {"accuracy_train": 0.35546875, "accuracy_val": 0.28125}, "19": {"accuracy_train": 0.34375, "accuracy_val": 0.265625}, "20": {"accuracy_train": 0.44921875, "accuracy_val": 0.34375}, "21": {"accuracy_train": 0.51171875, "accuracy_val": 0.2604166865348816}, "22": {"accuracy_train": 0.46875, "accuracy_val": 0.328125}, "23": {"accuracy_train": 0.501953125, "accuracy_val": 0.3072916865348816}, "24": {"accuracy_train": 0.5078125, "accuracy_val": 0.375}, "25": {"accuracy_train": 0.560546875, "accuracy_val": 0.390625}, "26": {"accuracy_train": 0.556640625, "accuracy_val": 0.3333333432674408}, "27": {"accuracy_train": 0.603515625, "accuracy_val": 0.4010416865348816}, "28": {"accuracy_train": 0.599609375, "accuracy_val": 0.3072916865348816}, "29": {"accuracy_train": 0.623046875, "accuracy_val": 0.3541666865348816}, "30": {"accuracy_train": 0.416015625, "accuracy_val": 0.328125}, "31": {"accuracy_train": 0.4375, "accuracy_val": 0.3541666865348816}, "32": {"accuracy_train": 0.435546875, "accuracy_val": 0.3020833432674408}, "33": {"accuracy_train": 0.3828125, "accuracy_val": 0.3125}, "34": {"accuracy_train": 0.443359375, "accuracy_val": 0.3645833432674408}, "35": {"accuracy_train": 0.453125, "accuracy_val": 0.2708333432674408}, "36": {"accuracy_train": 0.44921875, "accuracy_val": 0.3697916865348816}, "37": {"accuracy_train": 0.44140625, "accuracy_val": 0.3125}, "38": {"accuracy_train": 0.439453125, "accuracy_val": 0.2916666865348816}, "39": {"accuracy_train": 0.486328125, "accuracy_val": 0.2760416865348816}, "40": {"accuracy_train": 0.58984375, "accuracy_val": 0.3125}, "41": {"accuracy_train": 0.64453125, "accuracy_val": 0.359375}, "42": {"accuracy_train": 0.6796875, "accuracy_val": 0.390625}, "43": {"accuracy_train": 0.701171875, "accuracy_val": 0.3802083432674408}, "44": {"accuracy_train": 0.685546875, "accuracy_val": 0.328125}, "45": {"accuracy_train": 0.66796875, "accuracy_val": 0.3958333432674408}, "46": {"accuracy_train": 0.701171875, "accuracy_val": 0.3541666865348816}, "47": {"accuracy_train": 0.73046875, "accuracy_val": 0.328125}, "48": {"accuracy_train": 0.71875, "accuracy_val": 0.3697916865348816}, "49": {"accuracy_train": 0.75, "accuracy_val": 0.3645833432674408}, "50": {"accuracy_train": 0.49609375, "accuracy_val": 0.2864583432674408}, "51": {"accuracy_train": 0.541015625, "accuracy_val": 0.3385416865348816}, "52": {"accuracy_train": 0.5078125, "accuracy_val": 0.3020833432674408}, "53": {"accuracy_train": 0.505859375, "accuracy_val": 0.2916666865348816}, "54": {"accuracy_train": 0.541015625, "accuracy_val": 0.296875}, "55": {"accuracy_train": 0.51171875, "accuracy_val": 0.3177083432674408}, "56": {"accuracy_train": 0.5234375, "accuracy_val": 0.2916666865348816}, "57": {"accuracy_train": 0.533203125, "accuracy_val": 0.34375}, "58": {"accuracy_train": 0.484375, "accuracy_val": 0.3177083432674408}, "59": {"accuracy_train": 0.5390625, "accuracy_val": 0.2760416865348816}, "60": {"accuracy_train": 0.7109375, "accuracy_val": 0.2604166865348816}, "61": {"accuracy_train": 0.73828125, "accuracy_val": 0.3177083432674408}, "62": {"accuracy_train": 0.7890625, "accuracy_val": 0.2760416865348816}, "63": {"accuracy_train": 0.783203125, "accuracy_val": 0.34375}, "64": {"accuracy_train": 0.796875, "accuracy_val": 0.3802083432674408}, "65": {"accuracy_train": 0.791015625, "accuracy_val": 0.328125}, "66": {"accuracy_train": 0.79296875, "accuracy_val": 0.4114583432674408}, "67": {"accuracy_train": 0.82421875, "accuracy_val": 0.3541666865348816}, "68": {"accuracy_train": 0.82421875, "accuracy_val": 0.3489583432674408}, "69": {"accuracy_train": 0.849609375, "accuracy_val": 0.3802083432674408}, "70": {"accuracy_train": 0.607421875, "accuracy_val": 0.3802083432674408}, "71": {"accuracy_train": 0.5703125, "accuracy_val": 0.3489583432674408}, "72": {"accuracy_train": 0.595703125, "accuracy_val": 0.28125}, "73": {"accuracy_train": 0.599609375, "accuracy_val": 0.3385416865348816}, "74": {"accuracy_train": 0.564453125, "accuracy_val": 0.3020833432674408}, "75": {"accuracy_train": 0.603515625, "accuracy_val": 0.3020833432674408}, "76": {"accuracy_train": 0.552734375, "accuracy_val": 0.28125}, "77": {"accuracy_train": 0.6015625, "accuracy_val": 0.3385416865348816}, "78": {"accuracy_train": 0.564453125, "accuracy_val": 0.3072916865348816}, "79": {"accuracy_train": 0.623046875, "accuracy_val": 0.3333333432674408}, "80": {"accuracy_train": 0.818359375, "accuracy_val": 0.3645833432674408}, "81": {"accuracy_train": 0.826171875, "accuracy_val": 0.3333333432674408}, "82": {"accuracy_train": 0.861328125, "accuracy_val": 0.3125}, "83": {"accuracy_train": 0.8671875, "accuracy_val": 0.390625}, "84": {"accuracy_train": 0.892578125, "accuracy_val": 0.3854166865348816}, "85": {"accuracy_train": 0.875, "accuracy_val": 0.4427083432674408}, "86": {"accuracy_train": 0.89453125, "accuracy_val": 0.3697916865348816}, "87": {"accuracy_train": 0.91796875, "accuracy_val": 0.40625}, "88": {"accuracy_train": 0.88671875, "accuracy_val": 0.3541666865348816}, "89": {"accuracy_train": 0.88671875, "accuracy_val": 0.3697916865348816, "accuracy_test": 0.34375}}, "losses": {"0": {"loss_train": 904.2518310546875, "loss_val": 343.9059295654297}, "1": {"loss_train": 884.4242172241211, "loss_val": 344.3298034667969}, "2": {"loss_train": 875.9946823120117, "loss_val": 344.56243896484375}, "3": {"loss_train": 882.2473678588867, "loss_val": 339.6109161376953}, "4": {"loss_train": 864.5685958862305, "loss_val": 341.22635650634766}, "5": {"loss_train": 855.9064788818359, "loss_val": 333.93506622314453}, "6": {"loss_train": 849.7932052612305, "loss_val": 336.45428466796875}, "7": {"loss_train": 835.3338775634766, "loss_val": 332.4544677734375}, "8": {"loss_train": 852.8197174072266, "loss_val": 339.9851760864258}, "9": {"loss_train": 844.85546875, "loss_val": 331.0592498779297}, "10": {"loss_train": 870.3359985351562, "loss_val": 330.17198944091797}, "11": {"loss_train": 864.4323425292969, "loss_val": 334.62776947021484}, "12": {"loss_train": 866.4737548828125, "loss_val": 330.55777740478516}, "13": {"loss_train": 879.4442901611328, "loss_val": 325.52291107177734}, "14": {"loss_train": 866.2133407592773, "loss_val": 330.3463668823242}, "15": {"loss_train": 864.9250030517578, "loss_val": 328.2007522583008}, "16": {"loss_train": 853.6245422363281, "loss_val": 332.7667465209961}, "17": {"loss_train": 864.3803176879883, "loss_val": 327.81349182128906}, "18": {"loss_train": 857.6162261962891, "loss_val": 333.7392807006836}, "19": {"loss_train": 861.505615234375, "loss_val": 335.1261291503906}, "20": {"loss_train": 822.2963180541992, "loss_val": 323.64781188964844}, "21": {"loss_train": 795.5245361328125, "loss_val": 336.4839401245117}, "22": {"loss_train": 804.6677093505859, "loss_val": 325.9162292480469}, "23": {"loss_train": 789.2748107910156, "loss_val": 327.1102066040039}, "24": {"loss_train": 786.4285659790039, "loss_val": 316.3163604736328}, "25": {"loss_train": 768.3442306518555, "loss_val": 317.53729248046875}, "26": {"loss_train": 764.2136917114258, "loss_val": 323.23240661621094}, "27": {"loss_train": 756.2015151977539, "loss_val": 316.2109375}, "28": {"loss_train": 749.6882553100586, "loss_val": 328.47899627685547}, "29": {"loss_train": 738.181884765625, "loss_val": 319.29380798339844}, "30": {"loss_train": 824.5692977905273, "loss_val": 321.4378204345703}, "31": {"loss_train": 821.3006973266602, "loss_val": 326.1012725830078}, "32": {"loss_train": 816.4933471679688, "loss_val": 326.8603210449219}, "33": {"loss_train": 843.8744125366211, "loss_val": 326.7417907714844}, "34": {"loss_train": 818.7517471313477, "loss_val": 319.9722213745117}, "35": {"loss_train": 816.655891418457, "loss_val": 333.3405227661133}, "36": {"loss_train": 813.1977462768555, "loss_val": 318.9175262451172}, "37": {"loss_train": 815.2419509887695, "loss_val": 326.61448669433594}, "38": {"loss_train": 813.9753112792969, "loss_val": 329.5320510864258}, "39": {"loss_train": 804.7759780883789, "loss_val": 330.74908447265625}, "40": {"loss_train": 752.1691131591797, "loss_val": 328.7879333496094}, "41": {"loss_train": 733.5280532836914, "loss_val": 328.1194152832031}, "42": {"loss_train": 717.2090911865234, "loss_val": 316.85889434814453}, "43": {"loss_train": 699.2594909667969, "loss_val": 322.2451858520508}, "44": {"loss_train": 703.6794281005859, "loss_val": 322.06214904785156}, "45": {"loss_train": 711.5606384277344, "loss_val": 316.6670837402344}, "46": {"loss_train": 696.823616027832, "loss_val": 321.5372085571289}, "47": {"loss_train": 682.066780090332, "loss_val": 325.55699920654297}, "48": {"loss_train": 687.7016830444336, "loss_val": 320.9182815551758}, "49": {"loss_train": 675.4723663330078, "loss_val": 317.1319046020508}, "50": {"loss_train": 786.8911209106445, "loss_val": 332.819580078125}, "51": {"loss_train": 774.2339706420898, "loss_val": 325.0603790283203}, "52": {"loss_train": 776.7124176025391, "loss_val": 327.84083557128906}, "53": {"loss_train": 785.4104614257812, "loss_val": 329.6678695678711}, "54": {"loss_train": 767.5594100952148, "loss_val": 328.45465087890625}, "55": {"loss_train": 785.8466949462891, "loss_val": 327.02821350097656}, "56": {"loss_train": 782.6178665161133, "loss_val": 334.2803421020508}, "57": {"loss_train": 783.260627746582, "loss_val": 320.63260650634766}, "58": {"loss_train": 793.3590393066406, "loss_val": 327.14696502685547}, "59": {"loss_train": 772.288330078125, "loss_val": 331.65592193603516}, "60": {"loss_train": 692.2711791992188, "loss_val": 327.1093063354492}, "61": {"loss_train": 680.9780502319336, "loss_val": 324.31138610839844}, "62": {"loss_train": 663.9458465576172, "loss_val": 331.3945617675781}, "63": {"loss_train": 661.6594924926758, "loss_val": 319.7230682373047}, "64": {"loss_train": 652.3440093994141, "loss_val": 318.3365707397461}, "65": {"loss_train": 655.6103591918945, "loss_val": 323.3797836303711}, "66": {"loss_train": 650.3124008178711, "loss_val": 315.8776397705078}, "67": {"loss_train": 639.0149536132812, "loss_val": 323.1212844848633}, "68": {"loss_train": 637.0407257080078, "loss_val": 323.38392639160156}, "69": {"loss_train": 628.3450622558594, "loss_val": 317.8788375854492}, "70": {"loss_train": 745.7345352172852, "loss_val": 320.8122329711914}, "71": {"loss_train": 752.6943588256836, "loss_val": 319.5256881713867}, "72": {"loss_train": 749.4153594970703, "loss_val": 334.9149703979492}, "73": {"loss_train": 749.3226928710938, "loss_val": 323.67113494873047}, "74": {"loss_train": 763.0223999023438, "loss_val": 329.52197265625}, "75": {"loss_train": 742.6539001464844, "loss_val": 327.53539276123047}, "76": {"loss_train": 766.1312561035156, "loss_val": 329.6587448120117}, "77": {"loss_train": 748.077880859375, "loss_val": 324.9258117675781}, "78": {"loss_train": 756.6057891845703, "loss_val": 328.49620056152344}, "79": {"loss_train": 743.4046249389648, "loss_val": 325.08458709716797}, "80": {"loss_train": 646.1676712036133, "loss_val": 320.81321716308594}, "81": {"loss_train": 639.3153915405273, "loss_val": 321.60731506347656}, "82": {"loss_train": 621.5939788818359, "loss_val": 325.2786636352539}, "83": {"loss_train": 616.6573486328125, "loss_val": 318.329345703125}, "84": {"loss_train": 606.2113647460938, "loss_val": 319.32667541503906}, "85": {"loss_train": 610.863395690918, "loss_val": 311.85575103759766}, "86": {"loss_train": 603.3075256347656, "loss_val": 321.3097610473633}, "87": {"loss_train": 590.0063934326172, "loss_val": 315.8719940185547}, "88": {"loss_train": 597.0676803588867, "loss_val": 321.66104888916016}, "89": {"loss_train": 600.0902786254883, "loss_val": 319.9428482055664, "loss_test": 212.54141235351562}}, "training_time_secs": 475.46050214767456}, "2": {"train_id": "2022_12_15_14_21_39", "accuracies": {"0": {"accuracy_train": 0.224609375, "accuracy_val": 0.171875}, "1": {"accuracy_train": 0.3125, "accuracy_val": 0.15625}, "2": {"accuracy_train": 0.32421875, "accuracy_val": 0.1458333432674408}, "3": {"accuracy_train": 0.306640625, "accuracy_val": 0.2083333432674408}, "4": {"accuracy_train": 0.3515625, "accuracy_val": 0.2135416716337204}, "5": {"accuracy_train": 0.36328125, "accuracy_val": 0.2604166865348816}, "6": {"accuracy_train": 0.365234375, "accuracy_val": 0.2552083432674408}, "7": {"accuracy_train": 0.388671875, "accuracy_val": 0.2864583432674408}, "8": {"accuracy_train": 0.37109375, "accuracy_val": 0.234375}, "9": {"accuracy_train": 0.392578125, "accuracy_val": 0.2708333432674408}, "10": {"accuracy_train": 0.326171875, "accuracy_val": 0.28125}, "11": {"accuracy_train": 0.333984375, "accuracy_val": 0.25}, "12": {"accuracy_train": 0.318359375, "accuracy_val": 0.2916666865348816}, "13": {"accuracy_train": 0.29296875, "accuracy_val": 0.3177083432674408}, "14": {"accuracy_train": 0.3359375, "accuracy_val": 0.3072916865348816}, "15": {"accuracy_train": 0.3359375, "accuracy_val": 0.3489583432674408}, "16": {"accuracy_train": 0.333984375, "accuracy_val": 0.296875}, "17": {"accuracy_train": 0.3359375, "accuracy_val": 0.3177083432674408}, "18": {"accuracy_train": 0.35546875, "accuracy_val": 0.28125}, "19": {"accuracy_train": 0.34375, "accuracy_val": 0.265625}, "20": {"accuracy_train": 0.44921875, "accuracy_val": 0.34375}, "21": {"accuracy_train": 0.51171875, "accuracy_val": 0.2604166865348816}, "22": {"accuracy_train": 0.46875, "accuracy_val": 0.328125}, "23": {"accuracy_train": 0.501953125, "accuracy_val": 0.3072916865348816}, "24": {"accuracy_train": 0.5078125, "accuracy_val": 0.375}, "25": {"accuracy_train": 0.560546875, "accuracy_val": 0.390625}, "26": {"accuracy_train": 0.556640625, "accuracy_val": 0.3333333432674408}, "27": {"accuracy_train": 0.603515625, "accuracy_val": 0.4010416865348816}, "28": {"accuracy_train": 0.599609375, "accuracy_val": 0.3072916865348816}, "29": {"accuracy_train": 0.623046875, "accuracy_val": 0.3541666865348816}, "30": {"accuracy_train": 0.416015625, "accuracy_val": 0.328125}, "31": {"accuracy_train": 0.4375, "accuracy_val": 0.3541666865348816}, "32": {"accuracy_train": 0.435546875, "accuracy_val": 0.3020833432674408}, "33": {"accuracy_train": 0.3828125, "accuracy_val": 0.3125}, "34": {"accuracy_train": 0.443359375, "accuracy_val": 0.3645833432674408}, "35": {"accuracy_train": 0.453125, "accuracy_val": 0.2708333432674408}, "36": {"accuracy_train": 0.44921875, "accuracy_val": 0.3697916865348816}, "37": {"accuracy_train": 0.44140625, "accuracy_val": 0.3125}, "38": {"accuracy_train": 0.439453125, "accuracy_val": 0.2916666865348816}, "39": {"accuracy_train": 0.486328125, "accuracy_val": 0.2760416865348816}, "40": {"accuracy_train": 0.58984375, "accuracy_val": 0.3125}, "41": {"accuracy_train": 0.64453125, "accuracy_val": 0.359375}, "42": {"accuracy_train": 0.6796875, "accuracy_val": 0.390625}, "43": {"accuracy_train": 0.701171875, "accuracy_val": 0.3802083432674408}, "44": {"accuracy_train": 0.685546875, "accuracy_val": 0.328125}, "45": {"accuracy_train": 0.66796875, "accuracy_val": 0.3958333432674408}, "46": {"accuracy_train": 0.701171875, "accuracy_val": 0.3541666865348816}, "47": {"accuracy_train": 0.73046875, "accuracy_val": 0.328125}, "48": {"accuracy_train": 0.71875, "accuracy_val": 0.3697916865348816}, "49": {"accuracy_train": 0.75, "accuracy_val": 0.3645833432674408}, "50": {"accuracy_train": 0.49609375, "accuracy_val": 0.2864583432674408}, "51": {"accuracy_train": 0.541015625, "accuracy_val": 0.3385416865348816}, "52": {"accuracy_train": 0.5078125, "accuracy_val": 0.3020833432674408}, "53": {"accuracy_train": 0.505859375, "accuracy_val": 0.2916666865348816}, "54": {"accuracy_train": 0.541015625, "accuracy_val": 0.296875}, "55": {"accuracy_train": 0.51171875, "accuracy_val": 0.3177083432674408}, "56": {"accuracy_train": 0.5234375, "accuracy_val": 0.2916666865348816}, "57": {"accuracy_train": 0.533203125, "accuracy_val": 0.34375}, "58": {"accuracy_train": 0.484375, "accuracy_val": 0.3177083432674408}, "59": {"accuracy_train": 0.5390625, "accuracy_val": 0.2760416865348816}, "60": {"accuracy_train": 0.7109375, "accuracy_val": 0.2604166865348816}, "61": {"accuracy_train": 0.73828125, "accuracy_val": 0.3177083432674408}, "62": {"accuracy_train": 0.7890625, "accuracy_val": 0.2760416865348816}, "63": {"accuracy_train": 0.783203125, "accuracy_val": 0.34375}, "64": {"accuracy_train": 0.796875, "accuracy_val": 0.3802083432674408}, "65": {"accuracy_train": 0.791015625, "accuracy_val": 0.328125}, "66": {"accuracy_train": 0.79296875, "accuracy_val": 0.4114583432674408}, "67": {"accuracy_train": 0.82421875, "accuracy_val": 0.3541666865348816}, "68": {"accuracy_train": 0.82421875, "accuracy_val": 0.3489583432674408}, "69": {"accuracy_train": 0.849609375, "accuracy_val": 0.3802083432674408}, "70": {"accuracy_train": 0.607421875, "accuracy_val": 0.3802083432674408}, "71": {"accuracy_train": 0.5703125, "accuracy_val": 0.3489583432674408}, "72": {"accuracy_train": 0.595703125, "accuracy_val": 0.28125}, "73": {"accuracy_train": 0.599609375, "accuracy_val": 0.3385416865348816}, "74": {"accuracy_train": 0.564453125, "accuracy_val": 0.3020833432674408}, "75": {"accuracy_train": 0.603515625, "accuracy_val": 0.3020833432674408}, "76": {"accuracy_train": 0.552734375, "accuracy_val": 0.28125}, "77": {"accuracy_train": 0.6015625, "accuracy_val": 0.3385416865348816}, "78": {"accuracy_train": 0.564453125, "accuracy_val": 0.3072916865348816}, "79": {"accuracy_train": 0.623046875, "accuracy_val": 0.3333333432674408}, "80": {"accuracy_train": 0.818359375, "accuracy_val": 0.3645833432674408}, "81": {"accuracy_train": 0.826171875, "accuracy_val": 0.3333333432674408}, "82": {"accuracy_train": 0.861328125, "accuracy_val": 0.3125}, "83": {"accuracy_train": 0.8671875, "accuracy_val": 0.390625}, "84": {"accuracy_train": 0.892578125, "accuracy_val": 0.3854166865348816}, "85": {"accuracy_train": 0.875, "accuracy_val": 0.4427083432674408}, "86": {"accuracy_train": 0.89453125, "accuracy_val": 0.3697916865348816}, "87": {"accuracy_train": 0.91796875, "accuracy_val": 0.40625}, "88": {"accuracy_train": 0.88671875, "accuracy_val": 0.3541666865348816}, "89": {"accuracy_train": 0.88671875, "accuracy_val": 0.3697916865348816, "accuracy_test": 0.34375}}, "losses": {"0": {"loss_train": 904.2518310546875, "loss_val": 343.9059295654297}, "1": {"loss_train": 884.4242172241211, "loss_val": 344.3298034667969}, "2": {"loss_train": 875.9946823120117, "loss_val": 344.56243896484375}, "3": {"loss_train": 882.2473678588867, "loss_val": 339.6109161376953}, "4": {"loss_train": 864.5685958862305, "loss_val": 341.22635650634766}, "5": {"loss_train": 855.9064788818359, "loss_val": 333.93506622314453}, "6": {"loss_train": 849.7932052612305, "loss_val": 336.45428466796875}, "7": {"loss_train": 835.3338775634766, "loss_val": 332.4544677734375}, "8": {"loss_train": 852.8197174072266, "loss_val": 339.9851760864258}, "9": {"loss_train": 844.85546875, "loss_val": 331.0592498779297}, "10": {"loss_train": 870.3359985351562, "loss_val": 330.17198944091797}, "11": {"loss_train": 864.4323425292969, "loss_val": 334.62776947021484}, "12": {"loss_train": 866.4737548828125, "loss_val": 330.55777740478516}, "13": {"loss_train": 879.4442901611328, "loss_val": 325.52291107177734}, "14": {"loss_train": 866.2133407592773, "loss_val": 330.3463668823242}, "15": {"loss_train": 864.9250030517578, "loss_val": 328.2007522583008}, "16": {"loss_train": 853.6245422363281, "loss_val": 332.7667465209961}, "17": {"loss_train": 864.3803176879883, "loss_val": 327.81349182128906}, "18": {"loss_train": 857.6162261962891, "loss_val": 333.7392807006836}, "19": {"loss_train": 861.505615234375, "loss_val": 335.1261291503906}, "20": {"loss_train": 822.2963180541992, "loss_val": 323.64781188964844}, "21": {"loss_train": 795.5245361328125, "loss_val": 336.4839401245117}, "22": {"loss_train": 804.6677093505859, "loss_val": 325.9162292480469}, "23": {"loss_train": 789.2748107910156, "loss_val": 327.1102066040039}, "24": {"loss_train": 786.4285659790039, "loss_val": 316.3163604736328}, "25": {"loss_train": 768.3442306518555, "loss_val": 317.53729248046875}, "26": {"loss_train": 764.2136917114258, "loss_val": 323.23240661621094}, "27": {"loss_train": 756.2015151977539, "loss_val": 316.2109375}, "28": {"loss_train": 749.6882553100586, "loss_val": 328.47899627685547}, "29": {"loss_train": 738.181884765625, "loss_val": 319.29380798339844}, "30": {"loss_train": 824.5692977905273, "loss_val": 321.4378204345703}, "31": {"loss_train": 821.3006973266602, "loss_val": 326.1012725830078}, "32": {"loss_train": 816.4933471679688, "loss_val": 326.8603210449219}, "33": {"loss_train": 843.8744125366211, "loss_val": 326.7417907714844}, "34": {"loss_train": 818.7517471313477, "loss_val": 319.9722213745117}, "35": {"loss_train": 816.655891418457, "loss_val": 333.3405227661133}, "36": {"loss_train": 813.1977462768555, "loss_val": 318.9175262451172}, "37": {"loss_train": 815.2419509887695, "loss_val": 326.61448669433594}, "38": {"loss_train": 813.9753112792969, "loss_val": 329.5320510864258}, "39": {"loss_train": 804.7759780883789, "loss_val": 330.74908447265625}, "40": {"loss_train": 752.1691131591797, "loss_val": 328.7879333496094}, "41": {"loss_train": 733.5280532836914, "loss_val": 328.1194152832031}, "42": {"loss_train": 717.2090911865234, "loss_val": 316.85889434814453}, "43": {"loss_train": 699.2594909667969, "loss_val": 322.2451858520508}, "44": {"loss_train": 703.6794281005859, "loss_val": 322.06214904785156}, "45": {"loss_train": 711.5606384277344, "loss_val": 316.6670837402344}, "46": {"loss_train": 696.823616027832, "loss_val": 321.5372085571289}, "47": {"loss_train": 682.066780090332, "loss_val": 325.55699920654297}, "48": {"loss_train": 687.7016830444336, "loss_val": 320.9182815551758}, "49": {"loss_train": 675.4723663330078, "loss_val": 317.1319046020508}, "50": {"loss_train": 786.8911209106445, "loss_val": 332.819580078125}, "51": {"loss_train": 774.2339706420898, "loss_val": 325.0603790283203}, "52": {"loss_train": 776.7124176025391, "loss_val": 327.84083557128906}, "53": {"loss_train": 785.4104614257812, "loss_val": 329.6678695678711}, "54": {"loss_train": 767.5594100952148, "loss_val": 328.45465087890625}, "55": {"loss_train": 785.8466949462891, "loss_val": 327.02821350097656}, "56": {"loss_train": 782.6178665161133, "loss_val": 334.2803421020508}, "57": {"loss_train": 783.260627746582, "loss_val": 320.63260650634766}, "58": {"loss_train": 793.3590393066406, "loss_val": 327.14696502685547}, "59": {"loss_train": 772.288330078125, "loss_val": 331.65592193603516}, "60": {"loss_train": 692.2711791992188, "loss_val": 327.1093063354492}, "61": {"loss_train": 680.9780502319336, "loss_val": 324.31138610839844}, "62": {"loss_train": 663.9458465576172, "loss_val": 331.3945617675781}, "63": {"loss_train": 661.6594924926758, "loss_val": 319.7230682373047}, "64": {"loss_train": 652.3440093994141, "loss_val": 318.3365707397461}, "65": {"loss_train": 655.6103591918945, "loss_val": 323.3797836303711}, "66": {"loss_train": 650.3124008178711, "loss_val": 315.8776397705078}, "67": {"loss_train": 639.0149536132812, "loss_val": 323.1212844848633}, "68": {"loss_train": 637.0407257080078, "loss_val": 323.38392639160156}, "69": {"loss_train": 628.3450622558594, "loss_val": 317.8788375854492}, "70": {"loss_train": 745.7345352172852, "loss_val": 320.8122329711914}, "71": {"loss_train": 752.6943588256836, "loss_val": 319.5256881713867}, "72": {"loss_train": 749.4153594970703, "loss_val": 334.9149703979492}, "73": {"loss_train": 749.3226928710938, "loss_val": 323.67113494873047}, "74": {"loss_train": 763.0223999023438, "loss_val": 329.52197265625}, "75": {"loss_train": 742.6539001464844, "loss_val": 327.53539276123047}, "76": {"loss_train": 766.1312561035156, "loss_val": 329.6587448120117}, "77": {"loss_train": 748.077880859375, "loss_val": 324.9258117675781}, "78": {"loss_train": 756.6057891845703, "loss_val": 328.49620056152344}, "79": {"loss_train": 743.4046249389648, "loss_val": 325.08458709716797}, "80": {"loss_train": 646.1676712036133, "loss_val": 320.81321716308594}, "81": {"loss_train": 639.3153915405273, "loss_val": 321.60731506347656}, "82": {"loss_train": 621.5939788818359, "loss_val": 325.2786636352539}, "83": {"loss_train": 616.6573486328125, "loss_val": 318.329345703125}, "84": {"loss_train": 606.2113647460938, "loss_val": 319.32667541503906}, "85": {"loss_train": 610.863395690918, "loss_val": 311.85575103759766}, "86": {"loss_train": 603.3075256347656, "loss_val": 321.3097610473633}, "87": {"loss_train": 590.0063934326172, "loss_val": 315.8719940185547}, "88": {"loss_train": 597.0676803588867, "loss_val": 321.66104888916016}, "89": {"loss_train": 600.0902786254883, "loss_val": 319.9428482055664, "loss_test": 212.54141235351562}}, "training_time_secs": 475.46050214767456}, "3": {"train_id": "2022_12_15_14_21_39", "accuracies": {"0": {"accuracy_train": 0.224609375, "accuracy_val": 0.171875}, "1": {"accuracy_train": 0.3125, "accuracy_val": 0.15625}, "2": {"accuracy_train": 0.32421875, "accuracy_val": 0.1458333432674408}, "3": {"accuracy_train": 0.306640625, "accuracy_val": 0.2083333432674408}, "4": {"accuracy_train": 0.3515625, "accuracy_val": 0.2135416716337204}, "5": {"accuracy_train": 0.36328125, "accuracy_val": 0.2604166865348816}, "6": {"accuracy_train": 0.365234375, "accuracy_val": 0.2552083432674408}, "7": {"accuracy_train": 0.388671875, "accuracy_val": 0.2864583432674408}, "8": {"accuracy_train": 0.37109375, "accuracy_val": 0.234375}, "9": {"accuracy_train": 0.392578125, "accuracy_val": 0.2708333432674408}, "10": {"accuracy_train": 0.326171875, "accuracy_val": 0.28125}, "11": {"accuracy_train": 0.333984375, "accuracy_val": 0.25}, "12": {"accuracy_train": 0.318359375, "accuracy_val": 0.2916666865348816}, "13": {"accuracy_train": 0.29296875, "accuracy_val": 0.3177083432674408}, "14": {"accuracy_train": 0.3359375, "accuracy_val": 0.3072916865348816}, "15": {"accuracy_train": 0.3359375, "accuracy_val": 0.3489583432674408}, "16": {"accuracy_train": 0.333984375, "accuracy_val": 0.296875}, "17": {"accuracy_train": 0.3359375, "accuracy_val": 0.3177083432674408}, "18": {"accuracy_train": 0.35546875, "accuracy_val": 0.28125}, "19": {"accuracy_train": 0.34375, "accuracy_val": 0.265625}, "20": {"accuracy_train": 0.44921875, "accuracy_val": 0.34375}, "21": {"accuracy_train": 0.51171875, "accuracy_val": 0.2604166865348816}, "22": {"accuracy_train": 0.46875, "accuracy_val": 0.328125}, "23": {"accuracy_train": 0.501953125, "accuracy_val": 0.3072916865348816}, "24": {"accuracy_train": 0.5078125, "accuracy_val": 0.375}, "25": {"accuracy_train": 0.560546875, "accuracy_val": 0.390625}, "26": {"accuracy_train": 0.556640625, "accuracy_val": 0.3333333432674408}, "27": {"accuracy_train": 0.603515625, "accuracy_val": 0.4010416865348816}, "28": {"accuracy_train": 0.599609375, "accuracy_val": 0.3072916865348816}, "29": {"accuracy_train": 0.623046875, "accuracy_val": 0.3541666865348816}, "30": {"accuracy_train": 0.416015625, "accuracy_val": 0.328125}, "31": {"accuracy_train": 0.4375, "accuracy_val": 0.3541666865348816}, "32": {"accuracy_train": 0.435546875, "accuracy_val": 0.3020833432674408}, "33": {"accuracy_train": 0.3828125, "accuracy_val": 0.3125}, "34": {"accuracy_train": 0.443359375, "accuracy_val": 0.3645833432674408}, "35": {"accuracy_train": 0.453125, "accuracy_val": 0.2708333432674408}, "36": {"accuracy_train": 0.44921875, "accuracy_val": 0.3697916865348816}, "37": {"accuracy_train": 0.44140625, "accuracy_val": 0.3125}, "38": {"accuracy_train": 0.439453125, "accuracy_val": 0.2916666865348816}, "39": {"accuracy_train": 0.486328125, "accuracy_val": 0.2760416865348816}, "40": {"accuracy_train": 0.58984375, "accuracy_val": 0.3125}, "41": {"accuracy_train": 0.64453125, "accuracy_val": 0.359375}, "42": {"accuracy_train": 0.6796875, "accuracy_val": 0.390625}, "43": {"accuracy_train": 0.701171875, "accuracy_val": 0.3802083432674408}, "44": {"accuracy_train": 0.685546875, "accuracy_val": 0.328125}, "45": {"accuracy_train": 0.66796875, "accuracy_val": 0.3958333432674408}, "46": {"accuracy_train": 0.701171875, "accuracy_val": 0.3541666865348816}, "47": {"accuracy_train": 0.73046875, "accuracy_val": 0.328125}, "48": {"accuracy_train": 0.71875, "accuracy_val": 0.3697916865348816}, "49": {"accuracy_train": 0.75, "accuracy_val": 0.3645833432674408}, "50": {"accuracy_train": 0.49609375, "accuracy_val": 0.2864583432674408}, "51": {"accuracy_train": 0.541015625, "accuracy_val": 0.3385416865348816}, "52": {"accuracy_train": 0.5078125, "accuracy_val": 0.3020833432674408}, "53": {"accuracy_train": 0.505859375, "accuracy_val": 0.2916666865348816}, "54": {"accuracy_train": 0.541015625, "accuracy_val": 0.296875}, "55": {"accuracy_train": 0.51171875, "accuracy_val": 0.3177083432674408}, "56": {"accuracy_train": 0.5234375, "accuracy_val": 0.2916666865348816}, "57": {"accuracy_train": 0.533203125, "accuracy_val": 0.34375}, "58": {"accuracy_train": 0.484375, "accuracy_val": 0.3177083432674408}, "59": {"accuracy_train": 0.5390625, "accuracy_val": 0.2760416865348816}, "60": {"accuracy_train": 0.7109375, "accuracy_val": 0.2604166865348816}, "61": {"accuracy_train": 0.73828125, "accuracy_val": 0.3177083432674408}, "62": {"accuracy_train": 0.7890625, "accuracy_val": 0.2760416865348816}, "63": {"accuracy_train": 0.783203125, "accuracy_val": 0.34375}, "64": {"accuracy_train": 0.796875, "accuracy_val": 0.3802083432674408}, "65": {"accuracy_train": 0.791015625, "accuracy_val": 0.328125}, "66": {"accuracy_train": 0.79296875, "accuracy_val": 0.4114583432674408}, "67": {"accuracy_train": 0.82421875, "accuracy_val": 0.3541666865348816}, "68": {"accuracy_train": 0.82421875, "accuracy_val": 0.3489583432674408}, "69": {"accuracy_train": 0.849609375, "accuracy_val": 0.3802083432674408}, "70": {"accuracy_train": 0.607421875, "accuracy_val": 0.3802083432674408}, "71": {"accuracy_train": 0.5703125, "accuracy_val": 0.3489583432674408}, "72": {"accuracy_train": 0.595703125, "accuracy_val": 0.28125}, "73": {"accuracy_train": 0.599609375, "accuracy_val": 0.3385416865348816}, "74": {"accuracy_train": 0.564453125, "accuracy_val": 0.3020833432674408}, "75": {"accuracy_train": 0.603515625, "accuracy_val": 0.3020833432674408}, "76": {"accuracy_train": 0.552734375, "accuracy_val": 0.28125}, "77": {"accuracy_train": 0.6015625, "accuracy_val": 0.3385416865348816}, "78": {"accuracy_train": 0.564453125, "accuracy_val": 0.3072916865348816}, "79": {"accuracy_train": 0.623046875, "accuracy_val": 0.3333333432674408}, "80": {"accuracy_train": 0.818359375, "accuracy_val": 0.3645833432674408}, "81": {"accuracy_train": 0.826171875, "accuracy_val": 0.3333333432674408}, "82": {"accuracy_train": 0.861328125, "accuracy_val": 0.3125}, "83": {"accuracy_train": 0.8671875, "accuracy_val": 0.390625}, "84": {"accuracy_train": 0.892578125, "accuracy_val": 0.3854166865348816}, "85": {"accuracy_train": 0.875, "accuracy_val": 0.4427083432674408}, "86": {"accuracy_train": 0.89453125, "accuracy_val": 0.3697916865348816}, "87": {"accuracy_train": 0.91796875, "accuracy_val": 0.40625}, "88": {"accuracy_train": 0.88671875, "accuracy_val": 0.3541666865348816}, "89": {"accuracy_train": 0.88671875, "accuracy_val": 0.3697916865348816, "accuracy_test": 0.34375}}, "losses": {"0": {"loss_train": 904.2518310546875, "loss_val": 343.9059295654297}, "1": {"loss_train": 884.4242172241211, "loss_val": 344.3298034667969}, "2": {"loss_train": 875.9946823120117, "loss_val": 344.56243896484375}, "3": {"loss_train": 882.2473678588867, "loss_val": 339.6109161376953}, "4": {"loss_train": 864.5685958862305, "loss_val": 341.22635650634766}, "5": {"loss_train": 855.9064788818359, "loss_val": 333.93506622314453}, "6": {"loss_train": 849.7932052612305, "loss_val": 336.45428466796875}, "7": {"loss_train": 835.3338775634766, "loss_val": 332.4544677734375}, "8": {"loss_train": 852.8197174072266, "loss_val": 339.9851760864258}, "9": {"loss_train": 844.85546875, "loss_val": 331.0592498779297}, "10": {"loss_train": 870.3359985351562, "loss_val": 330.17198944091797}, "11": {"loss_train": 864.4323425292969, "loss_val": 334.62776947021484}, "12": {"loss_train": 866.4737548828125, "loss_val": 330.55777740478516}, "13": {"loss_train": 879.4442901611328, "loss_val": 325.52291107177734}, "14": {"loss_train": 866.2133407592773, "loss_val": 330.3463668823242}, "15": {"loss_train": 864.9250030517578, "loss_val": 328.2007522583008}, "16": {"loss_train": 853.6245422363281, "loss_val": 332.7667465209961}, "17": {"loss_train": 864.3803176879883, "loss_val": 327.81349182128906}, "18": {"loss_train": 857.6162261962891, "loss_val": 333.7392807006836}, "19": {"loss_train": 861.505615234375, "loss_val": 335.1261291503906}, "20": {"loss_train": 822.2963180541992, "loss_val": 323.64781188964844}, "21": {"loss_train": 795.5245361328125, "loss_val": 336.4839401245117}, "22": {"loss_train": 804.6677093505859, "loss_val": 325.9162292480469}, "23": {"loss_train": 789.2748107910156, "loss_val": 327.1102066040039}, "24": {"loss_train": 786.4285659790039, "loss_val": 316.3163604736328}, "25": {"loss_train": 768.3442306518555, "loss_val": 317.53729248046875}, "26": {"loss_train": 764.2136917114258, "loss_val": 323.23240661621094}, "27": {"loss_train": 756.2015151977539, "loss_val": 316.2109375}, "28": {"loss_train": 749.6882553100586, "loss_val": 328.47899627685547}, "29": {"loss_train": 738.181884765625, "loss_val": 319.29380798339844}, "30": {"loss_train": 824.5692977905273, "loss_val": 321.4378204345703}, "31": {"loss_train": 821.3006973266602, "loss_val": 326.1012725830078}, "32": {"loss_train": 816.4933471679688, "loss_val": 326.8603210449219}, "33": {"loss_train": 843.8744125366211, "loss_val": 326.7417907714844}, "34": {"loss_train": 818.7517471313477, "loss_val": 319.9722213745117}, "35": {"loss_train": 816.655891418457, "loss_val": 333.3405227661133}, "36": {"loss_train": 813.1977462768555, "loss_val": 318.9175262451172}, "37": {"loss_train": 815.2419509887695, "loss_val": 326.61448669433594}, "38": {"loss_train": 813.9753112792969, "loss_val": 329.5320510864258}, "39": {"loss_train": 804.7759780883789, "loss_val": 330.74908447265625}, "40": {"loss_train": 752.1691131591797, "loss_val": 328.7879333496094}, "41": {"loss_train": 733.5280532836914, "loss_val": 328.1194152832031}, "42": {"loss_train": 717.2090911865234, "loss_val": 316.85889434814453}, "43": {"loss_train": 699.2594909667969, "loss_val": 322.2451858520508}, "44": {"loss_train": 703.6794281005859, "loss_val": 322.06214904785156}, "45": {"loss_train": 711.5606384277344, "loss_val": 316.6670837402344}, "46": {"loss_train": 696.823616027832, "loss_val": 321.5372085571289}, "47": {"loss_train": 682.066780090332, "loss_val": 325.55699920654297}, "48": {"loss_train": 687.7016830444336, "loss_val": 320.9182815551758}, "49": {"loss_train": 675.4723663330078, "loss_val": 317.1319046020508}, "50": {"loss_train": 786.8911209106445, "loss_val": 332.819580078125}, "51": {"loss_train": 774.2339706420898, "loss_val": 325.0603790283203}, "52": {"loss_train": 776.7124176025391, "loss_val": 327.84083557128906}, "53": {"loss_train": 785.4104614257812, "loss_val": 329.6678695678711}, "54": {"loss_train": 767.5594100952148, "loss_val": 328.45465087890625}, "55": {"loss_train": 785.8466949462891, "loss_val": 327.02821350097656}, "56": {"loss_train": 782.6178665161133, "loss_val": 334.2803421020508}, "57": {"loss_train": 783.260627746582, "loss_val": 320.63260650634766}, "58": {"loss_train": 793.3590393066406, "loss_val": 327.14696502685547}, "59": {"loss_train": 772.288330078125, "loss_val": 331.65592193603516}, "60": {"loss_train": 692.2711791992188, "loss_val": 327.1093063354492}, "61": {"loss_train": 680.9780502319336, "loss_val": 324.31138610839844}, "62": {"loss_train": 663.9458465576172, "loss_val": 331.3945617675781}, "63": {"loss_train": 661.6594924926758, "loss_val": 319.7230682373047}, "64": {"loss_train": 652.3440093994141, "loss_val": 318.3365707397461}, "65": {"loss_train": 655.6103591918945, "loss_val": 323.3797836303711}, "66": {"loss_train": 650.3124008178711, "loss_val": 315.8776397705078}, "67": {"loss_train": 639.0149536132812, "loss_val": 323.1212844848633}, "68": {"loss_train": 637.0407257080078, "loss_val": 323.38392639160156}, "69": {"loss_train": 628.3450622558594, "loss_val": 317.8788375854492}, "70": {"loss_train": 745.7345352172852, "loss_val": 320.8122329711914}, "71": {"loss_train": 752.6943588256836, "loss_val": 319.5256881713867}, "72": {"loss_train": 749.4153594970703, "loss_val": 334.9149703979492}, "73": {"loss_train": 749.3226928710938, "loss_val": 323.67113494873047}, "74": {"loss_train": 763.0223999023438, "loss_val": 329.52197265625}, "75": {"loss_train": 742.6539001464844, "loss_val": 327.53539276123047}, "76": {"loss_train": 766.1312561035156, "loss_val": 329.6587448120117}, "77": {"loss_train": 748.077880859375, "loss_val": 324.9258117675781}, "78": {"loss_train": 756.6057891845703, "loss_val": 328.49620056152344}, "79": {"loss_train": 743.4046249389648, "loss_val": 325.08458709716797}, "80": {"loss_train": 646.1676712036133, "loss_val": 320.81321716308594}, "81": {"loss_train": 639.3153915405273, "loss_val": 321.60731506347656}, "82": {"loss_train": 621.5939788818359, "loss_val": 325.2786636352539}, "83": {"loss_train": 616.6573486328125, "loss_val": 318.329345703125}, "84": {"loss_train": 606.2113647460938, "loss_val": 319.32667541503906}, "85": {"loss_train": 610.863395690918, "loss_val": 311.85575103759766}, "86": {"loss_train": 603.3075256347656, "loss_val": 321.3097610473633}, "87": {"loss_train": 590.0063934326172, "loss_val": 315.8719940185547}, "88": {"loss_train": 597.0676803588867, "loss_val": 321.66104888916016}, "89": {"loss_train": 600.0902786254883, "loss_val": 319.9428482055664, "loss_test": 212.54141235351562}}, "training_time_secs": 475.46050214767456}, "4": {"train_id": "2022_12_15_14_21_39", "accuracies": {"0": {"accuracy_train": 0.224609375, "accuracy_val": 0.171875}, "1": {"accuracy_train": 0.3125, "accuracy_val": 0.15625}, "2": {"accuracy_train": 0.32421875, "accuracy_val": 0.1458333432674408}, "3": {"accuracy_train": 0.306640625, "accuracy_val": 0.2083333432674408}, "4": {"accuracy_train": 0.3515625, "accuracy_val": 0.2135416716337204}, "5": {"accuracy_train": 0.36328125, "accuracy_val": 0.2604166865348816}, "6": {"accuracy_train": 0.365234375, "accuracy_val": 0.2552083432674408}, "7": {"accuracy_train": 0.388671875, "accuracy_val": 0.2864583432674408}, "8": {"accuracy_train": 0.37109375, "accuracy_val": 0.234375}, "9": {"accuracy_train": 0.392578125, "accuracy_val": 0.2708333432674408}, "10": {"accuracy_train": 0.326171875, "accuracy_val": 0.28125}, "11": {"accuracy_train": 0.333984375, "accuracy_val": 0.25}, "12": {"accuracy_train": 0.318359375, "accuracy_val": 0.2916666865348816}, "13": {"accuracy_train": 0.29296875, "accuracy_val": 0.3177083432674408}, "14": {"accuracy_train": 0.3359375, "accuracy_val": 0.3072916865348816}, "15": {"accuracy_train": 0.3359375, "accuracy_val": 0.3489583432674408}, "16": {"accuracy_train": 0.333984375, "accuracy_val": 0.296875}, "17": {"accuracy_train": 0.3359375, "accuracy_val": 0.3177083432674408}, "18": {"accuracy_train": 0.35546875, "accuracy_val": 0.28125}, "19": {"accuracy_train": 0.34375, "accuracy_val": 0.265625}, "20": {"accuracy_train": 0.44921875, "accuracy_val": 0.34375}, "21": {"accuracy_train": 0.51171875, "accuracy_val": 0.2604166865348816}, "22": {"accuracy_train": 0.46875, "accuracy_val": 0.328125}, "23": {"accuracy_train": 0.501953125, "accuracy_val": 0.3072916865348816}, "24": {"accuracy_train": 0.5078125, "accuracy_val": 0.375}, "25": {"accuracy_train": 0.560546875, "accuracy_val": 0.390625}, "26": {"accuracy_train": 0.556640625, "accuracy_val": 0.3333333432674408}, "27": {"accuracy_train": 0.603515625, "accuracy_val": 0.4010416865348816}, "28": {"accuracy_train": 0.599609375, "accuracy_val": 0.3072916865348816}, "29": {"accuracy_train": 0.623046875, "accuracy_val": 0.3541666865348816}, "30": {"accuracy_train": 0.416015625, "accuracy_val": 0.328125}, "31": {"accuracy_train": 0.4375, "accuracy_val": 0.3541666865348816}, "32": {"accuracy_train": 0.435546875, "accuracy_val": 0.3020833432674408}, "33": {"accuracy_train": 0.3828125, "accuracy_val": 0.3125}, "34": {"accuracy_train": 0.443359375, "accuracy_val": 0.3645833432674408}, "35": {"accuracy_train": 0.453125, "accuracy_val": 0.2708333432674408}, "36": {"accuracy_train": 0.44921875, "accuracy_val": 0.3697916865348816}, "37": {"accuracy_train": 0.44140625, "accuracy_val": 0.3125}, "38": {"accuracy_train": 0.439453125, "accuracy_val": 0.2916666865348816}, "39": {"accuracy_train": 0.486328125, "accuracy_val": 0.2760416865348816}, "40": {"accuracy_train": 0.58984375, "accuracy_val": 0.3125}, "41": {"accuracy_train": 0.64453125, "accuracy_val": 0.359375}, "42": {"accuracy_train": 0.6796875, "accuracy_val": 0.390625}, "43": {"accuracy_train": 0.701171875, "accuracy_val": 0.3802083432674408}, "44": {"accuracy_train": 0.685546875, "accuracy_val": 0.328125}, "45": {"accuracy_train": 0.66796875, "accuracy_val": 0.3958333432674408}, "46": {"accuracy_train": 0.701171875, "accuracy_val": 0.3541666865348816}, "47": {"accuracy_train": 0.73046875, "accuracy_val": 0.328125}, "48": {"accuracy_train": 0.71875, "accuracy_val": 0.3697916865348816}, "49": {"accuracy_train": 0.75, "accuracy_val": 0.3645833432674408}, "50": {"accuracy_train": 0.49609375, "accuracy_val": 0.2864583432674408}, "51": {"accuracy_train": 0.541015625, "accuracy_val": 0.3385416865348816}, "52": {"accuracy_train": 0.5078125, "accuracy_val": 0.3020833432674408}, "53": {"accuracy_train": 0.505859375, "accuracy_val": 0.2916666865348816}, "54": {"accuracy_train": 0.541015625, "accuracy_val": 0.296875}, "55": {"accuracy_train": 0.51171875, "accuracy_val": 0.3177083432674408}, "56": {"accuracy_train": 0.5234375, "accuracy_val": 0.2916666865348816}, "57": {"accuracy_train": 0.533203125, "accuracy_val": 0.34375}, "58": {"accuracy_train": 0.484375, "accuracy_val": 0.3177083432674408}, "59": {"accuracy_train": 0.5390625, "accuracy_val": 0.2760416865348816}, "60": {"accuracy_train": 0.7109375, "accuracy_val": 0.2604166865348816}, "61": {"accuracy_train": 0.73828125, "accuracy_val": 0.3177083432674408}, "62": {"accuracy_train": 0.7890625, "accuracy_val": 0.2760416865348816}, "63": {"accuracy_train": 0.783203125, "accuracy_val": 0.34375}, "64": {"accuracy_train": 0.796875, "accuracy_val": 0.3802083432674408}, "65": {"accuracy_train": 0.791015625, "accuracy_val": 0.328125}, "66": {"accuracy_train": 0.79296875, "accuracy_val": 0.4114583432674408}, "67": {"accuracy_train": 0.82421875, "accuracy_val": 0.3541666865348816}, "68": {"accuracy_train": 0.82421875, "accuracy_val": 0.3489583432674408}, "69": {"accuracy_train": 0.849609375, "accuracy_val": 0.3802083432674408}, "70": {"accuracy_train": 0.607421875, "accuracy_val": 0.3802083432674408}, "71": {"accuracy_train": 0.5703125, "accuracy_val": 0.3489583432674408}, "72": {"accuracy_train": 0.595703125, "accuracy_val": 0.28125}, "73": {"accuracy_train": 0.599609375, "accuracy_val": 0.3385416865348816}, "74": {"accuracy_train": 0.564453125, "accuracy_val": 0.3020833432674408}, "75": {"accuracy_train": 0.603515625, "accuracy_val": 0.3020833432674408}, "76": {"accuracy_train": 0.552734375, "accuracy_val": 0.28125}, "77": {"accuracy_train": 0.6015625, "accuracy_val": 0.3385416865348816}, "78": {"accuracy_train": 0.564453125, "accuracy_val": 0.3072916865348816}, "79": {"accuracy_train": 0.623046875, "accuracy_val": 0.3333333432674408}, "80": {"accuracy_train": 0.818359375, "accuracy_val": 0.3645833432674408}, "81": {"accuracy_train": 0.826171875, "accuracy_val": 0.3333333432674408}, "82": {"accuracy_train": 0.861328125, "accuracy_val": 0.3125}, "83": {"accuracy_train": 0.8671875, "accuracy_val": 0.390625}, "84": {"accuracy_train": 0.892578125, "accuracy_val": 0.3854166865348816}, "85": {"accuracy_train": 0.875, "accuracy_val": 0.4427083432674408}, "86": {"accuracy_train": 0.89453125, "accuracy_val": 0.3697916865348816}, "87": {"accuracy_train": 0.91796875, "accuracy_val": 0.40625}, "88": {"accuracy_train": 0.88671875, "accuracy_val": 0.3541666865348816}, "89": {"accuracy_train": 0.88671875, "accuracy_val": 0.3697916865348816, "accuracy_test": 0.34375}}, "losses": {"0": {"loss_train": 904.2518310546875, "loss_val": 343.9059295654297}, "1": {"loss_train": 884.4242172241211, "loss_val": 344.3298034667969}, "2": {"loss_train": 875.9946823120117, "loss_val": 344.56243896484375}, "3": {"loss_train": 882.2473678588867, "loss_val": 339.6109161376953}, "4": {"loss_train": 864.5685958862305, "loss_val": 341.22635650634766}, "5": {"loss_train": 855.9064788818359, "loss_val": 333.93506622314453}, "6": {"loss_train": 849.7932052612305, "loss_val": 336.45428466796875}, "7": {"loss_train": 835.3338775634766, "loss_val": 332.4544677734375}, "8": {"loss_train": 852.8197174072266, "loss_val": 339.9851760864258}, "9": {"loss_train": 844.85546875, "loss_val": 331.0592498779297}, "10": {"loss_train": 870.3359985351562, "loss_val": 330.17198944091797}, "11": {"loss_train": 864.4323425292969, "loss_val": 334.62776947021484}, "12": {"loss_train": 866.4737548828125, "loss_val": 330.55777740478516}, "13": {"loss_train": 879.4442901611328, "loss_val": 325.52291107177734}, "14": {"loss_train": 866.2133407592773, "loss_val": 330.3463668823242}, "15": {"loss_train": 864.9250030517578, "loss_val": 328.2007522583008}, "16": {"loss_train": 853.6245422363281, "loss_val": 332.7667465209961}, "17": {"loss_train": 864.3803176879883, "loss_val": 327.81349182128906}, "18": {"loss_train": 857.6162261962891, "loss_val": 333.7392807006836}, "19": {"loss_train": 861.505615234375, "loss_val": 335.1261291503906}, "20": {"loss_train": 822.2963180541992, "loss_val": 323.64781188964844}, "21": {"loss_train": 795.5245361328125, "loss_val": 336.4839401245117}, "22": {"loss_train": 804.6677093505859, "loss_val": 325.9162292480469}, "23": {"loss_train": 789.2748107910156, "loss_val": 327.1102066040039}, "24": {"loss_train": 786.4285659790039, "loss_val": 316.3163604736328}, "25": {"loss_train": 768.3442306518555, "loss_val": 317.53729248046875}, "26": {"loss_train": 764.2136917114258, "loss_val": 323.23240661621094}, "27": {"loss_train": 756.2015151977539, "loss_val": 316.2109375}, "28": {"loss_train": 749.6882553100586, "loss_val": 328.47899627685547}, "29": {"loss_train": 738.181884765625, "loss_val": 319.29380798339844}, "30": {"loss_train": 824.5692977905273, "loss_val": 321.4378204345703}, "31": {"loss_train": 821.3006973266602, "loss_val": 326.1012725830078}, "32": {"loss_train": 816.4933471679688, "loss_val": 326.8603210449219}, "33": {"loss_train": 843.8744125366211, "loss_val": 326.7417907714844}, "34": {"loss_train": 818.7517471313477, "loss_val": 319.9722213745117}, "35": {"loss_train": 816.655891418457, "loss_val": 333.3405227661133}, "36": {"loss_train": 813.1977462768555, "loss_val": 318.9175262451172}, "37": {"loss_train": 815.2419509887695, "loss_val": 326.61448669433594}, "38": {"loss_train": 813.9753112792969, "loss_val": 329.5320510864258}, "39": {"loss_train": 804.7759780883789, "loss_val": 330.74908447265625}, "40": {"loss_train": 752.1691131591797, "loss_val": 328.7879333496094}, "41": {"loss_train": 733.5280532836914, "loss_val": 328.1194152832031}, "42": {"loss_train": 717.2090911865234, "loss_val": 316.85889434814453}, "43": {"loss_train": 699.2594909667969, "loss_val": 322.2451858520508}, "44": {"loss_train": 703.6794281005859, "loss_val": 322.06214904785156}, "45": {"loss_train": 711.5606384277344, "loss_val": 316.6670837402344}, "46": {"loss_train": 696.823616027832, "loss_val": 321.5372085571289}, "47": {"loss_train": 682.066780090332, "loss_val": 325.55699920654297}, "48": {"loss_train": 687.7016830444336, "loss_val": 320.9182815551758}, "49": {"loss_train": 675.4723663330078, "loss_val": 317.1319046020508}, "50": {"loss_train": 786.8911209106445, "loss_val": 332.819580078125}, "51": {"loss_train": 774.2339706420898, "loss_val": 325.0603790283203}, "52": {"loss_train": 776.7124176025391, "loss_val": 327.84083557128906}, "53": {"loss_train": 785.4104614257812, "loss_val": 329.6678695678711}, "54": {"loss_train": 767.5594100952148, "loss_val": 328.45465087890625}, "55": {"loss_train": 785.8466949462891, "loss_val": 327.02821350097656}, "56": {"loss_train": 782.6178665161133, "loss_val": 334.2803421020508}, "57": {"loss_train": 783.260627746582, "loss_val": 320.63260650634766}, "58": {"loss_train": 793.3590393066406, "loss_val": 327.14696502685547}, "59": {"loss_train": 772.288330078125, "loss_val": 331.65592193603516}, "60": {"loss_train": 692.2711791992188, "loss_val": 327.1093063354492}, "61": {"loss_train": 680.9780502319336, "loss_val": 324.31138610839844}, "62": {"loss_train": 663.9458465576172, "loss_val": 331.3945617675781}, "63": {"loss_train": 661.6594924926758, "loss_val": 319.7230682373047}, "64": {"loss_train": 652.3440093994141, "loss_val": 318.3365707397461}, "65": {"loss_train": 655.6103591918945, "loss_val": 323.3797836303711}, "66": {"loss_train": 650.3124008178711, "loss_val": 315.8776397705078}, "67": {"loss_train": 639.0149536132812, "loss_val": 323.1212844848633}, "68": {"loss_train": 637.0407257080078, "loss_val": 323.38392639160156}, "69": {"loss_train": 628.3450622558594, "loss_val": 317.8788375854492}, "70": {"loss_train": 745.7345352172852, "loss_val": 320.8122329711914}, "71": {"loss_train": 752.6943588256836, "loss_val": 319.5256881713867}, "72": {"loss_train": 749.4153594970703, "loss_val": 334.9149703979492}, "73": {"loss_train": 749.3226928710938, "loss_val": 323.67113494873047}, "74": {"loss_train": 763.0223999023438, "loss_val": 329.52197265625}, "75": {"loss_train": 742.6539001464844, "loss_val": 327.53539276123047}, "76": {"loss_train": 766.1312561035156, "loss_val": 329.6587448120117}, "77": {"loss_train": 748.077880859375, "loss_val": 324.9258117675781}, "78": {"loss_train": 756.6057891845703, "loss_val": 328.49620056152344}, "79": {"loss_train": 743.4046249389648, "loss_val": 325.08458709716797}, "80": {"loss_train": 646.1676712036133, "loss_val": 320.81321716308594}, "81": {"loss_train": 639.3153915405273, "loss_val": 321.60731506347656}, "82": {"loss_train": 621.5939788818359, "loss_val": 325.2786636352539}, "83": {"loss_train": 616.6573486328125, "loss_val": 318.329345703125}, "84": {"loss_train": 606.2113647460938, "loss_val": 319.32667541503906}, "85": {"loss_train": 610.863395690918, "loss_val": 311.85575103759766}, "86": {"loss_train": 603.3075256347656, "loss_val": 321.3097610473633}, "87": {"loss_train": 590.0063934326172, "loss_val": 315.8719940185547}, "88": {"loss_train": 597.0676803588867, "loss_val": 321.66104888916016}, "89": {"loss_train": 600.0902786254883, "loss_val": 319.9428482055664, "loss_test": 212.54141235351562}}, "training_time_secs": 475.46050214767456}}, "lr_scheduler_configr": {"lr_scheduler_type": null, "lr_scheduler_step_size": 30, "lr_scheduler_gamma": 0.02, "lr_scheduler_last_epoch": -1}}