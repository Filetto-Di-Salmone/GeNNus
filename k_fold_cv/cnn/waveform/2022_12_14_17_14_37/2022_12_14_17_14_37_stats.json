{"k_fold_cv_id": "2022_12_14_17_14_37", "stats_type": "k_fold_cross_validation", "k_folds_cv_num_folds": 3, "data_logs": {"data_type": "waveform", "dataset_size": "s", "batch_size": 64, "num_samples_per_second": 8000, "num_channels": 1, "train_transforms": "[\"{'transform_name': 'StandardizeTransform', 'mean': -7.975741027621552e-05, 'std': 0.2950393557548523}\", 'RandomApply(\\n    p=0.05\\n    PolarityInversion()\\n)', 'RandomApply(\\n    p=0.05\\n    Noise()\\n)', 'RandomApply(\\n    p=0.05\\n    Gain()\\n)', 'RandomApply(\\n    p=0.05\\n    Delay()\\n)', {'p_boosting_factors': None, 'epoch_steps': None}]"}, "optimizer_config": {"lr": 0.01, "momentum": 0.9, "weight_decay": 0.001, "nesterov": true}, "model_setup": {"num_layers": 5, "kernel_sizes": [2, 2, 2, 2, 2], "strides": [2, 2, 2, 2, 2], "in_channels": 1, "num_filters": [16, 32, 64, 128, 256], "pool_sizes": [2, 2, 2, 2, 2], "pool_strides": [2, 2, 2, 2, 2], "dropout_p_conv": 0.0, "dropout_p_linear": 0.5}, "training_logs": {"0": {"train_id": "2022_12_14_17_14_37", "accuracies": {"0": {"accuracy_train": 0.165178582072258, "accuracy_val": 0.18225419521331787}, "1": {"accuracy_train": 0.2098214328289032, "accuracy_val": 0.1834532469511032}, "2": {"accuracy_train": 0.227678582072258, "accuracy_val": 0.1834532469511032}, "3": {"accuracy_train": 0.2053571492433548, "accuracy_val": 0.18465228378772736}, "4": {"accuracy_train": 0.2254464328289032, "accuracy_val": 0.18465228378772736}, "5": {"accuracy_train": 0.2031250149011612, "accuracy_val": 0.18465228378772736}, "6": {"accuracy_train": 0.2075892984867096, "accuracy_val": 0.18465228378772736}, "7": {"accuracy_train": 0.2053571492433548, "accuracy_val": 0.18225419521331787}, "8": {"accuracy_train": 0.2187500149011612, "accuracy_val": 0.18225419521331787}, "9": {"accuracy_train": 0.2142857313156128, "accuracy_val": 0.1834532469511032}, "10": {"accuracy_train": 0.2209821492433548, "accuracy_val": 0.1834532469511032}, "11": {"accuracy_train": 0.2187500149011612, "accuracy_val": 0.1834532469511032}, "12": {"accuracy_train": 0.165178582072258, "accuracy_val": 0.1834532469511032}, "13": {"accuracy_train": 0.1986607164144516, "accuracy_val": 0.1834532469511032}, "14": {"accuracy_train": 0.1919642984867096, "accuracy_val": 0.18225419521331787}, "15": {"accuracy_train": 0.2075892984867096, "accuracy_val": 0.18225419521331787}, "16": {"accuracy_train": 0.2232142984867096, "accuracy_val": 0.18225419521331787}, "17": {"accuracy_train": 0.2232142984867096, "accuracy_val": 0.1834532469511032}, "18": {"accuracy_train": 0.2008928656578064, "accuracy_val": 0.18465228378772736}, "19": {"accuracy_train": 0.1919642984867096, "accuracy_val": 0.18465228378772736}, "20": {"accuracy_train": 0.2209821492433548, "accuracy_val": 0.18465228378772736}, "21": {"accuracy_train": 0.212053582072258, "accuracy_val": 0.1834532469511032}, "22": {"accuracy_train": 0.2165178656578064, "accuracy_val": 0.1834532469511032}, "23": {"accuracy_train": 0.2008928656578064, "accuracy_val": 0.18225419521331787}, "24": {"accuracy_train": 0.2232142984867096, "accuracy_val": 0.1834532469511032}, "25": {"accuracy_train": 0.2254464328289032, "accuracy_val": 0.1834532469511032}, "26": {"accuracy_train": 0.1941964328289032, "accuracy_val": 0.1834532469511032}, "27": {"accuracy_train": 0.2142857313156128, "accuracy_val": 0.1834532469511032}, "28": {"accuracy_train": 0.2142857313156128, "accuracy_val": 0.18465228378772736}, "29": {"accuracy_train": 0.2544642984867096, "accuracy_val": 0.18465228378772736}, "30": {"accuracy_train": 0.1875000149011612, "accuracy_val": 0.18465228378772736}, "31": {"accuracy_train": 0.252232164144516, "accuracy_val": 0.18465228378772736}, "32": {"accuracy_train": 0.2343750149011612, "accuracy_val": 0.18465228378772736}, "33": {"accuracy_train": 0.2098214328289032, "accuracy_val": 0.1834532469511032}, "34": {"accuracy_train": 0.212053582072258, "accuracy_val": 0.18225419521331787}, "35": {"accuracy_train": 0.1919642984867096, "accuracy_val": 0.18225419521331787}, "36": {"accuracy_train": 0.2142857313156128, "accuracy_val": 0.18465228378772736}, "37": {"accuracy_train": 0.1986607164144516, "accuracy_val": 0.1834532469511032}, "38": {"accuracy_train": 0.1919642984867096, "accuracy_val": 0.1834532469511032}, "39": {"accuracy_train": 0.2410714328289032, "accuracy_val": 0.18225419521331787}, "40": {"accuracy_train": 0.2187500149011612, "accuracy_val": 0.1834532469511032}, "41": {"accuracy_train": 0.2165178656578064, "accuracy_val": 0.1834532469511032}, "42": {"accuracy_train": 0.2165178656578064, "accuracy_val": 0.1834532469511032}, "43": {"accuracy_train": 0.2566964328289032, "accuracy_val": 0.18225419521331787}, "44": {"accuracy_train": 0.2053571492433548, "accuracy_val": 0.1834532469511032}, "45": {"accuracy_train": 0.196428582072258, "accuracy_val": 0.1834532469511032}, "46": {"accuracy_train": 0.1941964328289032, "accuracy_val": 0.1834532469511032}, "47": {"accuracy_train": 0.1919642984867096, "accuracy_val": 0.18225419521331787}, "48": {"accuracy_train": 0.196428582072258, "accuracy_val": 0.1834532469511032}, "49": {"accuracy_train": 0.2142857313156128, "accuracy_val": 0.1834532469511032, "accuracy_test": 0.17985612154006958}}, "losses": {"0": {"loss_train": 810.5723037719727, "loss_val": 1493.3968091011047}, "1": {"loss_train": 804.5307998657227, "loss_val": 1492.9987435340881}, "2": {"loss_train": 811.1992340087891, "loss_val": 1495.357029914856}, "3": {"loss_train": 809.8336791992188, "loss_val": 1495.972547531128}, "4": {"loss_train": 801.4474029541016, "loss_val": 1499.4847683906555}, "5": {"loss_train": 806.7471542358398, "loss_val": 1504.8640584945679}, "6": {"loss_train": 806.2515106201172, "loss_val": 1514.4288005828857}, "7": {"loss_train": 813.8444061279297, "loss_val": 1525.200237751007}, "8": {"loss_train": 811.2518310546875, "loss_val": 1525.4530732631683}, "9": {"loss_train": 804.1471862792969, "loss_val": 1519.8356671333313}, "10": {"loss_train": 802.7742767333984, "loss_val": 1517.9897303581238}, "11": {"loss_train": 803.2080993652344, "loss_val": 1517.2215433120728}, "12": {"loss_train": 807.0717468261719, "loss_val": 1519.1567487716675}, "13": {"loss_train": 803.2686767578125, "loss_val": 1522.659131526947}, "14": {"loss_train": 802.716926574707, "loss_val": 1525.0156111717224}, "15": {"loss_train": 808.7432403564453, "loss_val": 1530.5184128284454}, "16": {"loss_train": 797.4288177490234, "loss_val": 1530.3975658416748}, "17": {"loss_train": 800.8866806030273, "loss_val": 1531.027901649475}, "18": {"loss_train": 797.4162826538086, "loss_val": 1531.6633014678955}, "19": {"loss_train": 804.2078094482422, "loss_val": 1532.2230215072632}, "20": {"loss_train": 792.2821197509766, "loss_val": 1531.4558086395264}, "21": {"loss_train": 802.0979995727539, "loss_val": 1531.219703912735}, "22": {"loss_train": 807.3087997436523, "loss_val": 1529.997817516327}, "23": {"loss_train": 795.7384033203125, "loss_val": 1530.5649099349976}, "24": {"loss_train": 802.2716064453125, "loss_val": 1530.606262922287}, "25": {"loss_train": 805.8966827392578, "loss_val": 1530.1193733215332}, "26": {"loss_train": 803.7727203369141, "loss_val": 1530.5105006694794}, "27": {"loss_train": 792.7233657836914, "loss_val": 1531.0076942443848}, "28": {"loss_train": 808.8500442504883, "loss_val": 1531.110984802246}, "29": {"loss_train": 788.4567947387695, "loss_val": 1531.3458831310272}, "30": {"loss_train": 803.9075088500977, "loss_val": 1530.8482694625854}, "31": {"loss_train": 799.7234039306641, "loss_val": 1528.78941488266}, "32": {"loss_train": 801.4323348999023, "loss_val": 1529.0923964977264}, "33": {"loss_train": 799.7437210083008, "loss_val": 1528.3274593353271}, "34": {"loss_train": 815.2927322387695, "loss_val": 1527.2112710475922}, "35": {"loss_train": 805.6511306762695, "loss_val": 1526.7664890289307}, "36": {"loss_train": 789.9871139526367, "loss_val": 1526.8377990722656}, "37": {"loss_train": 812.6279602050781, "loss_val": 1527.724925994873}, "38": {"loss_train": 811.6913604736328, "loss_val": 1528.2297925949097}, "39": {"loss_train": 799.3310928344727, "loss_val": 1526.5594449043274}, "40": {"loss_train": 799.8291549682617, "loss_val": 1527.7226114273071}, "41": {"loss_train": 801.378532409668, "loss_val": 1528.2850451469421}, "42": {"loss_train": 809.5854263305664, "loss_val": 1528.670262336731}, "43": {"loss_train": 794.7033233642578, "loss_val": 1527.7441010475159}, "44": {"loss_train": 797.8351440429688, "loss_val": 1528.1862287521362}, "45": {"loss_train": 808.1543350219727, "loss_val": 1528.0947153568268}, "46": {"loss_train": 805.6458740234375, "loss_val": 1527.550122976303}, "47": {"loss_train": 806.7029418945312, "loss_val": 1527.776249408722}, "48": {"loss_train": 804.4349670410156, "loss_val": 1527.7314248085022}, "49": {"loss_train": 802.958869934082, "loss_val": 1528.0001492500305, "loss_test": 501.0512068271637}}, "training_time_secs": 183.07815790176392}, "1": {"train_id": "2022_12_14_17_14_37", "accuracies": {"0": {"accuracy_train": 0.165178582072258, "accuracy_val": 0.18225419521331787}, "1": {"accuracy_train": 0.2098214328289032, "accuracy_val": 0.1834532469511032}, "2": {"accuracy_train": 0.227678582072258, "accuracy_val": 0.1834532469511032}, "3": {"accuracy_train": 0.2053571492433548, "accuracy_val": 0.18465228378772736}, "4": {"accuracy_train": 0.2254464328289032, "accuracy_val": 0.18465228378772736}, "5": {"accuracy_train": 0.2031250149011612, "accuracy_val": 0.18465228378772736}, "6": {"accuracy_train": 0.2075892984867096, "accuracy_val": 0.18465228378772736}, "7": {"accuracy_train": 0.2053571492433548, "accuracy_val": 0.18225419521331787}, "8": {"accuracy_train": 0.2187500149011612, "accuracy_val": 0.18225419521331787}, "9": {"accuracy_train": 0.2142857313156128, "accuracy_val": 0.1834532469511032}, "10": {"accuracy_train": 0.2209821492433548, "accuracy_val": 0.1834532469511032}, "11": {"accuracy_train": 0.2187500149011612, "accuracy_val": 0.1834532469511032}, "12": {"accuracy_train": 0.165178582072258, "accuracy_val": 0.1834532469511032}, "13": {"accuracy_train": 0.1986607164144516, "accuracy_val": 0.1834532469511032}, "14": {"accuracy_train": 0.1919642984867096, "accuracy_val": 0.18225419521331787}, "15": {"accuracy_train": 0.2075892984867096, "accuracy_val": 0.18225419521331787}, "16": {"accuracy_train": 0.2232142984867096, "accuracy_val": 0.18225419521331787}, "17": {"accuracy_train": 0.2232142984867096, "accuracy_val": 0.1834532469511032}, "18": {"accuracy_train": 0.2008928656578064, "accuracy_val": 0.18465228378772736}, "19": {"accuracy_train": 0.1919642984867096, "accuracy_val": 0.18465228378772736}, "20": {"accuracy_train": 0.2209821492433548, "accuracy_val": 0.18465228378772736}, "21": {"accuracy_train": 0.212053582072258, "accuracy_val": 0.1834532469511032}, "22": {"accuracy_train": 0.2165178656578064, "accuracy_val": 0.1834532469511032}, "23": {"accuracy_train": 0.2008928656578064, "accuracy_val": 0.18225419521331787}, "24": {"accuracy_train": 0.2232142984867096, "accuracy_val": 0.1834532469511032}, "25": {"accuracy_train": 0.2254464328289032, "accuracy_val": 0.1834532469511032}, "26": {"accuracy_train": 0.1941964328289032, "accuracy_val": 0.1834532469511032}, "27": {"accuracy_train": 0.2142857313156128, "accuracy_val": 0.1834532469511032}, "28": {"accuracy_train": 0.2142857313156128, "accuracy_val": 0.18465228378772736}, "29": {"accuracy_train": 0.2544642984867096, "accuracy_val": 0.18465228378772736}, "30": {"accuracy_train": 0.1875000149011612, "accuracy_val": 0.18465228378772736}, "31": {"accuracy_train": 0.252232164144516, "accuracy_val": 0.18465228378772736}, "32": {"accuracy_train": 0.2343750149011612, "accuracy_val": 0.18465228378772736}, "33": {"accuracy_train": 0.2098214328289032, "accuracy_val": 0.1834532469511032}, "34": {"accuracy_train": 0.212053582072258, "accuracy_val": 0.18225419521331787}, "35": {"accuracy_train": 0.1919642984867096, "accuracy_val": 0.18225419521331787}, "36": {"accuracy_train": 0.2142857313156128, "accuracy_val": 0.18465228378772736}, "37": {"accuracy_train": 0.1986607164144516, "accuracy_val": 0.1834532469511032}, "38": {"accuracy_train": 0.1919642984867096, "accuracy_val": 0.1834532469511032}, "39": {"accuracy_train": 0.2410714328289032, "accuracy_val": 0.18225419521331787}, "40": {"accuracy_train": 0.2187500149011612, "accuracy_val": 0.1834532469511032}, "41": {"accuracy_train": 0.2165178656578064, "accuracy_val": 0.1834532469511032}, "42": {"accuracy_train": 0.2165178656578064, "accuracy_val": 0.1834532469511032}, "43": {"accuracy_train": 0.2566964328289032, "accuracy_val": 0.18225419521331787}, "44": {"accuracy_train": 0.2053571492433548, "accuracy_val": 0.1834532469511032}, "45": {"accuracy_train": 0.196428582072258, "accuracy_val": 0.1834532469511032}, "46": {"accuracy_train": 0.1941964328289032, "accuracy_val": 0.1834532469511032}, "47": {"accuracy_train": 0.1919642984867096, "accuracy_val": 0.18225419521331787}, "48": {"accuracy_train": 0.196428582072258, "accuracy_val": 0.1834532469511032}, "49": {"accuracy_train": 0.2142857313156128, "accuracy_val": 0.1834532469511032, "accuracy_test": 0.17985612154006958}}, "losses": {"0": {"loss_train": 810.5723037719727, "loss_val": 1493.3968091011047}, "1": {"loss_train": 804.5307998657227, "loss_val": 1492.9987435340881}, "2": {"loss_train": 811.1992340087891, "loss_val": 1495.357029914856}, "3": {"loss_train": 809.8336791992188, "loss_val": 1495.972547531128}, "4": {"loss_train": 801.4474029541016, "loss_val": 1499.4847683906555}, "5": {"loss_train": 806.7471542358398, "loss_val": 1504.8640584945679}, "6": {"loss_train": 806.2515106201172, "loss_val": 1514.4288005828857}, "7": {"loss_train": 813.8444061279297, "loss_val": 1525.200237751007}, "8": {"loss_train": 811.2518310546875, "loss_val": 1525.4530732631683}, "9": {"loss_train": 804.1471862792969, "loss_val": 1519.8356671333313}, "10": {"loss_train": 802.7742767333984, "loss_val": 1517.9897303581238}, "11": {"loss_train": 803.2080993652344, "loss_val": 1517.2215433120728}, "12": {"loss_train": 807.0717468261719, "loss_val": 1519.1567487716675}, "13": {"loss_train": 803.2686767578125, "loss_val": 1522.659131526947}, "14": {"loss_train": 802.716926574707, "loss_val": 1525.0156111717224}, "15": {"loss_train": 808.7432403564453, "loss_val": 1530.5184128284454}, "16": {"loss_train": 797.4288177490234, "loss_val": 1530.3975658416748}, "17": {"loss_train": 800.8866806030273, "loss_val": 1531.027901649475}, "18": {"loss_train": 797.4162826538086, "loss_val": 1531.6633014678955}, "19": {"loss_train": 804.2078094482422, "loss_val": 1532.2230215072632}, "20": {"loss_train": 792.2821197509766, "loss_val": 1531.4558086395264}, "21": {"loss_train": 802.0979995727539, "loss_val": 1531.219703912735}, "22": {"loss_train": 807.3087997436523, "loss_val": 1529.997817516327}, "23": {"loss_train": 795.7384033203125, "loss_val": 1530.5649099349976}, "24": {"loss_train": 802.2716064453125, "loss_val": 1530.606262922287}, "25": {"loss_train": 805.8966827392578, "loss_val": 1530.1193733215332}, "26": {"loss_train": 803.7727203369141, "loss_val": 1530.5105006694794}, "27": {"loss_train": 792.7233657836914, "loss_val": 1531.0076942443848}, "28": {"loss_train": 808.8500442504883, "loss_val": 1531.110984802246}, "29": {"loss_train": 788.4567947387695, "loss_val": 1531.3458831310272}, "30": {"loss_train": 803.9075088500977, "loss_val": 1530.8482694625854}, "31": {"loss_train": 799.7234039306641, "loss_val": 1528.78941488266}, "32": {"loss_train": 801.4323348999023, "loss_val": 1529.0923964977264}, "33": {"loss_train": 799.7437210083008, "loss_val": 1528.3274593353271}, "34": {"loss_train": 815.2927322387695, "loss_val": 1527.2112710475922}, "35": {"loss_train": 805.6511306762695, "loss_val": 1526.7664890289307}, "36": {"loss_train": 789.9871139526367, "loss_val": 1526.8377990722656}, "37": {"loss_train": 812.6279602050781, "loss_val": 1527.724925994873}, "38": {"loss_train": 811.6913604736328, "loss_val": 1528.2297925949097}, "39": {"loss_train": 799.3310928344727, "loss_val": 1526.5594449043274}, "40": {"loss_train": 799.8291549682617, "loss_val": 1527.7226114273071}, "41": {"loss_train": 801.378532409668, "loss_val": 1528.2850451469421}, "42": {"loss_train": 809.5854263305664, "loss_val": 1528.670262336731}, "43": {"loss_train": 794.7033233642578, "loss_val": 1527.7441010475159}, "44": {"loss_train": 797.8351440429688, "loss_val": 1528.1862287521362}, "45": {"loss_train": 808.1543350219727, "loss_val": 1528.0947153568268}, "46": {"loss_train": 805.6458740234375, "loss_val": 1527.550122976303}, "47": {"loss_train": 806.7029418945312, "loss_val": 1527.776249408722}, "48": {"loss_train": 804.4349670410156, "loss_val": 1527.7314248085022}, "49": {"loss_train": 802.958869934082, "loss_val": 1528.0001492500305, "loss_test": 501.0512068271637}}, "training_time_secs": 183.07815790176392}, "2": {"train_id": "2022_12_14_17_14_37", "accuracies": {"0": {"accuracy_train": 0.165178582072258, "accuracy_val": 0.18225419521331787}, "1": {"accuracy_train": 0.2098214328289032, "accuracy_val": 0.1834532469511032}, "2": {"accuracy_train": 0.227678582072258, "accuracy_val": 0.1834532469511032}, "3": {"accuracy_train": 0.2053571492433548, "accuracy_val": 0.18465228378772736}, "4": {"accuracy_train": 0.2254464328289032, "accuracy_val": 0.18465228378772736}, "5": {"accuracy_train": 0.2031250149011612, "accuracy_val": 0.18465228378772736}, "6": {"accuracy_train": 0.2075892984867096, "accuracy_val": 0.18465228378772736}, "7": {"accuracy_train": 0.2053571492433548, "accuracy_val": 0.18225419521331787}, "8": {"accuracy_train": 0.2187500149011612, "accuracy_val": 0.18225419521331787}, "9": {"accuracy_train": 0.2142857313156128, "accuracy_val": 0.1834532469511032}, "10": {"accuracy_train": 0.2209821492433548, "accuracy_val": 0.1834532469511032}, "11": {"accuracy_train": 0.2187500149011612, "accuracy_val": 0.1834532469511032}, "12": {"accuracy_train": 0.165178582072258, "accuracy_val": 0.1834532469511032}, "13": {"accuracy_train": 0.1986607164144516, "accuracy_val": 0.1834532469511032}, "14": {"accuracy_train": 0.1919642984867096, "accuracy_val": 0.18225419521331787}, "15": {"accuracy_train": 0.2075892984867096, "accuracy_val": 0.18225419521331787}, "16": {"accuracy_train": 0.2232142984867096, "accuracy_val": 0.18225419521331787}, "17": {"accuracy_train": 0.2232142984867096, "accuracy_val": 0.1834532469511032}, "18": {"accuracy_train": 0.2008928656578064, "accuracy_val": 0.18465228378772736}, "19": {"accuracy_train": 0.1919642984867096, "accuracy_val": 0.18465228378772736}, "20": {"accuracy_train": 0.2209821492433548, "accuracy_val": 0.18465228378772736}, "21": {"accuracy_train": 0.212053582072258, "accuracy_val": 0.1834532469511032}, "22": {"accuracy_train": 0.2165178656578064, "accuracy_val": 0.1834532469511032}, "23": {"accuracy_train": 0.2008928656578064, "accuracy_val": 0.18225419521331787}, "24": {"accuracy_train": 0.2232142984867096, "accuracy_val": 0.1834532469511032}, "25": {"accuracy_train": 0.2254464328289032, "accuracy_val": 0.1834532469511032}, "26": {"accuracy_train": 0.1941964328289032, "accuracy_val": 0.1834532469511032}, "27": {"accuracy_train": 0.2142857313156128, "accuracy_val": 0.1834532469511032}, "28": {"accuracy_train": 0.2142857313156128, "accuracy_val": 0.18465228378772736}, "29": {"accuracy_train": 0.2544642984867096, "accuracy_val": 0.18465228378772736}, "30": {"accuracy_train": 0.1875000149011612, "accuracy_val": 0.18465228378772736}, "31": {"accuracy_train": 0.252232164144516, "accuracy_val": 0.18465228378772736}, "32": {"accuracy_train": 0.2343750149011612, "accuracy_val": 0.18465228378772736}, "33": {"accuracy_train": 0.2098214328289032, "accuracy_val": 0.1834532469511032}, "34": {"accuracy_train": 0.212053582072258, "accuracy_val": 0.18225419521331787}, "35": {"accuracy_train": 0.1919642984867096, "accuracy_val": 0.18225419521331787}, "36": {"accuracy_train": 0.2142857313156128, "accuracy_val": 0.18465228378772736}, "37": {"accuracy_train": 0.1986607164144516, "accuracy_val": 0.1834532469511032}, "38": {"accuracy_train": 0.1919642984867096, "accuracy_val": 0.1834532469511032}, "39": {"accuracy_train": 0.2410714328289032, "accuracy_val": 0.18225419521331787}, "40": {"accuracy_train": 0.2187500149011612, "accuracy_val": 0.1834532469511032}, "41": {"accuracy_train": 0.2165178656578064, "accuracy_val": 0.1834532469511032}, "42": {"accuracy_train": 0.2165178656578064, "accuracy_val": 0.1834532469511032}, "43": {"accuracy_train": 0.2566964328289032, "accuracy_val": 0.18225419521331787}, "44": {"accuracy_train": 0.2053571492433548, "accuracy_val": 0.1834532469511032}, "45": {"accuracy_train": 0.196428582072258, "accuracy_val": 0.1834532469511032}, "46": {"accuracy_train": 0.1941964328289032, "accuracy_val": 0.1834532469511032}, "47": {"accuracy_train": 0.1919642984867096, "accuracy_val": 0.18225419521331787}, "48": {"accuracy_train": 0.196428582072258, "accuracy_val": 0.1834532469511032}, "49": {"accuracy_train": 0.2142857313156128, "accuracy_val": 0.1834532469511032, "accuracy_test": 0.17985612154006958}}, "losses": {"0": {"loss_train": 810.5723037719727, "loss_val": 1493.3968091011047}, "1": {"loss_train": 804.5307998657227, "loss_val": 1492.9987435340881}, "2": {"loss_train": 811.1992340087891, "loss_val": 1495.357029914856}, "3": {"loss_train": 809.8336791992188, "loss_val": 1495.972547531128}, "4": {"loss_train": 801.4474029541016, "loss_val": 1499.4847683906555}, "5": {"loss_train": 806.7471542358398, "loss_val": 1504.8640584945679}, "6": {"loss_train": 806.2515106201172, "loss_val": 1514.4288005828857}, "7": {"loss_train": 813.8444061279297, "loss_val": 1525.200237751007}, "8": {"loss_train": 811.2518310546875, "loss_val": 1525.4530732631683}, "9": {"loss_train": 804.1471862792969, "loss_val": 1519.8356671333313}, "10": {"loss_train": 802.7742767333984, "loss_val": 1517.9897303581238}, "11": {"loss_train": 803.2080993652344, "loss_val": 1517.2215433120728}, "12": {"loss_train": 807.0717468261719, "loss_val": 1519.1567487716675}, "13": {"loss_train": 803.2686767578125, "loss_val": 1522.659131526947}, "14": {"loss_train": 802.716926574707, "loss_val": 1525.0156111717224}, "15": {"loss_train": 808.7432403564453, "loss_val": 1530.5184128284454}, "16": {"loss_train": 797.4288177490234, "loss_val": 1530.3975658416748}, "17": {"loss_train": 800.8866806030273, "loss_val": 1531.027901649475}, "18": {"loss_train": 797.4162826538086, "loss_val": 1531.6633014678955}, "19": {"loss_train": 804.2078094482422, "loss_val": 1532.2230215072632}, "20": {"loss_train": 792.2821197509766, "loss_val": 1531.4558086395264}, "21": {"loss_train": 802.0979995727539, "loss_val": 1531.219703912735}, "22": {"loss_train": 807.3087997436523, "loss_val": 1529.997817516327}, "23": {"loss_train": 795.7384033203125, "loss_val": 1530.5649099349976}, "24": {"loss_train": 802.2716064453125, "loss_val": 1530.606262922287}, "25": {"loss_train": 805.8966827392578, "loss_val": 1530.1193733215332}, "26": {"loss_train": 803.7727203369141, "loss_val": 1530.5105006694794}, "27": {"loss_train": 792.7233657836914, "loss_val": 1531.0076942443848}, "28": {"loss_train": 808.8500442504883, "loss_val": 1531.110984802246}, "29": {"loss_train": 788.4567947387695, "loss_val": 1531.3458831310272}, "30": {"loss_train": 803.9075088500977, "loss_val": 1530.8482694625854}, "31": {"loss_train": 799.7234039306641, "loss_val": 1528.78941488266}, "32": {"loss_train": 801.4323348999023, "loss_val": 1529.0923964977264}, "33": {"loss_train": 799.7437210083008, "loss_val": 1528.3274593353271}, "34": {"loss_train": 815.2927322387695, "loss_val": 1527.2112710475922}, "35": {"loss_train": 805.6511306762695, "loss_val": 1526.7664890289307}, "36": {"loss_train": 789.9871139526367, "loss_val": 1526.8377990722656}, "37": {"loss_train": 812.6279602050781, "loss_val": 1527.724925994873}, "38": {"loss_train": 811.6913604736328, "loss_val": 1528.2297925949097}, "39": {"loss_train": 799.3310928344727, "loss_val": 1526.5594449043274}, "40": {"loss_train": 799.8291549682617, "loss_val": 1527.7226114273071}, "41": {"loss_train": 801.378532409668, "loss_val": 1528.2850451469421}, "42": {"loss_train": 809.5854263305664, "loss_val": 1528.670262336731}, "43": {"loss_train": 794.7033233642578, "loss_val": 1527.7441010475159}, "44": {"loss_train": 797.8351440429688, "loss_val": 1528.1862287521362}, "45": {"loss_train": 808.1543350219727, "loss_val": 1528.0947153568268}, "46": {"loss_train": 805.6458740234375, "loss_val": 1527.550122976303}, "47": {"loss_train": 806.7029418945312, "loss_val": 1527.776249408722}, "48": {"loss_train": 804.4349670410156, "loss_val": 1527.7314248085022}, "49": {"loss_train": 802.958869934082, "loss_val": 1528.0001492500305, "loss_test": 501.0512068271637}}, "training_time_secs": 183.07815790176392}}, "lr_scheduler_configr": {"lr_scheduler_step_size": 30, "lr_scheduler_gamma": 0.02, "lr_scheduler_last_epoch": -1}}