{"k_fold_cv_id": "2022_12_12_09_30_11", "stats_type": "k_fold_cross_validation", "k_folds_cv_num_folds": 3, "data_logs": {"data_type": "waveform", "dataset_size": "s", "batch_size": 128, "num_samples_per_second": 8000, "num_channels": 1, "train_transforms": "[\"{'transform_name': 'StandardizeTransform', 'mean': -7.975741027621552e-05, 'std': 0.2950393557548523}\", 'RandomApply(\\n    p=1e-05\\n    PolarityInversion()\\n)', 'RandomApply(\\n    p=1e-05\\n    Noise()\\n)', 'RandomApply(\\n    p=1e-05\\n    Gain()\\n)', 'RandomApply(\\n    p=1e-05\\n    Delay()\\n)', {'p_boosting_factors': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1, 0.11, 0.12000000000000001, 0.13, 0.14, 0.15000000000000002, 0.16, 0.17, 0.18, 0.19, 0.2, 0.21000000000000002, 0.22, 0.23, 0.24000000000000002, 0.25, 0.25, 0.24846153846153846, 0.2469230769230769, 0.2453846153846154, 0.24384615384615385, 0.2423076923076923, 0.24076923076923076, 0.23923076923076922, 0.2376923076923077, 0.23615384615384616, 0.23461538461538461, 0.23307692307692307, 0.23153846153846153, 0.23, 0.22846153846153847, 0.22692307692307692, 0.22538461538461538, 0.22384615384615386, 0.22230769230769232, 0.22076923076923077, 0.21923076923076923, 0.21769230769230768, 0.21615384615384614, 0.21461538461538462, 0.21307692307692308, 0.21153846153846154, 0.21, 0.20846153846153848, 0.20692307692307693, 0.2053846153846154, 0.20384615384615384, 0.2023076923076923, 0.20076923076923076, 0.19923076923076924, 0.1976923076923077, 0.19615384615384615, 0.1946153846153846, 0.1930769230769231, 0.19153846153846155, 0.19, 0.18846153846153846, 0.18692307692307691, 0.18538461538461537, 0.18384615384615383, 0.1823076923076923, 0.18076923076923077, 0.17923076923076925, 0.1776923076923077, 0.17615384615384616, 0.17461538461538462, 0.17307692307692307, 0.17153846153846153, 0.16999999999999998, 0.16846153846153847, 0.16692307692307692, 0.16538461538461538, 0.16384615384615386, 0.16230769230769232, 0.16076923076923078, 0.15923076923076923, 0.1576923076923077, 0.15615384615384614, 0.1546153846153846, 0.15307692307692308, 0.15153846153846154, 0.15], 'epoch_steps': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98]}]"}, "optimizer_config": {"lr": 0.9, "momentum": 0.9, "weight_decay": 1e-06, "nesterov": true}, "model_setup": {"num_layers": 5, "kernel_sizes": [64, 32, 16, 8, 4], "strides": [3, 3, 2, 2, 2], "in_channels": 1, "num_filters": [18, 22, 22, 26, 6], "pool_sizes": [8, 8, 2, 2, 4], "pool_strides": [8, 8, 2, 4, 2], "dropout_p_conv": 0.0, "dropout_p_linear": 0.5}, "training_logs": {"0": {"train_id": "2022_12_12_09_30_11", "accuracies": {"0": {"accuracy_train": 0.2074652761220932, "accuracy_val": 0.1642685830593109}, "1": {"accuracy_train": 0.2916666567325592, "accuracy_val": 0.23621103167533875}, "2": {"accuracy_train": 0.3098958432674408, "accuracy_val": 0.2685851454734802}, "3": {"accuracy_train": 0.347222238779068, "accuracy_val": 0.33213430643081665}, "4": {"accuracy_train": 0.3524305522441864, "accuracy_val": 0.3285371661186218}, "5": {"accuracy_train": 0.3524305522441864, "accuracy_val": 0.32134294509887695}, "6": {"accuracy_train": 0.3680555522441864, "accuracy_val": 0.35611510276794434}, "7": {"accuracy_train": 0.3897569477558136, "accuracy_val": 0.38729017972946167}, "8": {"accuracy_train": 0.3897569477558136, "accuracy_val": 0.316546767950058}, "9": {"accuracy_train": 0.4105902910232544, "accuracy_val": 0.37050360441207886}, "10": {"accuracy_train": 0.401909738779068, "accuracy_val": 0.34532374143600464}, "11": {"accuracy_train": 0.3871527910232544, "accuracy_val": 0.371702641248703}, "12": {"accuracy_train": 0.4279513955116272, "accuracy_val": 0.3824940025806427}, "13": {"accuracy_train": 0.4270833432674408, "accuracy_val": 0.35371702909469604}, "14": {"accuracy_train": 0.453125, "accuracy_val": 0.37290167808532715}, "15": {"accuracy_train": 0.4461805522441864, "accuracy_val": 0.4016786515712738}, "16": {"accuracy_train": 0.4626736044883728, "accuracy_val": 0.3860911428928375}, "17": {"accuracy_train": 0.4279513955116272, "accuracy_val": 0.358513206243515}, "18": {"accuracy_train": 0.4435763955116272, "accuracy_val": 0.3884892165660858}, "19": {"accuracy_train": 0.4314236044883728, "accuracy_val": 0.3201438784599304}, "20": {"accuracy_train": 0.4418402910232544, "accuracy_val": 0.35371702909469604}, "21": {"accuracy_train": 0.4357638955116272, "accuracy_val": 0.3549160659313202}, "22": {"accuracy_train": 0.4184027910232544, "accuracy_val": 0.3860911428928375}, "23": {"accuracy_train": 0.4114583432674408, "accuracy_val": 0.3357314169406891}, "24": {"accuracy_train": 0.433159738779068, "accuracy_val": 0.3141486942768097}, "25": {"accuracy_train": 0.4279513955116272, "accuracy_val": 0.3752997815608978}, "26": {"accuracy_train": 0.4279513955116272, "accuracy_val": 0.3752997815608978}, "27": {"accuracy_train": 0.421875, "accuracy_val": 0.3860911428928375}, "28": {"accuracy_train": 0.4522569477558136, "accuracy_val": 0.41966426372528076}, "29": {"accuracy_train": 0.4557291567325592, "accuracy_val": 0.40047961473464966}, "30": {"accuracy_train": 0.4635416567325592, "accuracy_val": 0.39448443055152893}, "31": {"accuracy_train": 0.4305555522441864, "accuracy_val": 0.4100719392299652}, "32": {"accuracy_train": 0.4583333432674408, "accuracy_val": 0.4208633303642273}, "33": {"accuracy_train": 0.4748263955116272, "accuracy_val": 0.41127100586891174}, "34": {"accuracy_train": 0.4427083432674408, "accuracy_val": 0.4148681163787842}, "35": {"accuracy_train": 0.4765625, "accuracy_val": 0.41366907954216003}, "36": {"accuracy_train": 0.4809027910232544, "accuracy_val": 0.426858514547348}, "37": {"accuracy_train": 0.4592013955116272, "accuracy_val": 0.42805755138397217}, "38": {"accuracy_train": 0.4887152910232544, "accuracy_val": 0.43045565485954285}, "39": {"accuracy_train": 0.4921875, "accuracy_val": 0.41127100586891174}, "40": {"accuracy_train": 0.5008680820465088, "accuracy_val": 0.41127100586891174}, "41": {"accuracy_train": 0.4826388955116272, "accuracy_val": 0.41966426372528076}, "42": {"accuracy_train": 0.487847238779068, "accuracy_val": 0.41966426372528076}, "43": {"accuracy_train": 0.4852430522441864, "accuracy_val": 0.42206236720085144}, "44": {"accuracy_train": 0.4939236044883728, "accuracy_val": 0.4232614040374756}, "45": {"accuracy_train": 0.5034722089767456, "accuracy_val": 0.4184652268886566}, "46": {"accuracy_train": 0.4861111044883728, "accuracy_val": 0.41726619005203247}, "47": {"accuracy_train": 0.5026041865348816, "accuracy_val": 0.4184652268886566}, "48": {"accuracy_train": 0.5026041865348816, "accuracy_val": 0.4340527653694153}, "49": {"accuracy_train": 0.4947916567325592, "accuracy_val": 0.4292566180229187}, "50": {"accuracy_train": 0.4791666567325592, "accuracy_val": 0.4232614040374756}, "51": {"accuracy_train": 0.506944477558136, "accuracy_val": 0.42446044087409973}, "52": {"accuracy_train": 0.4965277910232544, "accuracy_val": 0.4232614040374756}, "53": {"accuracy_train": 0.5078125, "accuracy_val": 0.431654691696167}, "54": {"accuracy_train": 0.4965277910232544, "accuracy_val": 0.44124701619148254}, "55": {"accuracy_train": 0.495659738779068, "accuracy_val": 0.426858514547348}, "56": {"accuracy_train": 0.5243055820465088, "accuracy_val": 0.41726619005203247}, "57": {"accuracy_train": 0.5373263955116272, "accuracy_val": 0.41966426372528076}, "58": {"accuracy_train": 0.4852430522441864, "accuracy_val": 0.4184652268886566}, "59": {"accuracy_train": 0.5182291865348816, "accuracy_val": 0.40887290239334106}, "60": {"accuracy_train": 0.5451388955116272, "accuracy_val": 0.4208633303642273}, "61": {"accuracy_train": 0.5138888955116272, "accuracy_val": 0.44124701619148254}, "62": {"accuracy_train": 0.506944477558136, "accuracy_val": 0.4340527653694153}, "63": {"accuracy_train": 0.5208333134651184, "accuracy_val": 0.41966426372528076}, "64": {"accuracy_train": 0.5295138955116272, "accuracy_val": 0.4208633303642273}, "65": {"accuracy_train": 0.5199652910232544, "accuracy_val": 0.4208633303642273}, "66": {"accuracy_train": 0.5199652910232544, "accuracy_val": 0.44124701619148254}, "67": {"accuracy_train": 0.546006977558136, "accuracy_val": 0.4208633303642273}, "68": {"accuracy_train": 0.5251736044883728, "accuracy_val": 0.41366907954216003}, "69": {"accuracy_train": 0.5260416865348816, "accuracy_val": 0.42805755138397217}, "70": {"accuracy_train": 0.5442708134651184, "accuracy_val": 0.43045565485954285}, "71": {"accuracy_train": 0.5442708134651184, "accuracy_val": 0.43285372853279114}, "72": {"accuracy_train": 0.5373263955116272, "accuracy_val": 0.431654691696167}, "73": {"accuracy_train": 0.5355902910232544, "accuracy_val": 0.43045565485954285}, "74": {"accuracy_train": 0.5364583134651184, "accuracy_val": 0.4148681163787842}, "75": {"accuracy_train": 0.5486111044883728, "accuracy_val": 0.41366907954216003}, "76": {"accuracy_train": 0.5234375, "accuracy_val": 0.4292566180229187}, "77": {"accuracy_train": 0.5407986044883728, "accuracy_val": 0.426858514547348}, "78": {"accuracy_train": 0.5520833134651184, "accuracy_val": 0.43045565485954285}, "79": {"accuracy_train": 0.5425347089767456, "accuracy_val": 0.39808154106140137}, "80": {"accuracy_train": 0.5373263955116272, "accuracy_val": 0.41726619005203247}, "81": {"accuracy_train": 0.5477430820465088, "accuracy_val": 0.41726619005203247}, "82": {"accuracy_train": 0.5416666865348816, "accuracy_val": 0.40887290239334106}, "83": {"accuracy_train": 0.546006977558136, "accuracy_val": 0.4292566180229187}, "84": {"accuracy_train": 0.5503472089767456, "accuracy_val": 0.4208633303642273}, "85": {"accuracy_train": 0.5442708134651184, "accuracy_val": 0.40047961473464966}, "86": {"accuracy_train": 0.5998263955116272, "accuracy_val": 0.431654691696167}, "87": {"accuracy_train": 0.5451388955116272, "accuracy_val": 0.4376498758792877}, "88": {"accuracy_train": 0.5737847089767456, "accuracy_val": 0.41966426372528076}, "89": {"accuracy_train": 0.5590277910232544, "accuracy_val": 0.41366907954216003}, "90": {"accuracy_train": 0.5564236044883728, "accuracy_val": 0.4208633303642273}, "91": {"accuracy_train": 0.553819477558136, "accuracy_val": 0.4148681163787842}, "92": {"accuracy_train": 0.5894097089767456, "accuracy_val": 0.42446044087409973}, "93": {"accuracy_train": 0.5642361044883728, "accuracy_val": 0.39208632707595825}, "94": {"accuracy_train": 0.5651041865348816, "accuracy_val": 0.4184652268886566}, "95": {"accuracy_train": 0.5642361044883728, "accuracy_val": 0.4160671532154083}, "96": {"accuracy_train": 0.5520833134651184, "accuracy_val": 0.41366907954216003}, "97": {"accuracy_train": 0.5972222089767456, "accuracy_val": 0.4184652268886566}, "98": {"accuracy_train": 0.6067708134651184, "accuracy_val": 0.4160671532154083, "accuracy_test": 0.3741007149219513}}, "losses": {"0": {"loss_train": 2043.0182189941406, "loss_val": 1514.9439535140991}, "1": {"loss_train": 1977.1363067626953, "loss_val": 1426.2525312900543}, "2": {"loss_train": 1943.6351470947266, "loss_val": 1388.2518515586853}, "3": {"loss_train": 1913.7293548583984, "loss_val": 1375.428894996643}, "4": {"loss_train": 1902.1924438476562, "loss_val": 1368.6466748714447}, "5": {"loss_train": 1896.579330444336, "loss_val": 1362.0858988761902}, "6": {"loss_train": 1878.5438995361328, "loss_val": 1355.827702999115}, "7": {"loss_train": 1865.2914428710938, "loss_val": 1351.219046831131}, "8": {"loss_train": 1857.4593200683594, "loss_val": 1392.2153084278107}, "9": {"loss_train": 1842.8453063964844, "loss_val": 1354.0910527706146}, "10": {"loss_train": 1844.6280212402344, "loss_val": 1361.1933398246765}, "11": {"loss_train": 1836.962142944336, "loss_val": 1370.938404083252}, "12": {"loss_train": 1822.2792358398438, "loss_val": 1339.7167069911957}, "13": {"loss_train": 1787.1658020019531, "loss_val": 1359.793921470642}, "14": {"loss_train": 1794.4849853515625, "loss_val": 1333.071900844574}, "15": {"loss_train": 1778.4716033935547, "loss_val": 1348.9510667324066}, "16": {"loss_train": 1778.281234741211, "loss_val": 1349.3346371650696}, "17": {"loss_train": 1798.4136657714844, "loss_val": 1382.1664922237396}, "18": {"loss_train": 1799.193618774414, "loss_val": 1322.928451538086}, "19": {"loss_train": 1797.6883544921875, "loss_val": 1361.5618476867676}, "20": {"loss_train": 1785.9454498291016, "loss_val": 1352.1930181980133}, "21": {"loss_train": 1789.2448272705078, "loss_val": 1394.6707203388214}, "22": {"loss_train": 1797.9645080566406, "loss_val": 1363.4069883823395}, "23": {"loss_train": 1802.1742858886719, "loss_val": 1383.8532276153564}, "24": {"loss_train": 1791.735595703125, "loss_val": 1398.100881099701}, "25": {"loss_train": 1798.940689086914, "loss_val": 1367.8336942195892}, "26": {"loss_train": 1807.6400756835938, "loss_val": 1345.9463829994202}, "27": {"loss_train": 1797.4690704345703, "loss_val": 1325.7633578777313}, "28": {"loss_train": 1775.6486053466797, "loss_val": 1314.0690569877625}, "29": {"loss_train": 1757.4376678466797, "loss_val": 1320.1214921474457}, "30": {"loss_train": 1769.9734802246094, "loss_val": 1325.934653520584}, "31": {"loss_train": 1778.23681640625, "loss_val": 1327.5887968540192}, "32": {"loss_train": 1759.1884002685547, "loss_val": 1326.0227513313293}, "33": {"loss_train": 1753.9517822265625, "loss_val": 1322.1898174285889}, "34": {"loss_train": 1768.3244323730469, "loss_val": 1323.175615310669}, "35": {"loss_train": 1734.0350189208984, "loss_val": 1327.0113682746887}, "36": {"loss_train": 1749.4951782226562, "loss_val": 1316.8501596450806}, "37": {"loss_train": 1743.8333435058594, "loss_val": 1313.9744007587433}, "38": {"loss_train": 1738.3594512939453, "loss_val": 1314.1938281059265}, "39": {"loss_train": 1723.79736328125, "loss_val": 1318.221732378006}, "40": {"loss_train": 1737.8507843017578, "loss_val": 1315.9039521217346}, "41": {"loss_train": 1735.8253326416016, "loss_val": 1313.485762834549}, "42": {"loss_train": 1720.6871795654297, "loss_val": 1316.6235826015472}, "43": {"loss_train": 1724.3112487792969, "loss_val": 1314.8438510894775}, "44": {"loss_train": 1731.7240600585938, "loss_val": 1316.5916483402252}, "45": {"loss_train": 1727.8987274169922, "loss_val": 1319.5472645759583}, "46": {"loss_train": 1718.4666748046875, "loss_val": 1317.5220384597778}, "47": {"loss_train": 1724.2423706054688, "loss_val": 1318.7541103363037}, "48": {"loss_train": 1716.1801300048828, "loss_val": 1313.7050971984863}, "49": {"loss_train": 1718.9352111816406, "loss_val": 1317.395494222641}, "50": {"loss_train": 1724.803207397461, "loss_val": 1311.7171745300293}, "51": {"loss_train": 1711.048110961914, "loss_val": 1309.828536748886}, "52": {"loss_train": 1735.4835357666016, "loss_val": 1309.9745943546295}, "53": {"loss_train": 1715.0181732177734, "loss_val": 1320.65940451622}, "54": {"loss_train": 1723.232894897461, "loss_val": 1313.2076354026794}, "55": {"loss_train": 1711.5552368164062, "loss_val": 1317.279839515686}, "56": {"loss_train": 1709.4320983886719, "loss_val": 1318.311862707138}, "57": {"loss_train": 1692.8381652832031, "loss_val": 1321.6121847629547}, "58": {"loss_train": 1714.2434387207031, "loss_val": 1305.6715002059937}, "59": {"loss_train": 1688.2604370117188, "loss_val": 1330.8896782398224}, "60": {"loss_train": 1689.8236999511719, "loss_val": 1318.4001157283783}, "61": {"loss_train": 1704.8384094238281, "loss_val": 1312.477131843567}, "62": {"loss_train": 1707.630859375, "loss_val": 1305.247364282608}, "63": {"loss_train": 1690.675064086914, "loss_val": 1318.088320016861}, "64": {"loss_train": 1685.237060546875, "loss_val": 1316.0770666599274}, "65": {"loss_train": 1702.4862670898438, "loss_val": 1313.586104631424}, "66": {"loss_train": 1691.6018676757812, "loss_val": 1307.3085074424744}, "67": {"loss_train": 1685.919921875, "loss_val": 1312.5200686454773}, "68": {"loss_train": 1689.5050506591797, "loss_val": 1314.8274915218353}, "69": {"loss_train": 1701.7810974121094, "loss_val": 1317.7652192115784}, "70": {"loss_train": 1680.0329284667969, "loss_val": 1309.6842668056488}, "71": {"loss_train": 1680.7052612304688, "loss_val": 1314.5806777477264}, "72": {"loss_train": 1670.90185546875, "loss_val": 1309.9017157554626}, "73": {"loss_train": 1666.9893341064453, "loss_val": 1311.5224239826202}, "74": {"loss_train": 1678.2284698486328, "loss_val": 1319.8673231601715}, "75": {"loss_train": 1676.51416015625, "loss_val": 1323.604041337967}, "76": {"loss_train": 1705.1142120361328, "loss_val": 1317.0031671524048}, "77": {"loss_train": 1689.3825225830078, "loss_val": 1319.8116295337677}, "78": {"loss_train": 1681.9617004394531, "loss_val": 1303.4781506061554}, "79": {"loss_train": 1672.5786437988281, "loss_val": 1342.6354911327362}, "80": {"loss_train": 1682.1279296875, "loss_val": 1317.6026339530945}, "81": {"loss_train": 1664.6276092529297, "loss_val": 1323.1602957248688}, "82": {"loss_train": 1663.4107513427734, "loss_val": 1313.731588602066}, "83": {"loss_train": 1651.2703552246094, "loss_val": 1309.7198181152344}, "84": {"loss_train": 1654.1474914550781, "loss_val": 1320.4679517745972}, "85": {"loss_train": 1669.8367614746094, "loss_val": 1330.0672492980957}, "86": {"loss_train": 1635.2425842285156, "loss_val": 1317.494857788086}, "87": {"loss_train": 1660.4592742919922, "loss_val": 1304.3161990642548}, "88": {"loss_train": 1650.3482513427734, "loss_val": 1304.5251309871674}, "89": {"loss_train": 1660.0272521972656, "loss_val": 1324.1136102676392}, "90": {"loss_train": 1653.6492462158203, "loss_val": 1319.3858692646027}, "91": {"loss_train": 1656.5067138671875, "loss_val": 1323.8031017780304}, "92": {"loss_train": 1636.2180480957031, "loss_val": 1312.2113192081451}, "93": {"loss_train": 1647.438720703125, "loss_val": 1337.597915172577}, "94": {"loss_train": 1652.860107421875, "loss_val": 1316.343759059906}, "95": {"loss_train": 1640.5553131103516, "loss_val": 1320.1069025993347}, "96": {"loss_train": 1659.022216796875, "loss_val": 1314.0389313697815}, "97": {"loss_train": 1638.6612396240234, "loss_val": 1310.2933459281921}, "98": {"loss_train": 1617.4666900634766, "loss_val": 1309.5043835639954, "loss_test": 444.67195200920105}}, "training_time_secs": 463.5768370628357}, "1": {"train_id": "2022_12_12_09_30_11", "accuracies": {"0": {"accuracy_train": 0.2074652761220932, "accuracy_val": 0.1642685830593109}, "1": {"accuracy_train": 0.2916666567325592, "accuracy_val": 0.23621103167533875}, "2": {"accuracy_train": 0.3098958432674408, "accuracy_val": 0.2685851454734802}, "3": {"accuracy_train": 0.347222238779068, "accuracy_val": 0.33213430643081665}, "4": {"accuracy_train": 0.3524305522441864, "accuracy_val": 0.3285371661186218}, "5": {"accuracy_train": 0.3524305522441864, "accuracy_val": 0.32134294509887695}, "6": {"accuracy_train": 0.3680555522441864, "accuracy_val": 0.35611510276794434}, "7": {"accuracy_train": 0.3897569477558136, "accuracy_val": 0.38729017972946167}, "8": {"accuracy_train": 0.3897569477558136, "accuracy_val": 0.316546767950058}, "9": {"accuracy_train": 0.4105902910232544, "accuracy_val": 0.37050360441207886}, "10": {"accuracy_train": 0.401909738779068, "accuracy_val": 0.34532374143600464}, "11": {"accuracy_train": 0.3871527910232544, "accuracy_val": 0.371702641248703}, "12": {"accuracy_train": 0.4279513955116272, "accuracy_val": 0.3824940025806427}, "13": {"accuracy_train": 0.4270833432674408, "accuracy_val": 0.35371702909469604}, "14": {"accuracy_train": 0.453125, "accuracy_val": 0.37290167808532715}, "15": {"accuracy_train": 0.4461805522441864, "accuracy_val": 0.4016786515712738}, "16": {"accuracy_train": 0.4626736044883728, "accuracy_val": 0.3860911428928375}, "17": {"accuracy_train": 0.4279513955116272, "accuracy_val": 0.358513206243515}, "18": {"accuracy_train": 0.4435763955116272, "accuracy_val": 0.3884892165660858}, "19": {"accuracy_train": 0.4314236044883728, "accuracy_val": 0.3201438784599304}, "20": {"accuracy_train": 0.4418402910232544, "accuracy_val": 0.35371702909469604}, "21": {"accuracy_train": 0.4357638955116272, "accuracy_val": 0.3549160659313202}, "22": {"accuracy_train": 0.4184027910232544, "accuracy_val": 0.3860911428928375}, "23": {"accuracy_train": 0.4114583432674408, "accuracy_val": 0.3357314169406891}, "24": {"accuracy_train": 0.433159738779068, "accuracy_val": 0.3141486942768097}, "25": {"accuracy_train": 0.4279513955116272, "accuracy_val": 0.3752997815608978}, "26": {"accuracy_train": 0.4279513955116272, "accuracy_val": 0.3752997815608978}, "27": {"accuracy_train": 0.421875, "accuracy_val": 0.3860911428928375}, "28": {"accuracy_train": 0.4522569477558136, "accuracy_val": 0.41966426372528076}, "29": {"accuracy_train": 0.4557291567325592, "accuracy_val": 0.40047961473464966}, "30": {"accuracy_train": 0.4635416567325592, "accuracy_val": 0.39448443055152893}, "31": {"accuracy_train": 0.4305555522441864, "accuracy_val": 0.4100719392299652}, "32": {"accuracy_train": 0.4583333432674408, "accuracy_val": 0.4208633303642273}, "33": {"accuracy_train": 0.4748263955116272, "accuracy_val": 0.41127100586891174}, "34": {"accuracy_train": 0.4427083432674408, "accuracy_val": 0.4148681163787842}, "35": {"accuracy_train": 0.4765625, "accuracy_val": 0.41366907954216003}, "36": {"accuracy_train": 0.4809027910232544, "accuracy_val": 0.426858514547348}, "37": {"accuracy_train": 0.4592013955116272, "accuracy_val": 0.42805755138397217}, "38": {"accuracy_train": 0.4887152910232544, "accuracy_val": 0.43045565485954285}, "39": {"accuracy_train": 0.4921875, "accuracy_val": 0.41127100586891174}, "40": {"accuracy_train": 0.5008680820465088, "accuracy_val": 0.41127100586891174}, "41": {"accuracy_train": 0.4826388955116272, "accuracy_val": 0.41966426372528076}, "42": {"accuracy_train": 0.487847238779068, "accuracy_val": 0.41966426372528076}, "43": {"accuracy_train": 0.4852430522441864, "accuracy_val": 0.42206236720085144}, "44": {"accuracy_train": 0.4939236044883728, "accuracy_val": 0.4232614040374756}, "45": {"accuracy_train": 0.5034722089767456, "accuracy_val": 0.4184652268886566}, "46": {"accuracy_train": 0.4861111044883728, "accuracy_val": 0.41726619005203247}, "47": {"accuracy_train": 0.5026041865348816, "accuracy_val": 0.4184652268886566}, "48": {"accuracy_train": 0.5026041865348816, "accuracy_val": 0.4340527653694153}, "49": {"accuracy_train": 0.4947916567325592, "accuracy_val": 0.4292566180229187}, "50": {"accuracy_train": 0.4791666567325592, "accuracy_val": 0.4232614040374756}, "51": {"accuracy_train": 0.506944477558136, "accuracy_val": 0.42446044087409973}, "52": {"accuracy_train": 0.4965277910232544, "accuracy_val": 0.4232614040374756}, "53": {"accuracy_train": 0.5078125, "accuracy_val": 0.431654691696167}, "54": {"accuracy_train": 0.4965277910232544, "accuracy_val": 0.44124701619148254}, "55": {"accuracy_train": 0.495659738779068, "accuracy_val": 0.426858514547348}, "56": {"accuracy_train": 0.5243055820465088, "accuracy_val": 0.41726619005203247}, "57": {"accuracy_train": 0.5373263955116272, "accuracy_val": 0.41966426372528076}, "58": {"accuracy_train": 0.4852430522441864, "accuracy_val": 0.4184652268886566}, "59": {"accuracy_train": 0.5182291865348816, "accuracy_val": 0.40887290239334106}, "60": {"accuracy_train": 0.5451388955116272, "accuracy_val": 0.4208633303642273}, "61": {"accuracy_train": 0.5138888955116272, "accuracy_val": 0.44124701619148254}, "62": {"accuracy_train": 0.506944477558136, "accuracy_val": 0.4340527653694153}, "63": {"accuracy_train": 0.5208333134651184, "accuracy_val": 0.41966426372528076}, "64": {"accuracy_train": 0.5295138955116272, "accuracy_val": 0.4208633303642273}, "65": {"accuracy_train": 0.5199652910232544, "accuracy_val": 0.4208633303642273}, "66": {"accuracy_train": 0.5199652910232544, "accuracy_val": 0.44124701619148254}, "67": {"accuracy_train": 0.546006977558136, "accuracy_val": 0.4208633303642273}, "68": {"accuracy_train": 0.5251736044883728, "accuracy_val": 0.41366907954216003}, "69": {"accuracy_train": 0.5260416865348816, "accuracy_val": 0.42805755138397217}, "70": {"accuracy_train": 0.5442708134651184, "accuracy_val": 0.43045565485954285}, "71": {"accuracy_train": 0.5442708134651184, "accuracy_val": 0.43285372853279114}, "72": {"accuracy_train": 0.5373263955116272, "accuracy_val": 0.431654691696167}, "73": {"accuracy_train": 0.5355902910232544, "accuracy_val": 0.43045565485954285}, "74": {"accuracy_train": 0.5364583134651184, "accuracy_val": 0.4148681163787842}, "75": {"accuracy_train": 0.5486111044883728, "accuracy_val": 0.41366907954216003}, "76": {"accuracy_train": 0.5234375, "accuracy_val": 0.4292566180229187}, "77": {"accuracy_train": 0.5407986044883728, "accuracy_val": 0.426858514547348}, "78": {"accuracy_train": 0.5520833134651184, "accuracy_val": 0.43045565485954285}, "79": {"accuracy_train": 0.5425347089767456, "accuracy_val": 0.39808154106140137}, "80": {"accuracy_train": 0.5373263955116272, "accuracy_val": 0.41726619005203247}, "81": {"accuracy_train": 0.5477430820465088, "accuracy_val": 0.41726619005203247}, "82": {"accuracy_train": 0.5416666865348816, "accuracy_val": 0.40887290239334106}, "83": {"accuracy_train": 0.546006977558136, "accuracy_val": 0.4292566180229187}, "84": {"accuracy_train": 0.5503472089767456, "accuracy_val": 0.4208633303642273}, "85": {"accuracy_train": 0.5442708134651184, "accuracy_val": 0.40047961473464966}, "86": {"accuracy_train": 0.5998263955116272, "accuracy_val": 0.431654691696167}, "87": {"accuracy_train": 0.5451388955116272, "accuracy_val": 0.4376498758792877}, "88": {"accuracy_train": 0.5737847089767456, "accuracy_val": 0.41966426372528076}, "89": {"accuracy_train": 0.5590277910232544, "accuracy_val": 0.41366907954216003}, "90": {"accuracy_train": 0.5564236044883728, "accuracy_val": 0.4208633303642273}, "91": {"accuracy_train": 0.553819477558136, "accuracy_val": 0.4148681163787842}, "92": {"accuracy_train": 0.5894097089767456, "accuracy_val": 0.42446044087409973}, "93": {"accuracy_train": 0.5642361044883728, "accuracy_val": 0.39208632707595825}, "94": {"accuracy_train": 0.5651041865348816, "accuracy_val": 0.4184652268886566}, "95": {"accuracy_train": 0.5642361044883728, "accuracy_val": 0.4160671532154083}, "96": {"accuracy_train": 0.5520833134651184, "accuracy_val": 0.41366907954216003}, "97": {"accuracy_train": 0.5972222089767456, "accuracy_val": 0.4184652268886566}, "98": {"accuracy_train": 0.6067708134651184, "accuracy_val": 0.4160671532154083, "accuracy_test": 0.3741007149219513}}, "losses": {"0": {"loss_train": 2043.0182189941406, "loss_val": 1514.9439535140991}, "1": {"loss_train": 1977.1363067626953, "loss_val": 1426.2525312900543}, "2": {"loss_train": 1943.6351470947266, "loss_val": 1388.2518515586853}, "3": {"loss_train": 1913.7293548583984, "loss_val": 1375.428894996643}, "4": {"loss_train": 1902.1924438476562, "loss_val": 1368.6466748714447}, "5": {"loss_train": 1896.579330444336, "loss_val": 1362.0858988761902}, "6": {"loss_train": 1878.5438995361328, "loss_val": 1355.827702999115}, "7": {"loss_train": 1865.2914428710938, "loss_val": 1351.219046831131}, "8": {"loss_train": 1857.4593200683594, "loss_val": 1392.2153084278107}, "9": {"loss_train": 1842.8453063964844, "loss_val": 1354.0910527706146}, "10": {"loss_train": 1844.6280212402344, "loss_val": 1361.1933398246765}, "11": {"loss_train": 1836.962142944336, "loss_val": 1370.938404083252}, "12": {"loss_train": 1822.2792358398438, "loss_val": 1339.7167069911957}, "13": {"loss_train": 1787.1658020019531, "loss_val": 1359.793921470642}, "14": {"loss_train": 1794.4849853515625, "loss_val": 1333.071900844574}, "15": {"loss_train": 1778.4716033935547, "loss_val": 1348.9510667324066}, "16": {"loss_train": 1778.281234741211, "loss_val": 1349.3346371650696}, "17": {"loss_train": 1798.4136657714844, "loss_val": 1382.1664922237396}, "18": {"loss_train": 1799.193618774414, "loss_val": 1322.928451538086}, "19": {"loss_train": 1797.6883544921875, "loss_val": 1361.5618476867676}, "20": {"loss_train": 1785.9454498291016, "loss_val": 1352.1930181980133}, "21": {"loss_train": 1789.2448272705078, "loss_val": 1394.6707203388214}, "22": {"loss_train": 1797.9645080566406, "loss_val": 1363.4069883823395}, "23": {"loss_train": 1802.1742858886719, "loss_val": 1383.8532276153564}, "24": {"loss_train": 1791.735595703125, "loss_val": 1398.100881099701}, "25": {"loss_train": 1798.940689086914, "loss_val": 1367.8336942195892}, "26": {"loss_train": 1807.6400756835938, "loss_val": 1345.9463829994202}, "27": {"loss_train": 1797.4690704345703, "loss_val": 1325.7633578777313}, "28": {"loss_train": 1775.6486053466797, "loss_val": 1314.0690569877625}, "29": {"loss_train": 1757.4376678466797, "loss_val": 1320.1214921474457}, "30": {"loss_train": 1769.9734802246094, "loss_val": 1325.934653520584}, "31": {"loss_train": 1778.23681640625, "loss_val": 1327.5887968540192}, "32": {"loss_train": 1759.1884002685547, "loss_val": 1326.0227513313293}, "33": {"loss_train": 1753.9517822265625, "loss_val": 1322.1898174285889}, "34": {"loss_train": 1768.3244323730469, "loss_val": 1323.175615310669}, "35": {"loss_train": 1734.0350189208984, "loss_val": 1327.0113682746887}, "36": {"loss_train": 1749.4951782226562, "loss_val": 1316.8501596450806}, "37": {"loss_train": 1743.8333435058594, "loss_val": 1313.9744007587433}, "38": {"loss_train": 1738.3594512939453, "loss_val": 1314.1938281059265}, "39": {"loss_train": 1723.79736328125, "loss_val": 1318.221732378006}, "40": {"loss_train": 1737.8507843017578, "loss_val": 1315.9039521217346}, "41": {"loss_train": 1735.8253326416016, "loss_val": 1313.485762834549}, "42": {"loss_train": 1720.6871795654297, "loss_val": 1316.6235826015472}, "43": {"loss_train": 1724.3112487792969, "loss_val": 1314.8438510894775}, "44": {"loss_train": 1731.7240600585938, "loss_val": 1316.5916483402252}, "45": {"loss_train": 1727.8987274169922, "loss_val": 1319.5472645759583}, "46": {"loss_train": 1718.4666748046875, "loss_val": 1317.5220384597778}, "47": {"loss_train": 1724.2423706054688, "loss_val": 1318.7541103363037}, "48": {"loss_train": 1716.1801300048828, "loss_val": 1313.7050971984863}, "49": {"loss_train": 1718.9352111816406, "loss_val": 1317.395494222641}, "50": {"loss_train": 1724.803207397461, "loss_val": 1311.7171745300293}, "51": {"loss_train": 1711.048110961914, "loss_val": 1309.828536748886}, "52": {"loss_train": 1735.4835357666016, "loss_val": 1309.9745943546295}, "53": {"loss_train": 1715.0181732177734, "loss_val": 1320.65940451622}, "54": {"loss_train": 1723.232894897461, "loss_val": 1313.2076354026794}, "55": {"loss_train": 1711.5552368164062, "loss_val": 1317.279839515686}, "56": {"loss_train": 1709.4320983886719, "loss_val": 1318.311862707138}, "57": {"loss_train": 1692.8381652832031, "loss_val": 1321.6121847629547}, "58": {"loss_train": 1714.2434387207031, "loss_val": 1305.6715002059937}, "59": {"loss_train": 1688.2604370117188, "loss_val": 1330.8896782398224}, "60": {"loss_train": 1689.8236999511719, "loss_val": 1318.4001157283783}, "61": {"loss_train": 1704.8384094238281, "loss_val": 1312.477131843567}, "62": {"loss_train": 1707.630859375, "loss_val": 1305.247364282608}, "63": {"loss_train": 1690.675064086914, "loss_val": 1318.088320016861}, "64": {"loss_train": 1685.237060546875, "loss_val": 1316.0770666599274}, "65": {"loss_train": 1702.4862670898438, "loss_val": 1313.586104631424}, "66": {"loss_train": 1691.6018676757812, "loss_val": 1307.3085074424744}, "67": {"loss_train": 1685.919921875, "loss_val": 1312.5200686454773}, "68": {"loss_train": 1689.5050506591797, "loss_val": 1314.8274915218353}, "69": {"loss_train": 1701.7810974121094, "loss_val": 1317.7652192115784}, "70": {"loss_train": 1680.0329284667969, "loss_val": 1309.6842668056488}, "71": {"loss_train": 1680.7052612304688, "loss_val": 1314.5806777477264}, "72": {"loss_train": 1670.90185546875, "loss_val": 1309.9017157554626}, "73": {"loss_train": 1666.9893341064453, "loss_val": 1311.5224239826202}, "74": {"loss_train": 1678.2284698486328, "loss_val": 1319.8673231601715}, "75": {"loss_train": 1676.51416015625, "loss_val": 1323.604041337967}, "76": {"loss_train": 1705.1142120361328, "loss_val": 1317.0031671524048}, "77": {"loss_train": 1689.3825225830078, "loss_val": 1319.8116295337677}, "78": {"loss_train": 1681.9617004394531, "loss_val": 1303.4781506061554}, "79": {"loss_train": 1672.5786437988281, "loss_val": 1342.6354911327362}, "80": {"loss_train": 1682.1279296875, "loss_val": 1317.6026339530945}, "81": {"loss_train": 1664.6276092529297, "loss_val": 1323.1602957248688}, "82": {"loss_train": 1663.4107513427734, "loss_val": 1313.731588602066}, "83": {"loss_train": 1651.2703552246094, "loss_val": 1309.7198181152344}, "84": {"loss_train": 1654.1474914550781, "loss_val": 1320.4679517745972}, "85": {"loss_train": 1669.8367614746094, "loss_val": 1330.0672492980957}, "86": {"loss_train": 1635.2425842285156, "loss_val": 1317.494857788086}, "87": {"loss_train": 1660.4592742919922, "loss_val": 1304.3161990642548}, "88": {"loss_train": 1650.3482513427734, "loss_val": 1304.5251309871674}, "89": {"loss_train": 1660.0272521972656, "loss_val": 1324.1136102676392}, "90": {"loss_train": 1653.6492462158203, "loss_val": 1319.3858692646027}, "91": {"loss_train": 1656.5067138671875, "loss_val": 1323.8031017780304}, "92": {"loss_train": 1636.2180480957031, "loss_val": 1312.2113192081451}, "93": {"loss_train": 1647.438720703125, "loss_val": 1337.597915172577}, "94": {"loss_train": 1652.860107421875, "loss_val": 1316.343759059906}, "95": {"loss_train": 1640.5553131103516, "loss_val": 1320.1069025993347}, "96": {"loss_train": 1659.022216796875, "loss_val": 1314.0389313697815}, "97": {"loss_train": 1638.6612396240234, "loss_val": 1310.2933459281921}, "98": {"loss_train": 1617.4666900634766, "loss_val": 1309.5043835639954, "loss_test": 444.67195200920105}}, "training_time_secs": 463.5768370628357}, "2": {"train_id": "2022_12_12_09_30_11", "accuracies": {"0": {"accuracy_train": 0.2074652761220932, "accuracy_val": 0.1642685830593109}, "1": {"accuracy_train": 0.2916666567325592, "accuracy_val": 0.23621103167533875}, "2": {"accuracy_train": 0.3098958432674408, "accuracy_val": 0.2685851454734802}, "3": {"accuracy_train": 0.347222238779068, "accuracy_val": 0.33213430643081665}, "4": {"accuracy_train": 0.3524305522441864, "accuracy_val": 0.3285371661186218}, "5": {"accuracy_train": 0.3524305522441864, "accuracy_val": 0.32134294509887695}, "6": {"accuracy_train": 0.3680555522441864, "accuracy_val": 0.35611510276794434}, "7": {"accuracy_train": 0.3897569477558136, "accuracy_val": 0.38729017972946167}, "8": {"accuracy_train": 0.3897569477558136, "accuracy_val": 0.316546767950058}, "9": {"accuracy_train": 0.4105902910232544, "accuracy_val": 0.37050360441207886}, "10": {"accuracy_train": 0.401909738779068, "accuracy_val": 0.34532374143600464}, "11": {"accuracy_train": 0.3871527910232544, "accuracy_val": 0.371702641248703}, "12": {"accuracy_train": 0.4279513955116272, "accuracy_val": 0.3824940025806427}, "13": {"accuracy_train": 0.4270833432674408, "accuracy_val": 0.35371702909469604}, "14": {"accuracy_train": 0.453125, "accuracy_val": 0.37290167808532715}, "15": {"accuracy_train": 0.4461805522441864, "accuracy_val": 0.4016786515712738}, "16": {"accuracy_train": 0.4626736044883728, "accuracy_val": 0.3860911428928375}, "17": {"accuracy_train": 0.4279513955116272, "accuracy_val": 0.358513206243515}, "18": {"accuracy_train": 0.4435763955116272, "accuracy_val": 0.3884892165660858}, "19": {"accuracy_train": 0.4314236044883728, "accuracy_val": 0.3201438784599304}, "20": {"accuracy_train": 0.4418402910232544, "accuracy_val": 0.35371702909469604}, "21": {"accuracy_train": 0.4357638955116272, "accuracy_val": 0.3549160659313202}, "22": {"accuracy_train": 0.4184027910232544, "accuracy_val": 0.3860911428928375}, "23": {"accuracy_train": 0.4114583432674408, "accuracy_val": 0.3357314169406891}, "24": {"accuracy_train": 0.433159738779068, "accuracy_val": 0.3141486942768097}, "25": {"accuracy_train": 0.4279513955116272, "accuracy_val": 0.3752997815608978}, "26": {"accuracy_train": 0.4279513955116272, "accuracy_val": 0.3752997815608978}, "27": {"accuracy_train": 0.421875, "accuracy_val": 0.3860911428928375}, "28": {"accuracy_train": 0.4522569477558136, "accuracy_val": 0.41966426372528076}, "29": {"accuracy_train": 0.4557291567325592, "accuracy_val": 0.40047961473464966}, "30": {"accuracy_train": 0.4635416567325592, "accuracy_val": 0.39448443055152893}, "31": {"accuracy_train": 0.4305555522441864, "accuracy_val": 0.4100719392299652}, "32": {"accuracy_train": 0.4583333432674408, "accuracy_val": 0.4208633303642273}, "33": {"accuracy_train": 0.4748263955116272, "accuracy_val": 0.41127100586891174}, "34": {"accuracy_train": 0.4427083432674408, "accuracy_val": 0.4148681163787842}, "35": {"accuracy_train": 0.4765625, "accuracy_val": 0.41366907954216003}, "36": {"accuracy_train": 0.4809027910232544, "accuracy_val": 0.426858514547348}, "37": {"accuracy_train": 0.4592013955116272, "accuracy_val": 0.42805755138397217}, "38": {"accuracy_train": 0.4887152910232544, "accuracy_val": 0.43045565485954285}, "39": {"accuracy_train": 0.4921875, "accuracy_val": 0.41127100586891174}, "40": {"accuracy_train": 0.5008680820465088, "accuracy_val": 0.41127100586891174}, "41": {"accuracy_train": 0.4826388955116272, "accuracy_val": 0.41966426372528076}, "42": {"accuracy_train": 0.487847238779068, "accuracy_val": 0.41966426372528076}, "43": {"accuracy_train": 0.4852430522441864, "accuracy_val": 0.42206236720085144}, "44": {"accuracy_train": 0.4939236044883728, "accuracy_val": 0.4232614040374756}, "45": {"accuracy_train": 0.5034722089767456, "accuracy_val": 0.4184652268886566}, "46": {"accuracy_train": 0.4861111044883728, "accuracy_val": 0.41726619005203247}, "47": {"accuracy_train": 0.5026041865348816, "accuracy_val": 0.4184652268886566}, "48": {"accuracy_train": 0.5026041865348816, "accuracy_val": 0.4340527653694153}, "49": {"accuracy_train": 0.4947916567325592, "accuracy_val": 0.4292566180229187}, "50": {"accuracy_train": 0.4791666567325592, "accuracy_val": 0.4232614040374756}, "51": {"accuracy_train": 0.506944477558136, "accuracy_val": 0.42446044087409973}, "52": {"accuracy_train": 0.4965277910232544, "accuracy_val": 0.4232614040374756}, "53": {"accuracy_train": 0.5078125, "accuracy_val": 0.431654691696167}, "54": {"accuracy_train": 0.4965277910232544, "accuracy_val": 0.44124701619148254}, "55": {"accuracy_train": 0.495659738779068, "accuracy_val": 0.426858514547348}, "56": {"accuracy_train": 0.5243055820465088, "accuracy_val": 0.41726619005203247}, "57": {"accuracy_train": 0.5373263955116272, "accuracy_val": 0.41966426372528076}, "58": {"accuracy_train": 0.4852430522441864, "accuracy_val": 0.4184652268886566}, "59": {"accuracy_train": 0.5182291865348816, "accuracy_val": 0.40887290239334106}, "60": {"accuracy_train": 0.5451388955116272, "accuracy_val": 0.4208633303642273}, "61": {"accuracy_train": 0.5138888955116272, "accuracy_val": 0.44124701619148254}, "62": {"accuracy_train": 0.506944477558136, "accuracy_val": 0.4340527653694153}, "63": {"accuracy_train": 0.5208333134651184, "accuracy_val": 0.41966426372528076}, "64": {"accuracy_train": 0.5295138955116272, "accuracy_val": 0.4208633303642273}, "65": {"accuracy_train": 0.5199652910232544, "accuracy_val": 0.4208633303642273}, "66": {"accuracy_train": 0.5199652910232544, "accuracy_val": 0.44124701619148254}, "67": {"accuracy_train": 0.546006977558136, "accuracy_val": 0.4208633303642273}, "68": {"accuracy_train": 0.5251736044883728, "accuracy_val": 0.41366907954216003}, "69": {"accuracy_train": 0.5260416865348816, "accuracy_val": 0.42805755138397217}, "70": {"accuracy_train": 0.5442708134651184, "accuracy_val": 0.43045565485954285}, "71": {"accuracy_train": 0.5442708134651184, "accuracy_val": 0.43285372853279114}, "72": {"accuracy_train": 0.5373263955116272, "accuracy_val": 0.431654691696167}, "73": {"accuracy_train": 0.5355902910232544, "accuracy_val": 0.43045565485954285}, "74": {"accuracy_train": 0.5364583134651184, "accuracy_val": 0.4148681163787842}, "75": {"accuracy_train": 0.5486111044883728, "accuracy_val": 0.41366907954216003}, "76": {"accuracy_train": 0.5234375, "accuracy_val": 0.4292566180229187}, "77": {"accuracy_train": 0.5407986044883728, "accuracy_val": 0.426858514547348}, "78": {"accuracy_train": 0.5520833134651184, "accuracy_val": 0.43045565485954285}, "79": {"accuracy_train": 0.5425347089767456, "accuracy_val": 0.39808154106140137}, "80": {"accuracy_train": 0.5373263955116272, "accuracy_val": 0.41726619005203247}, "81": {"accuracy_train": 0.5477430820465088, "accuracy_val": 0.41726619005203247}, "82": {"accuracy_train": 0.5416666865348816, "accuracy_val": 0.40887290239334106}, "83": {"accuracy_train": 0.546006977558136, "accuracy_val": 0.4292566180229187}, "84": {"accuracy_train": 0.5503472089767456, "accuracy_val": 0.4208633303642273}, "85": {"accuracy_train": 0.5442708134651184, "accuracy_val": 0.40047961473464966}, "86": {"accuracy_train": 0.5998263955116272, "accuracy_val": 0.431654691696167}, "87": {"accuracy_train": 0.5451388955116272, "accuracy_val": 0.4376498758792877}, "88": {"accuracy_train": 0.5737847089767456, "accuracy_val": 0.41966426372528076}, "89": {"accuracy_train": 0.5590277910232544, "accuracy_val": 0.41366907954216003}, "90": {"accuracy_train": 0.5564236044883728, "accuracy_val": 0.4208633303642273}, "91": {"accuracy_train": 0.553819477558136, "accuracy_val": 0.4148681163787842}, "92": {"accuracy_train": 0.5894097089767456, "accuracy_val": 0.42446044087409973}, "93": {"accuracy_train": 0.5642361044883728, "accuracy_val": 0.39208632707595825}, "94": {"accuracy_train": 0.5651041865348816, "accuracy_val": 0.4184652268886566}, "95": {"accuracy_train": 0.5642361044883728, "accuracy_val": 0.4160671532154083}, "96": {"accuracy_train": 0.5520833134651184, "accuracy_val": 0.41366907954216003}, "97": {"accuracy_train": 0.5972222089767456, "accuracy_val": 0.4184652268886566}, "98": {"accuracy_train": 0.6067708134651184, "accuracy_val": 0.4160671532154083, "accuracy_test": 0.3741007149219513}}, "losses": {"0": {"loss_train": 2043.0182189941406, "loss_val": 1514.9439535140991}, "1": {"loss_train": 1977.1363067626953, "loss_val": 1426.2525312900543}, "2": {"loss_train": 1943.6351470947266, "loss_val": 1388.2518515586853}, "3": {"loss_train": 1913.7293548583984, "loss_val": 1375.428894996643}, "4": {"loss_train": 1902.1924438476562, "loss_val": 1368.6466748714447}, "5": {"loss_train": 1896.579330444336, "loss_val": 1362.0858988761902}, "6": {"loss_train": 1878.5438995361328, "loss_val": 1355.827702999115}, "7": {"loss_train": 1865.2914428710938, "loss_val": 1351.219046831131}, "8": {"loss_train": 1857.4593200683594, "loss_val": 1392.2153084278107}, "9": {"loss_train": 1842.8453063964844, "loss_val": 1354.0910527706146}, "10": {"loss_train": 1844.6280212402344, "loss_val": 1361.1933398246765}, "11": {"loss_train": 1836.962142944336, "loss_val": 1370.938404083252}, "12": {"loss_train": 1822.2792358398438, "loss_val": 1339.7167069911957}, "13": {"loss_train": 1787.1658020019531, "loss_val": 1359.793921470642}, "14": {"loss_train": 1794.4849853515625, "loss_val": 1333.071900844574}, "15": {"loss_train": 1778.4716033935547, "loss_val": 1348.9510667324066}, "16": {"loss_train": 1778.281234741211, "loss_val": 1349.3346371650696}, "17": {"loss_train": 1798.4136657714844, "loss_val": 1382.1664922237396}, "18": {"loss_train": 1799.193618774414, "loss_val": 1322.928451538086}, "19": {"loss_train": 1797.6883544921875, "loss_val": 1361.5618476867676}, "20": {"loss_train": 1785.9454498291016, "loss_val": 1352.1930181980133}, "21": {"loss_train": 1789.2448272705078, "loss_val": 1394.6707203388214}, "22": {"loss_train": 1797.9645080566406, "loss_val": 1363.4069883823395}, "23": {"loss_train": 1802.1742858886719, "loss_val": 1383.8532276153564}, "24": {"loss_train": 1791.735595703125, "loss_val": 1398.100881099701}, "25": {"loss_train": 1798.940689086914, "loss_val": 1367.8336942195892}, "26": {"loss_train": 1807.6400756835938, "loss_val": 1345.9463829994202}, "27": {"loss_train": 1797.4690704345703, "loss_val": 1325.7633578777313}, "28": {"loss_train": 1775.6486053466797, "loss_val": 1314.0690569877625}, "29": {"loss_train": 1757.4376678466797, "loss_val": 1320.1214921474457}, "30": {"loss_train": 1769.9734802246094, "loss_val": 1325.934653520584}, "31": {"loss_train": 1778.23681640625, "loss_val": 1327.5887968540192}, "32": {"loss_train": 1759.1884002685547, "loss_val": 1326.0227513313293}, "33": {"loss_train": 1753.9517822265625, "loss_val": 1322.1898174285889}, "34": {"loss_train": 1768.3244323730469, "loss_val": 1323.175615310669}, "35": {"loss_train": 1734.0350189208984, "loss_val": 1327.0113682746887}, "36": {"loss_train": 1749.4951782226562, "loss_val": 1316.8501596450806}, "37": {"loss_train": 1743.8333435058594, "loss_val": 1313.9744007587433}, "38": {"loss_train": 1738.3594512939453, "loss_val": 1314.1938281059265}, "39": {"loss_train": 1723.79736328125, "loss_val": 1318.221732378006}, "40": {"loss_train": 1737.8507843017578, "loss_val": 1315.9039521217346}, "41": {"loss_train": 1735.8253326416016, "loss_val": 1313.485762834549}, "42": {"loss_train": 1720.6871795654297, "loss_val": 1316.6235826015472}, "43": {"loss_train": 1724.3112487792969, "loss_val": 1314.8438510894775}, "44": {"loss_train": 1731.7240600585938, "loss_val": 1316.5916483402252}, "45": {"loss_train": 1727.8987274169922, "loss_val": 1319.5472645759583}, "46": {"loss_train": 1718.4666748046875, "loss_val": 1317.5220384597778}, "47": {"loss_train": 1724.2423706054688, "loss_val": 1318.7541103363037}, "48": {"loss_train": 1716.1801300048828, "loss_val": 1313.7050971984863}, "49": {"loss_train": 1718.9352111816406, "loss_val": 1317.395494222641}, "50": {"loss_train": 1724.803207397461, "loss_val": 1311.7171745300293}, "51": {"loss_train": 1711.048110961914, "loss_val": 1309.828536748886}, "52": {"loss_train": 1735.4835357666016, "loss_val": 1309.9745943546295}, "53": {"loss_train": 1715.0181732177734, "loss_val": 1320.65940451622}, "54": {"loss_train": 1723.232894897461, "loss_val": 1313.2076354026794}, "55": {"loss_train": 1711.5552368164062, "loss_val": 1317.279839515686}, "56": {"loss_train": 1709.4320983886719, "loss_val": 1318.311862707138}, "57": {"loss_train": 1692.8381652832031, "loss_val": 1321.6121847629547}, "58": {"loss_train": 1714.2434387207031, "loss_val": 1305.6715002059937}, "59": {"loss_train": 1688.2604370117188, "loss_val": 1330.8896782398224}, "60": {"loss_train": 1689.8236999511719, "loss_val": 1318.4001157283783}, "61": {"loss_train": 1704.8384094238281, "loss_val": 1312.477131843567}, "62": {"loss_train": 1707.630859375, "loss_val": 1305.247364282608}, "63": {"loss_train": 1690.675064086914, "loss_val": 1318.088320016861}, "64": {"loss_train": 1685.237060546875, "loss_val": 1316.0770666599274}, "65": {"loss_train": 1702.4862670898438, "loss_val": 1313.586104631424}, "66": {"loss_train": 1691.6018676757812, "loss_val": 1307.3085074424744}, "67": {"loss_train": 1685.919921875, "loss_val": 1312.5200686454773}, "68": {"loss_train": 1689.5050506591797, "loss_val": 1314.8274915218353}, "69": {"loss_train": 1701.7810974121094, "loss_val": 1317.7652192115784}, "70": {"loss_train": 1680.0329284667969, "loss_val": 1309.6842668056488}, "71": {"loss_train": 1680.7052612304688, "loss_val": 1314.5806777477264}, "72": {"loss_train": 1670.90185546875, "loss_val": 1309.9017157554626}, "73": {"loss_train": 1666.9893341064453, "loss_val": 1311.5224239826202}, "74": {"loss_train": 1678.2284698486328, "loss_val": 1319.8673231601715}, "75": {"loss_train": 1676.51416015625, "loss_val": 1323.604041337967}, "76": {"loss_train": 1705.1142120361328, "loss_val": 1317.0031671524048}, "77": {"loss_train": 1689.3825225830078, "loss_val": 1319.8116295337677}, "78": {"loss_train": 1681.9617004394531, "loss_val": 1303.4781506061554}, "79": {"loss_train": 1672.5786437988281, "loss_val": 1342.6354911327362}, "80": {"loss_train": 1682.1279296875, "loss_val": 1317.6026339530945}, "81": {"loss_train": 1664.6276092529297, "loss_val": 1323.1602957248688}, "82": {"loss_train": 1663.4107513427734, "loss_val": 1313.731588602066}, "83": {"loss_train": 1651.2703552246094, "loss_val": 1309.7198181152344}, "84": {"loss_train": 1654.1474914550781, "loss_val": 1320.4679517745972}, "85": {"loss_train": 1669.8367614746094, "loss_val": 1330.0672492980957}, "86": {"loss_train": 1635.2425842285156, "loss_val": 1317.494857788086}, "87": {"loss_train": 1660.4592742919922, "loss_val": 1304.3161990642548}, "88": {"loss_train": 1650.3482513427734, "loss_val": 1304.5251309871674}, "89": {"loss_train": 1660.0272521972656, "loss_val": 1324.1136102676392}, "90": {"loss_train": 1653.6492462158203, "loss_val": 1319.3858692646027}, "91": {"loss_train": 1656.5067138671875, "loss_val": 1323.8031017780304}, "92": {"loss_train": 1636.2180480957031, "loss_val": 1312.2113192081451}, "93": {"loss_train": 1647.438720703125, "loss_val": 1337.597915172577}, "94": {"loss_train": 1652.860107421875, "loss_val": 1316.343759059906}, "95": {"loss_train": 1640.5553131103516, "loss_val": 1320.1069025993347}, "96": {"loss_train": 1659.022216796875, "loss_val": 1314.0389313697815}, "97": {"loss_train": 1638.6612396240234, "loss_val": 1310.2933459281921}, "98": {"loss_train": 1617.4666900634766, "loss_val": 1309.5043835639954, "loss_test": 444.67195200920105}}, "training_time_secs": 463.5768370628357}}, "lr_scheduler_configr": {"lr_scheduler_step_size": 30, "lr_scheduler_gamma": 0.02, "lr_scheduler_last_epoch": -1}}