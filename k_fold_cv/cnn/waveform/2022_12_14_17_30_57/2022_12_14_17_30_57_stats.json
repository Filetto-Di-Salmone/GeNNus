{"k_fold_cv_id": "2022_12_14_17_30_57", "stats_type": "k_fold_cross_validation", "k_folds_cv_num_folds": 3, "data_logs": {"data_type": "waveform", "dataset_size": "s", "batch_size": 64, "num_samples_per_second": 8000, "num_channels": 1, "train_transforms": "[\"{'transform_name': 'StandardizeTransform', 'mean': -7.975741027621552e-05, 'std': 0.2950393557548523}\", 'RandomApply(\\n    p=0.05\\n    PolarityInversion()\\n)', 'RandomApply(\\n    p=0.05\\n    Noise()\\n)', 'RandomApply(\\n    p=0.05\\n    Gain()\\n)', 'RandomApply(\\n    p=0.05\\n    Delay()\\n)', {'p_boosting_factors': None, 'epoch_steps': None}]"}, "optimizer_config": {"lr": 0.01, "momentum": 0.9, "weight_decay": 0.01, "nesterov": true}, "model_setup": {"num_layers": 5, "kernel_sizes": [2, 2, 2, 2, 2], "strides": [2, 2, 2, 2, 2], "in_channels": 1, "num_filters": [2, 4, 6, 8, 10], "pool_sizes": [2, 2, 2, 2, 2], "pool_strides": [2, 2, 2, 2, 2], "dropout_p_conv": 0.0, "dropout_p_linear": 0.5}, "training_logs": {"0": {"train_id": "2022_12_14_17_30_57", "accuracies": {"0": {"accuracy_train": 0.1674107164144516, "accuracy_val": 0.1690647453069687}, "1": {"accuracy_train": 0.180803582072258, "accuracy_val": 0.188249409198761}, "2": {"accuracy_train": 0.1897321492433548, "accuracy_val": 0.17026379704475403}, "3": {"accuracy_train": 0.1629464328289032, "accuracy_val": 0.17026379704475403}, "4": {"accuracy_train": 0.2165178656578064, "accuracy_val": 0.17026379704475403}, "5": {"accuracy_train": 0.2254464328289032, "accuracy_val": 0.17026379704475403}, "6": {"accuracy_train": 0.2075892984867096, "accuracy_val": 0.17026379704475403}, "7": {"accuracy_train": 0.2075892984867096, "accuracy_val": 0.17026379704475403}, "8": {"accuracy_train": 0.2232142984867096, "accuracy_val": 0.17026379704475403}, "9": {"accuracy_train": 0.2254464328289032, "accuracy_val": 0.17026379704475403}, "10": {"accuracy_train": 0.1852678656578064, "accuracy_val": 0.17026379704475403}, "11": {"accuracy_train": 0.2031250149011612, "accuracy_val": 0.1690647453069687}, "12": {"accuracy_train": 0.2053571492433548, "accuracy_val": 0.1690647453069687}, "13": {"accuracy_train": 0.2053571492433548, "accuracy_val": 0.1690647453069687}, "14": {"accuracy_train": 0.2187500149011612, "accuracy_val": 0.1690647453069687}, "15": {"accuracy_train": 0.2031250149011612, "accuracy_val": 0.1690647453069687}, "16": {"accuracy_train": 0.2008928656578064, "accuracy_val": 0.1690647453069687}, "17": {"accuracy_train": 0.2008928656578064, "accuracy_val": 0.17026379704475403}, "18": {"accuracy_train": 0.2142857313156128, "accuracy_val": 0.17026379704475403}, "19": {"accuracy_train": 0.2008928656578064, "accuracy_val": 0.17026379704475403}, "20": {"accuracy_train": 0.2366071492433548, "accuracy_val": 0.1690647453069687}, "21": {"accuracy_train": 0.2321428656578064, "accuracy_val": 0.1690647453069687}, "22": {"accuracy_train": 0.2098214328289032, "accuracy_val": 0.1690647453069687}, "23": {"accuracy_train": 0.227678582072258, "accuracy_val": 0.1690647453069687}, "24": {"accuracy_train": 0.2299107313156128, "accuracy_val": 0.16786570847034454}, "25": {"accuracy_train": 0.2232142984867096, "accuracy_val": 0.1690647453069687}, "26": {"accuracy_train": 0.1919642984867096, "accuracy_val": 0.1690647453069687}, "27": {"accuracy_train": 0.2366071492433548, "accuracy_val": 0.1690647453069687}, "28": {"accuracy_train": 0.2343750149011612, "accuracy_val": 0.1690647453069687}, "29": {"accuracy_train": 0.2388392984867096, "accuracy_val": 0.1690647453069687}, "30": {"accuracy_train": 0.2254464328289032, "accuracy_val": 0.1690647453069687}, "31": {"accuracy_train": 0.227678582072258, "accuracy_val": 0.16786570847034454}, "32": {"accuracy_train": 0.1919642984867096, "accuracy_val": 0.1690647453069687}, "33": {"accuracy_train": 0.2209821492433548, "accuracy_val": 0.16786570847034454}, "34": {"accuracy_train": 0.2098214328289032, "accuracy_val": 0.16786570847034454}, "35": {"accuracy_train": 0.2053571492433548, "accuracy_val": 0.16786570847034454}, "36": {"accuracy_train": 0.2209821492433548, "accuracy_val": 0.1690647453069687}, "37": {"accuracy_train": 0.212053582072258, "accuracy_val": 0.1690647453069687}, "38": {"accuracy_train": 0.2254464328289032, "accuracy_val": 0.1690647453069687}, "39": {"accuracy_train": 0.2633928656578064, "accuracy_val": 0.16786570847034454}, "40": {"accuracy_train": 0.2321428656578064, "accuracy_val": 0.1690647453069687}, "41": {"accuracy_train": 0.1986607164144516, "accuracy_val": 0.16786570847034454}, "42": {"accuracy_train": 0.227678582072258, "accuracy_val": 0.1690647453069687}, "43": {"accuracy_train": 0.2254464328289032, "accuracy_val": 0.1690647453069687}, "44": {"accuracy_train": 0.2299107313156128, "accuracy_val": 0.16786570847034454}, "45": {"accuracy_train": 0.2232142984867096, "accuracy_val": 0.16786570847034454}, "46": {"accuracy_train": 0.2053571492433548, "accuracy_val": 0.16786570847034454}, "47": {"accuracy_train": 0.2031250149011612, "accuracy_val": 0.16786570847034454}, "48": {"accuracy_train": 0.2299107313156128, "accuracy_val": 0.16786570847034454}, "49": {"accuracy_train": 0.1919642984867096, "accuracy_val": 0.16786570847034454, "accuracy_test": 0.17985612154006958}}, "losses": {"0": {"loss_train": 804.7506484985352, "loss_val": 1494.1611323356628}, "1": {"loss_train": 799.7689208984375, "loss_val": 1493.9661312103271}, "2": {"loss_train": 801.785026550293, "loss_val": 1493.9516372680664}, "3": {"loss_train": 804.5137405395508, "loss_val": 1494.2461433410645}, "4": {"loss_train": 797.298957824707, "loss_val": 1494.3625144958496}, "5": {"loss_train": 799.7128601074219, "loss_val": 1494.821039199829}, "6": {"loss_train": 796.2839431762695, "loss_val": 1495.9708602428436}, "7": {"loss_train": 793.0931396484375, "loss_val": 1497.6569664478302}, "8": {"loss_train": 796.234016418457, "loss_val": 1499.787915945053}, "9": {"loss_train": 798.1450042724609, "loss_val": 1501.384484052658}, "10": {"loss_train": 795.8034896850586, "loss_val": 1502.9312582015991}, "11": {"loss_train": 796.7017593383789, "loss_val": 1504.172667503357}, "12": {"loss_train": 796.7207565307617, "loss_val": 1503.2580318450928}, "13": {"loss_train": 802.6664657592773, "loss_val": 1502.8539366722107}, "14": {"loss_train": 797.2140045166016, "loss_val": 1503.2151584625244}, "15": {"loss_train": 798.3666763305664, "loss_val": 1504.5915780067444}, "16": {"loss_train": 793.3839111328125, "loss_val": 1505.573320388794}, "17": {"loss_train": 789.4915084838867, "loss_val": 1506.6534948349}, "18": {"loss_train": 792.9341583251953, "loss_val": 1507.7280440330505}, "19": {"loss_train": 793.3136749267578, "loss_val": 1507.6453976631165}, "20": {"loss_train": 785.1304626464844, "loss_val": 1508.4232580661774}, "21": {"loss_train": 784.7369003295898, "loss_val": 1509.7073106765747}, "22": {"loss_train": 795.5670166015625, "loss_val": 1510.5564618110657}, "23": {"loss_train": 798.8779449462891, "loss_val": 1510.525764465332}, "24": {"loss_train": 790.4106674194336, "loss_val": 1509.7656626701355}, "25": {"loss_train": 793.0907745361328, "loss_val": 1508.814564704895}, "26": {"loss_train": 800.506233215332, "loss_val": 1507.1489431858063}, "27": {"loss_train": 790.4235992431641, "loss_val": 1506.5678827762604}, "28": {"loss_train": 788.4392318725586, "loss_val": 1507.1634874343872}, "29": {"loss_train": 787.712776184082, "loss_val": 1508.1894311904907}, "30": {"loss_train": 789.3151092529297, "loss_val": 1507.705318927765}, "31": {"loss_train": 785.9783172607422, "loss_val": 1509.462564945221}, "32": {"loss_train": 795.514030456543, "loss_val": 1510.1367092132568}, "33": {"loss_train": 790.9435043334961, "loss_val": 1510.2825634479523}, "34": {"loss_train": 796.9064025878906, "loss_val": 1510.6813373565674}, "35": {"loss_train": 789.4979095458984, "loss_val": 1510.9029731750488}, "36": {"loss_train": 796.044059753418, "loss_val": 1510.9556455612183}, "37": {"loss_train": 788.8349380493164, "loss_val": 1510.785138130188}, "38": {"loss_train": 786.8865203857422, "loss_val": 1510.2803192138672}, "39": {"loss_train": 781.2061157226562, "loss_val": 1510.3873300552368}, "40": {"loss_train": 790.4953231811523, "loss_val": 1510.4532704353333}, "41": {"loss_train": 797.3489379882812, "loss_val": 1510.5367991924286}, "42": {"loss_train": 784.6406326293945, "loss_val": 1510.628160238266}, "43": {"loss_train": 783.935417175293, "loss_val": 1510.4828190803528}, "44": {"loss_train": 791.1796493530273, "loss_val": 1510.5924808979034}, "45": {"loss_train": 788.6301879882812, "loss_val": 1510.871009349823}, "46": {"loss_train": 797.4500961303711, "loss_val": 1510.5065789222717}, "47": {"loss_train": 797.9445495605469, "loss_val": 1510.813015460968}, "48": {"loss_train": 784.3549957275391, "loss_val": 1510.3897228240967}, "49": {"loss_train": 793.7864379882812, "loss_val": 1510.8880023956299, "loss_test": 494.3489227294922}}, "training_time_secs": 149.946280002594}, "1": {"train_id": "2022_12_14_17_30_57", "accuracies": {"0": {"accuracy_train": 0.1674107164144516, "accuracy_val": 0.1690647453069687}, "1": {"accuracy_train": 0.180803582072258, "accuracy_val": 0.188249409198761}, "2": {"accuracy_train": 0.1897321492433548, "accuracy_val": 0.17026379704475403}, "3": {"accuracy_train": 0.1629464328289032, "accuracy_val": 0.17026379704475403}, "4": {"accuracy_train": 0.2165178656578064, "accuracy_val": 0.17026379704475403}, "5": {"accuracy_train": 0.2254464328289032, "accuracy_val": 0.17026379704475403}, "6": {"accuracy_train": 0.2075892984867096, "accuracy_val": 0.17026379704475403}, "7": {"accuracy_train": 0.2075892984867096, "accuracy_val": 0.17026379704475403}, "8": {"accuracy_train": 0.2232142984867096, "accuracy_val": 0.17026379704475403}, "9": {"accuracy_train": 0.2254464328289032, "accuracy_val": 0.17026379704475403}, "10": {"accuracy_train": 0.1852678656578064, "accuracy_val": 0.17026379704475403}, "11": {"accuracy_train": 0.2031250149011612, "accuracy_val": 0.1690647453069687}, "12": {"accuracy_train": 0.2053571492433548, "accuracy_val": 0.1690647453069687}, "13": {"accuracy_train": 0.2053571492433548, "accuracy_val": 0.1690647453069687}, "14": {"accuracy_train": 0.2187500149011612, "accuracy_val": 0.1690647453069687}, "15": {"accuracy_train": 0.2031250149011612, "accuracy_val": 0.1690647453069687}, "16": {"accuracy_train": 0.2008928656578064, "accuracy_val": 0.1690647453069687}, "17": {"accuracy_train": 0.2008928656578064, "accuracy_val": 0.17026379704475403}, "18": {"accuracy_train": 0.2142857313156128, "accuracy_val": 0.17026379704475403}, "19": {"accuracy_train": 0.2008928656578064, "accuracy_val": 0.17026379704475403}, "20": {"accuracy_train": 0.2366071492433548, "accuracy_val": 0.1690647453069687}, "21": {"accuracy_train": 0.2321428656578064, "accuracy_val": 0.1690647453069687}, "22": {"accuracy_train": 0.2098214328289032, "accuracy_val": 0.1690647453069687}, "23": {"accuracy_train": 0.227678582072258, "accuracy_val": 0.1690647453069687}, "24": {"accuracy_train": 0.2299107313156128, "accuracy_val": 0.16786570847034454}, "25": {"accuracy_train": 0.2232142984867096, "accuracy_val": 0.1690647453069687}, "26": {"accuracy_train": 0.1919642984867096, "accuracy_val": 0.1690647453069687}, "27": {"accuracy_train": 0.2366071492433548, "accuracy_val": 0.1690647453069687}, "28": {"accuracy_train": 0.2343750149011612, "accuracy_val": 0.1690647453069687}, "29": {"accuracy_train": 0.2388392984867096, "accuracy_val": 0.1690647453069687}, "30": {"accuracy_train": 0.2254464328289032, "accuracy_val": 0.1690647453069687}, "31": {"accuracy_train": 0.227678582072258, "accuracy_val": 0.16786570847034454}, "32": {"accuracy_train": 0.1919642984867096, "accuracy_val": 0.1690647453069687}, "33": {"accuracy_train": 0.2209821492433548, "accuracy_val": 0.16786570847034454}, "34": {"accuracy_train": 0.2098214328289032, "accuracy_val": 0.16786570847034454}, "35": {"accuracy_train": 0.2053571492433548, "accuracy_val": 0.16786570847034454}, "36": {"accuracy_train": 0.2209821492433548, "accuracy_val": 0.1690647453069687}, "37": {"accuracy_train": 0.212053582072258, "accuracy_val": 0.1690647453069687}, "38": {"accuracy_train": 0.2254464328289032, "accuracy_val": 0.1690647453069687}, "39": {"accuracy_train": 0.2633928656578064, "accuracy_val": 0.16786570847034454}, "40": {"accuracy_train": 0.2321428656578064, "accuracy_val": 0.1690647453069687}, "41": {"accuracy_train": 0.1986607164144516, "accuracy_val": 0.16786570847034454}, "42": {"accuracy_train": 0.227678582072258, "accuracy_val": 0.1690647453069687}, "43": {"accuracy_train": 0.2254464328289032, "accuracy_val": 0.1690647453069687}, "44": {"accuracy_train": 0.2299107313156128, "accuracy_val": 0.16786570847034454}, "45": {"accuracy_train": 0.2232142984867096, "accuracy_val": 0.16786570847034454}, "46": {"accuracy_train": 0.2053571492433548, "accuracy_val": 0.16786570847034454}, "47": {"accuracy_train": 0.2031250149011612, "accuracy_val": 0.16786570847034454}, "48": {"accuracy_train": 0.2299107313156128, "accuracy_val": 0.16786570847034454}, "49": {"accuracy_train": 0.1919642984867096, "accuracy_val": 0.16786570847034454, "accuracy_test": 0.17985612154006958}}, "losses": {"0": {"loss_train": 804.7506484985352, "loss_val": 1494.1611323356628}, "1": {"loss_train": 799.7689208984375, "loss_val": 1493.9661312103271}, "2": {"loss_train": 801.785026550293, "loss_val": 1493.9516372680664}, "3": {"loss_train": 804.5137405395508, "loss_val": 1494.2461433410645}, "4": {"loss_train": 797.298957824707, "loss_val": 1494.3625144958496}, "5": {"loss_train": 799.7128601074219, "loss_val": 1494.821039199829}, "6": {"loss_train": 796.2839431762695, "loss_val": 1495.9708602428436}, "7": {"loss_train": 793.0931396484375, "loss_val": 1497.6569664478302}, "8": {"loss_train": 796.234016418457, "loss_val": 1499.787915945053}, "9": {"loss_train": 798.1450042724609, "loss_val": 1501.384484052658}, "10": {"loss_train": 795.8034896850586, "loss_val": 1502.9312582015991}, "11": {"loss_train": 796.7017593383789, "loss_val": 1504.172667503357}, "12": {"loss_train": 796.7207565307617, "loss_val": 1503.2580318450928}, "13": {"loss_train": 802.6664657592773, "loss_val": 1502.8539366722107}, "14": {"loss_train": 797.2140045166016, "loss_val": 1503.2151584625244}, "15": {"loss_train": 798.3666763305664, "loss_val": 1504.5915780067444}, "16": {"loss_train": 793.3839111328125, "loss_val": 1505.573320388794}, "17": {"loss_train": 789.4915084838867, "loss_val": 1506.6534948349}, "18": {"loss_train": 792.9341583251953, "loss_val": 1507.7280440330505}, "19": {"loss_train": 793.3136749267578, "loss_val": 1507.6453976631165}, "20": {"loss_train": 785.1304626464844, "loss_val": 1508.4232580661774}, "21": {"loss_train": 784.7369003295898, "loss_val": 1509.7073106765747}, "22": {"loss_train": 795.5670166015625, "loss_val": 1510.5564618110657}, "23": {"loss_train": 798.8779449462891, "loss_val": 1510.525764465332}, "24": {"loss_train": 790.4106674194336, "loss_val": 1509.7656626701355}, "25": {"loss_train": 793.0907745361328, "loss_val": 1508.814564704895}, "26": {"loss_train": 800.506233215332, "loss_val": 1507.1489431858063}, "27": {"loss_train": 790.4235992431641, "loss_val": 1506.5678827762604}, "28": {"loss_train": 788.4392318725586, "loss_val": 1507.1634874343872}, "29": {"loss_train": 787.712776184082, "loss_val": 1508.1894311904907}, "30": {"loss_train": 789.3151092529297, "loss_val": 1507.705318927765}, "31": {"loss_train": 785.9783172607422, "loss_val": 1509.462564945221}, "32": {"loss_train": 795.514030456543, "loss_val": 1510.1367092132568}, "33": {"loss_train": 790.9435043334961, "loss_val": 1510.2825634479523}, "34": {"loss_train": 796.9064025878906, "loss_val": 1510.6813373565674}, "35": {"loss_train": 789.4979095458984, "loss_val": 1510.9029731750488}, "36": {"loss_train": 796.044059753418, "loss_val": 1510.9556455612183}, "37": {"loss_train": 788.8349380493164, "loss_val": 1510.785138130188}, "38": {"loss_train": 786.8865203857422, "loss_val": 1510.2803192138672}, "39": {"loss_train": 781.2061157226562, "loss_val": 1510.3873300552368}, "40": {"loss_train": 790.4953231811523, "loss_val": 1510.4532704353333}, "41": {"loss_train": 797.3489379882812, "loss_val": 1510.5367991924286}, "42": {"loss_train": 784.6406326293945, "loss_val": 1510.628160238266}, "43": {"loss_train": 783.935417175293, "loss_val": 1510.4828190803528}, "44": {"loss_train": 791.1796493530273, "loss_val": 1510.5924808979034}, "45": {"loss_train": 788.6301879882812, "loss_val": 1510.871009349823}, "46": {"loss_train": 797.4500961303711, "loss_val": 1510.5065789222717}, "47": {"loss_train": 797.9445495605469, "loss_val": 1510.813015460968}, "48": {"loss_train": 784.3549957275391, "loss_val": 1510.3897228240967}, "49": {"loss_train": 793.7864379882812, "loss_val": 1510.8880023956299, "loss_test": 494.3489227294922}}, "training_time_secs": 149.946280002594}, "2": {"train_id": "2022_12_14_17_30_57", "accuracies": {"0": {"accuracy_train": 0.1674107164144516, "accuracy_val": 0.1690647453069687}, "1": {"accuracy_train": 0.180803582072258, "accuracy_val": 0.188249409198761}, "2": {"accuracy_train": 0.1897321492433548, "accuracy_val": 0.17026379704475403}, "3": {"accuracy_train": 0.1629464328289032, "accuracy_val": 0.17026379704475403}, "4": {"accuracy_train": 0.2165178656578064, "accuracy_val": 0.17026379704475403}, "5": {"accuracy_train": 0.2254464328289032, "accuracy_val": 0.17026379704475403}, "6": {"accuracy_train": 0.2075892984867096, "accuracy_val": 0.17026379704475403}, "7": {"accuracy_train": 0.2075892984867096, "accuracy_val": 0.17026379704475403}, "8": {"accuracy_train": 0.2232142984867096, "accuracy_val": 0.17026379704475403}, "9": {"accuracy_train": 0.2254464328289032, "accuracy_val": 0.17026379704475403}, "10": {"accuracy_train": 0.1852678656578064, "accuracy_val": 0.17026379704475403}, "11": {"accuracy_train": 0.2031250149011612, "accuracy_val": 0.1690647453069687}, "12": {"accuracy_train": 0.2053571492433548, "accuracy_val": 0.1690647453069687}, "13": {"accuracy_train": 0.2053571492433548, "accuracy_val": 0.1690647453069687}, "14": {"accuracy_train": 0.2187500149011612, "accuracy_val": 0.1690647453069687}, "15": {"accuracy_train": 0.2031250149011612, "accuracy_val": 0.1690647453069687}, "16": {"accuracy_train": 0.2008928656578064, "accuracy_val": 0.1690647453069687}, "17": {"accuracy_train": 0.2008928656578064, "accuracy_val": 0.17026379704475403}, "18": {"accuracy_train": 0.2142857313156128, "accuracy_val": 0.17026379704475403}, "19": {"accuracy_train": 0.2008928656578064, "accuracy_val": 0.17026379704475403}, "20": {"accuracy_train": 0.2366071492433548, "accuracy_val": 0.1690647453069687}, "21": {"accuracy_train": 0.2321428656578064, "accuracy_val": 0.1690647453069687}, "22": {"accuracy_train": 0.2098214328289032, "accuracy_val": 0.1690647453069687}, "23": {"accuracy_train": 0.227678582072258, "accuracy_val": 0.1690647453069687}, "24": {"accuracy_train": 0.2299107313156128, "accuracy_val": 0.16786570847034454}, "25": {"accuracy_train": 0.2232142984867096, "accuracy_val": 0.1690647453069687}, "26": {"accuracy_train": 0.1919642984867096, "accuracy_val": 0.1690647453069687}, "27": {"accuracy_train": 0.2366071492433548, "accuracy_val": 0.1690647453069687}, "28": {"accuracy_train": 0.2343750149011612, "accuracy_val": 0.1690647453069687}, "29": {"accuracy_train": 0.2388392984867096, "accuracy_val": 0.1690647453069687}, "30": {"accuracy_train": 0.2254464328289032, "accuracy_val": 0.1690647453069687}, "31": {"accuracy_train": 0.227678582072258, "accuracy_val": 0.16786570847034454}, "32": {"accuracy_train": 0.1919642984867096, "accuracy_val": 0.1690647453069687}, "33": {"accuracy_train": 0.2209821492433548, "accuracy_val": 0.16786570847034454}, "34": {"accuracy_train": 0.2098214328289032, "accuracy_val": 0.16786570847034454}, "35": {"accuracy_train": 0.2053571492433548, "accuracy_val": 0.16786570847034454}, "36": {"accuracy_train": 0.2209821492433548, "accuracy_val": 0.1690647453069687}, "37": {"accuracy_train": 0.212053582072258, "accuracy_val": 0.1690647453069687}, "38": {"accuracy_train": 0.2254464328289032, "accuracy_val": 0.1690647453069687}, "39": {"accuracy_train": 0.2633928656578064, "accuracy_val": 0.16786570847034454}, "40": {"accuracy_train": 0.2321428656578064, "accuracy_val": 0.1690647453069687}, "41": {"accuracy_train": 0.1986607164144516, "accuracy_val": 0.16786570847034454}, "42": {"accuracy_train": 0.227678582072258, "accuracy_val": 0.1690647453069687}, "43": {"accuracy_train": 0.2254464328289032, "accuracy_val": 0.1690647453069687}, "44": {"accuracy_train": 0.2299107313156128, "accuracy_val": 0.16786570847034454}, "45": {"accuracy_train": 0.2232142984867096, "accuracy_val": 0.16786570847034454}, "46": {"accuracy_train": 0.2053571492433548, "accuracy_val": 0.16786570847034454}, "47": {"accuracy_train": 0.2031250149011612, "accuracy_val": 0.16786570847034454}, "48": {"accuracy_train": 0.2299107313156128, "accuracy_val": 0.16786570847034454}, "49": {"accuracy_train": 0.1919642984867096, "accuracy_val": 0.16786570847034454, "accuracy_test": 0.17985612154006958}}, "losses": {"0": {"loss_train": 804.7506484985352, "loss_val": 1494.1611323356628}, "1": {"loss_train": 799.7689208984375, "loss_val": 1493.9661312103271}, "2": {"loss_train": 801.785026550293, "loss_val": 1493.9516372680664}, "3": {"loss_train": 804.5137405395508, "loss_val": 1494.2461433410645}, "4": {"loss_train": 797.298957824707, "loss_val": 1494.3625144958496}, "5": {"loss_train": 799.7128601074219, "loss_val": 1494.821039199829}, "6": {"loss_train": 796.2839431762695, "loss_val": 1495.9708602428436}, "7": {"loss_train": 793.0931396484375, "loss_val": 1497.6569664478302}, "8": {"loss_train": 796.234016418457, "loss_val": 1499.787915945053}, "9": {"loss_train": 798.1450042724609, "loss_val": 1501.384484052658}, "10": {"loss_train": 795.8034896850586, "loss_val": 1502.9312582015991}, "11": {"loss_train": 796.7017593383789, "loss_val": 1504.172667503357}, "12": {"loss_train": 796.7207565307617, "loss_val": 1503.2580318450928}, "13": {"loss_train": 802.6664657592773, "loss_val": 1502.8539366722107}, "14": {"loss_train": 797.2140045166016, "loss_val": 1503.2151584625244}, "15": {"loss_train": 798.3666763305664, "loss_val": 1504.5915780067444}, "16": {"loss_train": 793.3839111328125, "loss_val": 1505.573320388794}, "17": {"loss_train": 789.4915084838867, "loss_val": 1506.6534948349}, "18": {"loss_train": 792.9341583251953, "loss_val": 1507.7280440330505}, "19": {"loss_train": 793.3136749267578, "loss_val": 1507.6453976631165}, "20": {"loss_train": 785.1304626464844, "loss_val": 1508.4232580661774}, "21": {"loss_train": 784.7369003295898, "loss_val": 1509.7073106765747}, "22": {"loss_train": 795.5670166015625, "loss_val": 1510.5564618110657}, "23": {"loss_train": 798.8779449462891, "loss_val": 1510.525764465332}, "24": {"loss_train": 790.4106674194336, "loss_val": 1509.7656626701355}, "25": {"loss_train": 793.0907745361328, "loss_val": 1508.814564704895}, "26": {"loss_train": 800.506233215332, "loss_val": 1507.1489431858063}, "27": {"loss_train": 790.4235992431641, "loss_val": 1506.5678827762604}, "28": {"loss_train": 788.4392318725586, "loss_val": 1507.1634874343872}, "29": {"loss_train": 787.712776184082, "loss_val": 1508.1894311904907}, "30": {"loss_train": 789.3151092529297, "loss_val": 1507.705318927765}, "31": {"loss_train": 785.9783172607422, "loss_val": 1509.462564945221}, "32": {"loss_train": 795.514030456543, "loss_val": 1510.1367092132568}, "33": {"loss_train": 790.9435043334961, "loss_val": 1510.2825634479523}, "34": {"loss_train": 796.9064025878906, "loss_val": 1510.6813373565674}, "35": {"loss_train": 789.4979095458984, "loss_val": 1510.9029731750488}, "36": {"loss_train": 796.044059753418, "loss_val": 1510.9556455612183}, "37": {"loss_train": 788.8349380493164, "loss_val": 1510.785138130188}, "38": {"loss_train": 786.8865203857422, "loss_val": 1510.2803192138672}, "39": {"loss_train": 781.2061157226562, "loss_val": 1510.3873300552368}, "40": {"loss_train": 790.4953231811523, "loss_val": 1510.4532704353333}, "41": {"loss_train": 797.3489379882812, "loss_val": 1510.5367991924286}, "42": {"loss_train": 784.6406326293945, "loss_val": 1510.628160238266}, "43": {"loss_train": 783.935417175293, "loss_val": 1510.4828190803528}, "44": {"loss_train": 791.1796493530273, "loss_val": 1510.5924808979034}, "45": {"loss_train": 788.6301879882812, "loss_val": 1510.871009349823}, "46": {"loss_train": 797.4500961303711, "loss_val": 1510.5065789222717}, "47": {"loss_train": 797.9445495605469, "loss_val": 1510.813015460968}, "48": {"loss_train": 784.3549957275391, "loss_val": 1510.3897228240967}, "49": {"loss_train": 793.7864379882812, "loss_val": 1510.8880023956299, "loss_test": 494.3489227294922}}, "training_time_secs": 149.946280002594}}, "lr_scheduler_configr": {"lr_scheduler_step_size": 30, "lr_scheduler_gamma": 0.02, "lr_scheduler_last_epoch": -1}}