{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "import torchaudio\n",
    "import torchaudio.transforms\n",
    "\n",
    "import sys, os\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "from tqdm.notebook import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_from_str_to_one_hot(label_str: str): \n",
    "  \n",
    "  if label_str == \"Pop\":\n",
    "    return torch.tensor([1, 0, 0, 0, 0, 0])\n",
    "  \n",
    "  if label_str == \"Hip-Hop\":\n",
    "    return torch.tensor([0, 1, 0, 0, 0, 0])\n",
    "  \n",
    "  if label_str == \"Electronic\":\n",
    "    return torch.tensor([0, 0, 1, 0, 0, 0])\n",
    "  \n",
    "  if label_str == \"Rock\":\n",
    "    return torch.tensor([0, 0, 0, 1, 0, 0])\n",
    "\n",
    "  if label_str == \"Folk\":\n",
    "    return torch.tensor([0, 0, 0, 0, 1, 0])\n",
    "\n",
    "  if label_str == \"Jazz\":\n",
    "    return torch.tensor([0, 0, 0, 0, 0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_raw_audio_data(\n",
    "  path, normalize_audio, audio_num_frames\n",
    "):\n",
    "  \n",
    "  audio_tensor_list = []\n",
    "\n",
    "  for path, subdirs, files in tqdm(os.walk(path), colour=\"teal\"):\n",
    "    for name in tqdm(files, colour=\"turquoise\"):\n",
    "        \n",
    "      file_audio_path = os.path.join(path, name)\n",
    "      \n",
    "      try:\n",
    "        waveform, sample_rate = torchaudio.load(\n",
    "          file_audio_path, normalize=normalize_audio,\n",
    "          num_frames=audio_num_frames\n",
    "        )\n",
    "        \n",
    "        audio_tensor_list.append(\n",
    "          {\n",
    "            \"waveform\": waveform, \n",
    "            \"sample_rate\": sample_rate\n",
    "          }\n",
    "        )\n",
    "        \n",
    "      except:\n",
    "        print(f\"[load_audio_data] error while loading {file_audio_path}\")\n",
    "        continue\n",
    "  \n",
    "  return audio_tensor_list\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"audio_hop\" --> take one sample ever hop_size elements\n",
    "def perform_audio_hop(og_audio_list, hop_size):\n",
    "  \n",
    "  resampled_audio_tensor_list = []\n",
    "  \n",
    "  for audio in tqdm(og_audio_list, colour=\"steelblue\"):\n",
    "    \n",
    "    resampled_audio_tensor_list.append(\n",
    "      torchaudio.functional.resample(\n",
    "          audio, orig_freq=hop_size, new_freq=1\n",
    "        )\n",
    "    )\n",
    "    \n",
    "  return resampled_audio_tensor_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6196adc491cd48618607827d0e94d073",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbc6dce1d3464de0a9f81ab718e6fc8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0a925ecdbf64eeeaf3e761e692202ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebc3757e2d7a4e3baa8b5e099c4f0ad4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e75a50b50c9244548a5f67973f69de45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e132c11dabff477ab105219bbb55fe0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f13da48851c64848beee8bb7778f1cc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4c3d03cb2f84c4992778fd7dc532677",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "og_audio_list = load_raw_audio_data(\n",
    "  path=\"./data/fma_extra_small_organized_by_label/\", \n",
    "  normalize_audio=True, \n",
    "  audio_num_frames=1320000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OLD CODE TO RESAMPLE AND GET A MEL SPECTROGRAM\n",
    "\n",
    "# waveform = torchaudio.functional.resample(\n",
    "#           waveform, orig_freq=audio_hop_length, new_freq=1\n",
    "#         )\n",
    "        \n",
    "#         label = file_audio_path.split(\"/\")[-2]\n",
    "#         label_one_hot = label_from_str_to_one_hot(label)\n",
    "        \n",
    "#         temp_dict_waveform = {\n",
    "#           \"label\": label_one_hot,\n",
    "#           \"waveform\": waveform\n",
    "#         }\n",
    "        \n",
    "#         temp_dict_mel_spectrogram = {\n",
    "#           \"label\": label_one_hot,\n",
    "#           \"mel_spectrogram\": self.get_mel_spectrogram(\n",
    "#             waveform, sample_rate\n",
    "#           )\n",
    "#         }\n",
    "        \n",
    "#         data_waveform.append(temp_dict_waveform)\n",
    "#         data_mel_spectrogram.append(temp_dict_mel_spectrogram)\n",
    "        \n",
    "#   return data_waveform, data_mel_spectrogram\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetConverter(Dataset):\n",
    "    def __init__(\n",
    "      self, path: str, use_spectrogram: bool, normalize_audio: bool, \n",
    "      audio_num_frames: int, audio_hop_length: int\n",
    "    ):\n",
    "      self.path = path\n",
    "      self.use_spectrogram = use_spectrogram\n",
    "      self.normalize_audio = normalize_audio\n",
    "      self.audio_num_frames = audio_num_frames\n",
    "      self.audio_hop_length = audio_hop_length\n",
    "      \n",
    "      # TODO load the raw dataset only once, then use it in another class/cell\n",
    "      # to perform all the desired \"compressions\"/samplings/whatever \n",
    "      self.data_waveform, self.data_mel_spectrogram = self.load_audio_data()\n",
    "      \n",
    "      # TODO export self.data_waveform to disk\n",
    "      # TODO export self.data_spectrogram to disk\n",
    "  \n",
    "\n",
    "    def __len__(self):\n",
    "      return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "      return self.data_waveform[idx], self.data_mel_spectrogram[idx]\n",
    "    \n",
    "\n",
    "      \n",
    "    def get_mel_spectrogram(self, waveform, sample_rate):\n",
    "      \n",
    "      # TODO save the MelSpectrogram object in the class constructor in order\n",
    "      # to avoid to re-init it every time\n",
    "      \n",
    "      n_fft = 1024\n",
    "      win_length = None\n",
    "      # hop_length = 512\n",
    "      hop_length = 1\n",
    "      n_mels = 128\n",
    "\n",
    "      mel_spectrogram_transform = torchaudio.transforms.MelSpectrogram(\n",
    "        sample_rate=sample_rate,\n",
    "        n_fft=n_fft,\n",
    "        win_length=win_length,\n",
    "        hop_length=hop_length,\n",
    "        center=True,\n",
    "        pad_mode=\"reflect\",\n",
    "        power=2.0,\n",
    "        norm='slaney',\n",
    "        onesided=True,\n",
    "        n_mels=n_mels,\n",
    "        mel_scale=\"htk\",\n",
    "      )\n",
    "\n",
    "      return mel_spectrogram_transform(waveform)\n",
    "    \n",
    "    def load_audio_data(self):\n",
    "      \n",
    "      audio_file_list = []\n",
    "      data_waveform, data_mel_spectrogram = [], []\n",
    "\n",
    "      for path, subdirs, files in tqdm(os.walk(self.path), colour=\"teal\"):\n",
    "        for name in tqdm(files, colour=\"turquoise\"):\n",
    "            \n",
    "            file_audio_path = os.path.join(path, name)\n",
    "            \n",
    "            try:\n",
    "              waveform, sample_rate = torchaudio.load(\n",
    "                file_audio_path, normalize=self.normalize_audio,\n",
    "                num_frames=self.audio_num_frames\n",
    "              )\n",
    "            except:\n",
    "              print(f\"Got an error while loading {file_audio_path}\")\n",
    "              continue\n",
    "            \n",
    "            waveform = torchaudio.functional.resample(\n",
    "              waveform, orig_freq=self.audio_hop_length, new_freq=1\n",
    "              # orig_freq=sample_rate, \n",
    "              # new_freq=sample_rate / self.audio_hop_length\n",
    "            )\n",
    "            \n",
    "            label = file_audio_path.split(\"/\")[-2]\n",
    "            label_one_hot = self.label_from_str_to_one_hot(label)\n",
    "            \n",
    "            temp_dict_waveform = {\n",
    "              \"label\": label_one_hot,\n",
    "              \"waveform\": waveform\n",
    "            }\n",
    "            \n",
    "            temp_dict_mel_spectrogram = {\n",
    "              \"label\": label_one_hot,\n",
    "              \"mel_spectrogram\": self.get_mel_spectrogram(\n",
    "                waveform, sample_rate\n",
    "              )\n",
    "            }\n",
    "            \n",
    "            data_waveform.append(temp_dict_waveform)\n",
    "            data_mel_spectrogram.append(temp_dict_mel_spectrogram)\n",
    "            \n",
    "      return data_waveform, data_mel_spectrogram\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_converter = DatasetConverter(\n",
    "  path=\"./data/fma_extra_small_organized_by_label/\", \n",
    "  # path=\"./data/fma_large_6_top_level_downsampled_organized_by_label/\", \n",
    "  # KEEP THIS SET TO TRUE WHILE EXPORTING THE DATASETS IN THE \"COMPRESSED\" FORMAT\n",
    "  use_spectrogram=True, \n",
    "  normalize_audio=True, audio_num_frames=1320000, \n",
    "  audio_hop_length=512\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset_converter.data_mel_spectrogram[3][\"mel_spectrogram\"].shape)\n",
    "print(dataset_converter.data_waveform[3][\"waveform\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
