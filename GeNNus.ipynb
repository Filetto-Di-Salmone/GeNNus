{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "import torchaudio\n",
    "import torchaudio.transforms\n",
    "\n",
    "import torchvision\n",
    "\n",
    "\n",
    "import sys, os\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "from tqdm.autonotebook import tqdm\n",
    "\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import librosa\n",
    "import librosa.display\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import gc\n",
    "\n",
    "MANUAL_SEED = 69\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "from datetime import date\n",
    "from datetime import datetime\n",
    "\n",
    "import os.path\n",
    "from os import path\n",
    "  \n",
    "import json\n",
    "\n",
    "import time\n",
    "\n",
    "import copy\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "plt.rcParams['figure.dpi'] = 150\n",
    "plt.rcParams['savefig.dpi'] = 150\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enabling notebook extension jupyter-js-widgets/extension...\n",
      "      - Validating: \u001b[32mOK\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbextension enable --py widgetsnbextension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dir_if_absent(dir_path):\n",
    "  \n",
    "  if not os.path.exists(dir_path):\n",
    "    os.makedirs(dir_path)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FMADataset(Dataset):\n",
    "\n",
    "  def __init__(\n",
    "    self, path, transforms, data_type, mean, std\n",
    "  ):\n",
    "    self.path = path\n",
    "    self.transforms = transforms\n",
    "    self.data_type = data_type,\n",
    "    self.mean = mean\n",
    "    self.std = std\n",
    "    \n",
    "    self.data_paths = self._load_audio_list()\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.data_paths)\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "\n",
    "    data = (torch.load(self.data_paths[idx]) - self.mean) / self.std\n",
    "\n",
    "    label_one_hot = self._label_from_str_to_one_hot(\n",
    "      self.data_paths[idx].split(\"/\")[-2]\n",
    "    )\n",
    "\n",
    "    return data, label_one_hot\n",
    "  \n",
    "  def _label_from_str_to_one_hot(self, label_str: str): \n",
    "  \n",
    "    if label_str == \"Pop\":\n",
    "      return torch.tensor([1, 0, 0, 0, 0, 0]).float()\n",
    "    \n",
    "    if label_str == \"Hip-Hop\":\n",
    "      return torch.tensor([0, 1, 0, 0, 0, 0]).float()\n",
    "    \n",
    "    if label_str == \"Electronic\":\n",
    "      return torch.tensor([0, 0, 1, 0, 0, 0]).float()\n",
    "    \n",
    "    if label_str == \"Rock\":\n",
    "      return torch.tensor([0, 0, 0, 1, 0, 0]).float()\n",
    "\n",
    "    if label_str == \"Folk\":\n",
    "      return torch.tensor([0, 0, 0, 0, 1, 0]).float()\n",
    "\n",
    "    if label_str == \"Jazz\":\n",
    "      return torch.tensor([0, 0, 0, 0, 0, 1]).float()\n",
    "    \n",
    "  \n",
    "  def _load_audio_list(self):\n",
    "    \n",
    "    audio_path_list = []\n",
    "    \n",
    "    for path, subdirs, files in os.walk(self.path):\n",
    "      for name in files:\n",
    "          \n",
    "        file_audio_path = os.path.join(path, name)\n",
    "        \n",
    "        audio_path_list.append(file_audio_path)\n",
    "\n",
    "    return sorted(audio_path_list, reverse=True)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_SIZE = \"s\"\n",
    "DATASET_TYPE = \"waveform\"\n",
    "DATASET_FOLDER = f\"./data/{DATASET_TYPE}\"\n",
    "\n",
    "DATASET_NUM_SAMPLES_PER_SECOND = 8000\n",
    "DATASET_NUM_CHANNELS = 1\n",
    "\n",
    "DATASET_NAME = f\"fma_{DATASET_SIZE}_resampled_{DATASET_NUM_SAMPLES_PER_SECOND}_rechanneled_{DATASET_NUM_CHANNELS}\"\n",
    "\n",
    "dataset_path = f\"{DATASET_FOLDER}/{DATASET_NAME}\"\n",
    "\n",
    "SUMMARY_STATISTICS_PATH = f\"./data/summary_statistics/{DATASET_NAME}/{DATASET_NAME}_summary_statistics.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_statistics_json = open(SUMMARY_STATISTICS_PATH)\n",
    "\n",
    "summary_statistics_dict = json.load(summary_statistics_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "fma_data_transforms = torch.nn.Sequential(\n",
    "  # torchvision.transforms.Normalize(\n",
    "  #   summary_statistics_dict[f\"{DATASET_TYPE}_mean\"],\n",
    "  #   summary_statistics_dict[f\"{DATASET_TYPE}_std\"]\n",
    "  # )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "fma_dataset = FMADataset(\n",
    "  path=dataset_path, \n",
    "  transforms=fma_data_transforms,\n",
    "  data_type=DATASET_TYPE,\n",
    "  mean=summary_statistics_dict[f\"{DATASET_TYPE}_mean\"],\n",
    "  std=summary_statistics_dict[f\"{DATASET_TYPE}_std\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_VAL_PERCENTAGE = 0.9\n",
    "\n",
    "full_size = len(fma_dataset)\n",
    "train_val_size = int(TRAIN_VAL_PERCENTAGE * full_size)\n",
    "test_size = full_size - train_val_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator=torch.Generator().manual_seed(MANUAL_SEED)\n",
    "\n",
    "fma_dataset_train_val, fma_dataset_test = torch.utils.data.random_split(\n",
    "  fma_dataset, [train_val_size, test_size], generator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PERCENTAGE = 0.8\n",
    "\n",
    "full_size = train_val_size\n",
    "train_size = int(TRAIN_PERCENTAGE * full_size)\n",
    "val_size = full_size - train_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "fma_dataset_train, fma_dataset_val = torch.utils.data.random_split(\n",
    "  fma_dataset_train_val, [train_size, val_size], generator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f\"len(fma_dataset_train): {len(fma_dataset_train)}\")\n",
    "# print(f\"len(fma_dataset_val)  : {len(fma_dataset_val)}\")\n",
    "# print(f\"len(fma_dataset_test) : {len(fma_dataset_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **TODO reflect on this and use it as first hypothesis**\n",
    "\n",
    "\"the learning rate and batch size are closely linked â€” small batch sizes perform best with smaller learning rates, while large batch sizes do best on larger learning rates\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "NUM_WORKERS = 16\n",
    "\n",
    "data_logs = {\n",
    "  \"data_type\": DATASET_TYPE,\n",
    "  \"dataset_size\": DATASET_SIZE,\n",
    "  \"batch_size\": BATCH_SIZE,\n",
    "  \"num_samples_per_second\": DATASET_NUM_SAMPLES_PER_SECOND,\n",
    "  \"num_channels\": DATASET_NUM_CHANNELS\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "fma_dataloader_train = torch.utils.data.DataLoader(\n",
    "  fma_dataset_train, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS, \n",
    "  generator=generator\n",
    ")\n",
    "fma_dataloader_val = torch.utils.data.DataLoader(\n",
    "  fma_dataset_val, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS, \n",
    "  generator=generator\n",
    ")\n",
    "fma_dataloader_test = torch.utils.data.DataLoader(\n",
    "  fma_dataset_test, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS, \n",
    "  generator=generator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_num_trainable_parameters(model):\n",
    "  return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "NVIDIA GeForce RTX 2070\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(device)\n",
    "print(\n",
    "  torch.cuda.get_device_name(device) if torch.cuda.is_available() else \"cpu\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_train_id():\n",
    "  return datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_dict_to_disk(dict, full_path):\n",
    "\n",
    "  make_dir_if_absent(\"/\".join(full_path.split(\"/\")[:-1]))\n",
    "\n",
    "  with open(full_path, 'w') as fp:\n",
    "    json.dump(dict, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_ckp(\n",
    "  model, optimizer, ckp_dir, ckp_name, epoch, loss_train, loss_val, loss_test\n",
    "):\n",
    "\n",
    "  model_copy = copy.deepcopy(model)\n",
    "  \n",
    "  full_path_pickle = f\"{ckp_dir}/{ckp_name}_epoch_{epoch}.pth\"\n",
    "  \n",
    "  make_dir_if_absent(dir_path=\"/\".join(full_path_pickle.split('/')[:-1]))\n",
    "  \n",
    "  torch.save(\n",
    "    {\n",
    "      'epoch': epoch,\n",
    "      'model_state_dict': model_copy.cpu().state_dict(),\n",
    "      'optimizer_state_dict': optimizer.state_dict(),\n",
    "      'loss_train': loss_train,\n",
    "      'loss_val': loss_val,\n",
    "      'loss_test': loss_test,\n",
    "    }, \n",
    "    full_path_pickle\n",
    "  )\n",
    "  \n",
    "  torch.save(\n",
    "    model_copy.cpu(), \n",
    "    full_path_pickle\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_ckp(ckp_path, perform_loading_sanity_check):\n",
    "\n",
    "  loaded_model = torch.load(ckp_path)\n",
    "\n",
    "  if perform_loading_sanity_check:\n",
    "\n",
    "    loaded_model.eval()\n",
    "\n",
    "    sanity_check_out = loaded_model(torch.rand((16, 1, 238000)))\n",
    "\n",
    "  return loaded_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num_correct_preds(outputs, labels):\n",
    "  \n",
    "  output_pred_ind = torch.argmax(outputs, dim=1)\n",
    "  labels_ind = torch.argmax(labels, dim=1)\n",
    "  \n",
    "  matching_mask = (output_pred_ind == labels_ind).float()\n",
    "  \n",
    "  num_correct_preds = matching_mask.sum()\n",
    "  \n",
    "  return num_correct_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(\n",
    "  model, optimizer, criterion,\n",
    "  batch_size, train_dl, val_dl, test_dl, \n",
    "  num_epochs, \n",
    "  device, \n",
    "  print_freq, ckp_freq, \n",
    "  ckp_dir, ckp_name,\n",
    "  should_close_tqdm_prog_bars_when_done\n",
    "):\n",
    "\n",
    "  train_id = gen_train_id()\n",
    "  \n",
    "  training_logs = {\n",
    "    \"train_id\": train_id,\n",
    "    \"accuracies\": {},\n",
    "    \"losses\": {}\n",
    "  }\n",
    "  \n",
    "  model = model.to(device)\n",
    "  \n",
    "  pbar_epochs = tqdm(range(num_epochs), colour=\"#9400d3\")\n",
    "  pbar_batches_train = tqdm(\n",
    "    iter(train_dl), colour=\"#4169e1\", leave=False,\n",
    "  )\n",
    "  pbar_batches_val = tqdm(\n",
    "    iter(val_dl), colour=\"#008080\", leave=False,\n",
    "  )\n",
    "  \n",
    "  training_start_time = time.time()\n",
    "\n",
    "  for epoch in range(num_epochs):\n",
    "\n",
    "    running_loss_train = 0.0\n",
    "    running_loss_val   = 0.0\n",
    "    running_loss_test  = -1.0\n",
    "    \n",
    "    num_correct_preds_train = 0.0\n",
    "    num_preds_train = 0.0\n",
    "    accuracy_train = 0.0\n",
    "    \n",
    "    num_correct_preds_val = 0.0\n",
    "    num_preds_val = 0.0\n",
    "    accuracy_val = 0.0\n",
    "    \n",
    "    num_correct_preds_test = 0.0\n",
    "    num_preds_test = 0.000000001\n",
    "    accuracy_test = 0.0\n",
    "        \n",
    "    ## BEGIN training step\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    pbar_batches_train.reset()\n",
    "    pbar_batches_val.reset()\n",
    "    \n",
    "    pbar_epochs.set_description(f\"epoch {epoch}\")\n",
    "    pbar_batches_train.set_description(f\"epoch {epoch}\")\n",
    "    pbar_batches_val.set_description  (f\"epoch {epoch}\")\n",
    "    \n",
    "    for batch_x, batch_y in iter(train_dl):\n",
    "\n",
    "      inputs, labels = batch_x, batch_y\n",
    "      inputs, labels = inputs.to(device), labels.to(device)\n",
    "      \n",
    "      optimizer.zero_grad()\n",
    "\n",
    "      outputs = model(inputs)\n",
    "      outputs = outputs.squeeze(-1)\n",
    "      \n",
    "      loss = criterion(outputs, labels)\n",
    "      \n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "\n",
    "      running_loss_train += loss.item() * batch_x.shape[0]\n",
    "      \n",
    "      num_correct_preds_train += get_num_correct_preds(outputs, labels)\n",
    "      num_preds_train += outputs.shape[0]\n",
    "      \n",
    "      pbar_batches_train.update(1)\n",
    "      \n",
    "    \n",
    "    ## END training step\n",
    "    \n",
    "    ## BEGIN validation step\n",
    "    \n",
    "    with torch.no_grad():\n",
    "      \n",
    "      model.eval()\n",
    "      \n",
    "      for batch_x, batch_y in iter(val_dl):\n",
    "\n",
    "        inputs, labels = batch_x, batch_y\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        outputs = model(inputs)\n",
    "        outputs = outputs.squeeze(-1)\n",
    "        \n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        running_loss_val += loss.item() * batch_x.shape[0]\n",
    "        \n",
    "        num_correct_preds_val += get_num_correct_preds(outputs, labels)\n",
    "        num_preds_val += outputs.shape[0]\n",
    "        \n",
    "        pbar_batches_val.update(1)\n",
    "        \n",
    "    ## END validation step\n",
    "    \n",
    "    ## BEGIN test step\n",
    "    \n",
    "    if (epoch + 1 == num_epochs):\n",
    "      \n",
    "      pbar_batches_test = tqdm(\n",
    "        iter(test_dl), colour=\"#808000\", leave=False,\n",
    "      )\n",
    "      pbar_batches_test.set_description  (f\"epoch {epoch}\")\n",
    "    \n",
    "      with torch.no_grad():\n",
    "        \n",
    "        model.eval()\n",
    "        \n",
    "        for batch_x, batch_y in iter(test_dl):\n",
    "\n",
    "          inputs, labels = batch_x, batch_y\n",
    "          inputs, labels = inputs.to(device), labels.to(device)\n",
    "          \n",
    "          outputs = model(inputs)\n",
    "          outputs = outputs.squeeze(-1)\n",
    "          \n",
    "          loss = criterion(outputs, labels)\n",
    "          \n",
    "          running_loss_test += loss.item() * batch_x.shape[0]\n",
    "          \n",
    "          num_correct_preds_test += get_num_correct_preds(outputs, labels)\n",
    "          num_preds_test += outputs.shape[0]\n",
    "          \n",
    "          pbar_batches_test.update(1)\n",
    "        \n",
    "    ## END test step\n",
    "    \n",
    "    accuracy_train = num_correct_preds_train / num_preds_train\n",
    "    accuracy_val = num_correct_preds_val / num_preds_val\n",
    "    accuracy_test = num_correct_preds_test / num_preds_test\n",
    "    \n",
    "    training_logs[\"accuracies\"][str(epoch)] = {\n",
    "      \"accuracy_train\": accuracy_train.cpu().item(),\n",
    "      \"accuracy_val\": accuracy_val.cpu().item(),\n",
    "    }\n",
    "    training_logs[\"losses\"][str(epoch)] = {\n",
    "      \"loss_train\": running_loss_train,\n",
    "      \"loss_val\": running_loss_val,\n",
    "    }\n",
    "    \n",
    "    pbar_epochs.update(1)\n",
    "    \n",
    "    if ((epoch + 1) % print_freq == 0):  \n",
    "      tqdm.write(\n",
    "        f\"epoch: {epoch + 1}\\n\" + \n",
    "        f\"      train loss: {running_loss_train}, train acc: {accuracy_train}\\n\" + \n",
    "        f\"      val loss  : {running_loss_val}, val acc  : {accuracy_val}\\n\"\n",
    "      )\n",
    "    \n",
    "    if ((epoch + 1) == num_epochs):\n",
    "      tqdm.write(\n",
    "        f\"      test loss : {running_loss_test}, test acc : {accuracy_test}\"\n",
    "      )\n",
    "      \n",
    "      training_logs[\"accuracies\"][str(epoch)][\n",
    "        \"accuracy_test\"\n",
    "      ] = accuracy_test.cpu().item()\n",
    "      \n",
    "      training_logs[\"losses\"][str(epoch)][\n",
    "        \"loss_test\"\n",
    "      ] = running_loss_test\n",
    "      \n",
    "    if (ckp_freq != None and (epoch + 1) % ckp_freq == 0):\n",
    "      \n",
    "      store_ckp(\n",
    "        model=model, optimizer=optimizer, \n",
    "        ckp_dir=ckp_dir, ckp_name=ckp_name, epoch=epoch, \n",
    "        loss_train=running_loss_train, \n",
    "        loss_val=running_loss_val, \n",
    "        loss_test=running_loss_test\n",
    "      )\n",
    "  \n",
    "  training_end_time = time.time()\n",
    "\n",
    "  training_logs[\"training_time_secs\"] = training_end_time - training_start_time\n",
    "\n",
    "  if (should_close_tqdm_prog_bars_when_done):\n",
    "    pbar_epochs.container.close()\n",
    "    pbar_batches_train.close()\n",
    "    pbar_batches_val.close()\n",
    "    pbar_batches_test.close()\n",
    "  \n",
    "  return training_logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Design motivations\n",
    "\n",
    "First layers --> neural compression layers --> dimensionality reduction to roughly match dimensions of this paper https://arxiv.org/pdf/1703.01789.pdf\n",
    "\n",
    "Mid and final layers --> taken 1:1 from the paper linked above\n",
    "\n",
    "Batch norm placed BEFORE the activation function, as described in the og paper https://arxiv.org/abs/1502.03167 and explained by Bengio in his DL book https://www.deeplearningbook.org/contents/optimization.html in section 8.7.1\n",
    "\n",
    "Dropout placed according to the og paper: https://arxiv.org/pdf/1207.0580.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "  def __init__(\n",
    "    self, \n",
    "    num_layers, \n",
    "    kernel_sizes, strides, \n",
    "    in_channels, num_filters,\n",
    "    pool_sizes, pool_strides,\n",
    "    dropout_p_conv, dropout_p_linear\n",
    "  ):\n",
    "    super().__init__()\n",
    "\n",
    "    self.num_layers = num_layers \n",
    "    self.kernel_sizes = kernel_sizes \n",
    "    self.strides = strides \n",
    "    self.in_channels = in_channels \n",
    "    self.num_filters = num_filters\n",
    "    self.pool_sizes = pool_sizes \n",
    "    self.pool_strides = pool_strides\n",
    "    \n",
    "    self.dropout_p_conv = dropout_p_conv\n",
    "    self.dropout_p_linear = dropout_p_linear\n",
    "\n",
    "    self.bns = {\n",
    "      \"4\": nn.BatchNorm1d(num_features=4),\n",
    "      \"6\": nn.BatchNorm1d(num_features=6),\n",
    "      \"8\": nn.BatchNorm1d(num_features=8),\n",
    "      \"16\": nn.BatchNorm1d(num_features=16),\n",
    "      \"32\": nn.BatchNorm1d(num_features=32),\n",
    "      \"64\": nn.BatchNorm1d(num_features=64),\n",
    "      \"128\": nn.BatchNorm1d(num_features=128),\n",
    "      \"256\": nn.BatchNorm1d(num_features=256),\n",
    "      \"512\": nn.BatchNorm1d(num_features=512)\n",
    "    }\n",
    "    \n",
    "    self.neural_network = nn.Sequential()\n",
    "    \n",
    "    for i in range(num_layers):\n",
    "      \n",
    "      conv_layer = nn.Conv1d(\n",
    "        kernel_size=self.kernel_sizes[i],\n",
    "        stride=self.strides[i],\n",
    "        in_channels=in_channels,\n",
    "        out_channels=self.num_filters[i]\n",
    "      )\n",
    "      torch.nn.init.xavier_uniform_(conv_layer.weight)\n",
    "\n",
    "      \n",
    "      pooling_layer = nn.MaxPool1d(\n",
    "        kernel_size=self.pool_sizes[i],\n",
    "        stride=self.pool_strides[i],\n",
    "      )\n",
    "      \n",
    "      in_channels = self.num_filters[i]\n",
    "      \n",
    "      self.neural_network.add_module(name=f\"conv_{i}\", module=conv_layer)\n",
    "      \n",
    "      self.neural_network.add_module(name=f\"pool_{i}\", module=pooling_layer)\n",
    "        \n",
    "      self.neural_network.add_module(\n",
    "        name=f\"batchnorm_{i}\", module=self.bns[str(self.num_filters[i])]\n",
    "      )\n",
    "      \n",
    "      if (i < num_layers - 1):\n",
    "        \n",
    "        self.neural_network.add_module(name=f\"activ_{i}\", module=nn.ReLU())\n",
    "\n",
    "      else:\n",
    "        \n",
    "        self.neural_network.add_module(name=f\"activ_{i}\", module=nn.Sigmoid())\n",
    "\n",
    "      if (i < num_layers - 2):\n",
    "\n",
    "        self.neural_network.add_module(\n",
    "          name=f\"dropout_{i}\", module=nn.Dropout(p=self.dropout_p_conv))\n",
    "        \n",
    "      if (i == num_layers - 2):\n",
    "\n",
    "        self.neural_network.add_module(\n",
    "          name=f\"dropout_{i}\", module=nn.Dropout(p=self.dropout_p_linear)\n",
    "        )\n",
    "  \n",
    "  def forward(self, x):    \n",
    "    x = self.neural_network(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "  def get_model_setup(self):\n",
    "    \n",
    "    return {\n",
    "      \"num_layers\": self.num_layers, \n",
    "      \"kernel_sizes\": self.kernel_sizes, \n",
    "      \"strides\": self.strides, \n",
    "      \"in_channels\": self.in_channels, \n",
    "      \"num_filters\": self.num_filters,\n",
    "      \"pool_sizes\": self.pool_sizes, \n",
    "      \"pool_strides\": self.pool_strides,\n",
    "      \"dropout_p_conv\": self.dropout_p_conv,\n",
    "      \"dropout_p_linear\": self.dropout_p_linear,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss_curves(stats):\n",
    "  epochs = stats[\"training_logs\"][\"losses\"].keys()\n",
    "  \n",
    "  loss_train = [\n",
    "    j[\"loss_train\"] for j in stats[\"training_logs\"][\"losses\"].values()\n",
    "  ]\n",
    "  \n",
    "  loss_val = [j[\"loss_val\"] for j in stats[\"training_logs\"][\"losses\"].values()]\n",
    "\n",
    "  sns.lineplot(\n",
    "    x=epochs,\n",
    "    y=loss_train,\n",
    "    legend=\"full\",\n",
    "    label=\"train loss\"\n",
    "  )\n",
    "\n",
    "  sns.lineplot(\n",
    "    x=epochs,\n",
    "    y=loss_val,\n",
    "    legend=\"full\",\n",
    "    label=\"val loss\"\n",
    "  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-fold cross validation for hyperparameter search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_fold_cv_num_layers = 5\n",
    "\n",
    "k_fold_cv_kernel_sizes =[64, 32, 16,   8,   4]\n",
    "k_fold_cv_pool_sizes   =[ 8,  8,  2,   2,   4]\n",
    "k_fold_cv_strides      =[ 3,  3,  2,   2,   2]\n",
    "k_fold_cv_pool_strides =[ 8,  8,  2,   4,   2]\n",
    "k_fold_cv_num_filters  =[16, 32, 64, 128,   6]\n",
    "\n",
    "k_fold_cv_in_channels   = 1 if DATASET_TYPE == \"waveform\" else 2\n",
    "\n",
    "K_FOLD_CV_DROPOUT_P_CONV = 0.0\n",
    "K_FOLD_CV_DROPOUT_P_LINEAR = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_factory(\n",
    "  num_layers,\n",
    "  kernel_sizes,\n",
    "  strides,\n",
    "  in_channels,\n",
    "  num_filters,\n",
    "  pool_sizes,\n",
    "  pool_strides,\n",
    "  dropout_p_conv, \n",
    "  dropout_p_linear\n",
    "):\n",
    "  return CNN(\n",
    "  num_layers=num_layers,\n",
    "  kernel_sizes=kernel_sizes, \n",
    "  strides=strides, \n",
    "  in_channels=in_channels, \n",
    "  num_filters=num_filters,\n",
    "  pool_sizes=pool_sizes,\n",
    "  pool_strides=pool_strides,\n",
    "  dropout_p_conv=dropout_p_conv,\n",
    "  dropout_p_linear=dropout_p_linear\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = 0.001\n",
    "# LR = 0.01\n",
    "MOMENTUM = 0.9\n",
    "WEIGHT_DECAY = 1e-6\n",
    "OPTIMIZER_NAME = \"SGD\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimizer_factory(optimizer_name, model, lr, momentum, weight_decay):\n",
    "\n",
    "  if optimizer_name == \"SGD\":\n",
    "    optimizer = optim.SGD(\n",
    "      model.parameters(), \n",
    "      lr=lr, \n",
    "      momentum=momentum,\n",
    "      nesterov=True,\n",
    "      weight_decay=weight_decay\n",
    "    )\n",
    "\n",
    "    optimizer_config = {\n",
    "    \"lr\": lr, \n",
    "    \"momentum\": momentum, \n",
    "    \"weight_decay\": weight_decay,\n",
    "    \"nesterov\": True\n",
    "  }  \n",
    "\n",
    "  elif optimizer_name == \"Adam\":\n",
    "\n",
    "    optimizer = optim.Adam(\n",
    "      model.parameters(),\n",
    "      lr=lr,\n",
    "      weight_decay=weight_decay\n",
    "    )\n",
    "\n",
    "    optimizer_config = {\n",
    "    \"lr\": lr, \n",
    "    \"momentum\": momentum, \n",
    "    \"weight_decay\": weight_decay\n",
    "  }  \n",
    "    \n",
    "\n",
    "  return optimizer, optimizer_config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "K_FOLD_CV_NUM_FOLDS = 3\n",
    "\n",
    "K_FOLD_CV_BATCH_SIZE = 16\n",
    "\n",
    "K_FOLD_CV_NUM_EPOCHS = 50\n",
    "\n",
    "K_FOLD_CV_PRINT_FREQ = int(K_FOLD_CV_NUM_EPOCHS / 10)\n",
    "\n",
    "K_FOLD_CV_CKP_FREQ = int(K_FOLD_CV_NUM_EPOCHS / 5)\n",
    "\n",
    "K_FOLD_CV_LOGS_FOLDER = \"./k_fold_cv\"\n",
    "\n",
    "K_FOLD_CV_CKP_FOLDER = K_FOLD_CV_LOGS_FOLDER\n",
    "\n",
    "K_FOLD_CV_SHOULD_CLOSE_TQDM_PROG_BARS_WHEN_DONE=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_models = [\n",
    "\n",
    "  cnn_factory(\n",
    "    num_layers=k_fold_cv_num_layers,\n",
    "    kernel_sizes=k_fold_cv_kernel_sizes, \n",
    "    strides=k_fold_cv_strides, \n",
    "    in_channels=k_fold_cv_in_channels, \n",
    "    num_filters=k_fold_cv_num_filters,\n",
    "    pool_sizes=k_fold_cv_pool_sizes,\n",
    "    pool_strides=k_fold_cv_pool_strides,\n",
    "    dropout_p_conv=K_FOLD_CV_DROPOUT_P_CONV,\n",
    "    dropout_p_linear=K_FOLD_CV_DROPOUT_P_LINEAR\n",
    "  ) for _ in range(0, K_FOLD_CV_NUM_FOLDS)\n",
    "\n",
    "]\n",
    "\n",
    "cv_criterions = [nn.CrossEntropyLoss() for _ in range(0, K_FOLD_CV_NUM_FOLDS)]\n",
    "\n",
    "cv_opts = [\n",
    "  optimizer_factory(\n",
    "    optimizer_name=OPTIMIZER_NAME,\n",
    "    model=cv_models[i],\n",
    "    lr=LR,\n",
    "    momentum=MOMENTUM,\n",
    "    weight_decay=WEIGHT_DECAY\n",
    "  ) for i in range(0, K_FOLD_CV_NUM_FOLDS)\n",
    "]\n",
    "\n",
    "cv_optimizers = [opt for opt, _ in cv_opts]\n",
    "cv_optimizers_configs = [opt_conf for _, opt_conf in cv_opts]\n",
    "\n",
    "cv_train_dls = []\n",
    "cv_val_dls = []\n",
    "cv_test_dls = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_fold = KFold(n_splits=K_FOLD_CV_NUM_FOLDS, shuffle=True)\n",
    "\n",
    "cv_dataset = torch.utils.data.ConcatDataset(\n",
    "  [fma_dataset_train, fma_dataset_val]\n",
    ")\n",
    "\n",
    "for fold, (train_idxs, val_idxs) in enumerate(k_fold.split(cv_dataset)):\n",
    "\n",
    "  train_subsampler = torch.utils.data.SubsetRandomSampler(train_idxs)\n",
    "  val_subsampler = torch.utils.data.SubsetRandomSampler(val_idxs)\n",
    "\n",
    "  cv_train_dls.append(\n",
    "    torch.utils.data.DataLoader(\n",
    "      cv_dataset, batch_size=K_FOLD_CV_BATCH_SIZE, sampler=train_subsampler\n",
    "    )\n",
    "  )\n",
    "\n",
    "  cv_val_dls.append(\n",
    "    torch.utils.data.DataLoader(\n",
    "      cv_dataset, batch_size=K_FOLD_CV_BATCH_SIZE, sampler=val_subsampler\n",
    "    )\n",
    "  )\n",
    "\n",
    "  cv_test_dls.append(\n",
    "    torch.utils.data.DataLoader(\n",
    "      fma_dataset_test, batch_size=K_FOLD_CV_BATCH_SIZE\n",
    "    )\n",
    "  )\n",
    "\n",
    "cv_data_logs = {\n",
    "  \"data_type\": DATASET_TYPE,\n",
    "  \"dataset_size\": DATASET_SIZE,\n",
    "  \"batch_size\": K_FOLD_CV_BATCH_SIZE,\n",
    "  \"num_samples_per_second\": DATASET_NUM_SAMPLES_PER_SECOND,\n",
    "  \"num_channels\": DATASET_NUM_CHANNELS\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_k_fold_cv(\n",
    "  cv_id,\n",
    "  cv_num_folds,\n",
    "  cv_models, cv_optimizers, cv_criterions,\n",
    "  batch_size, \n",
    "  cv_train_dls, cv_val_dls, cv_test_dls, \n",
    "  cv_num_epochs, \n",
    "  cv_device, \n",
    "  cv_print_freq, cv_ckp_freq, \n",
    "  cv_ckp_dir,\n",
    "  cv_should_close_tqdm_prog_bars_when_done\n",
    "):\n",
    "\n",
    "  cv_training_logs = {}\n",
    "\n",
    "  pbar_folds = tqdm(range(cv_num_folds), colour=\"#b22222\")\n",
    "\n",
    "  for fold in pbar_folds:\n",
    "    pbar_folds.set_description(f\"fold {fold}\")\n",
    "\n",
    "    cv_ckp_fold_dir = f\"{cv_ckp_dir}/fold_{fold}\"\n",
    "\n",
    "    training_log = train_model(\n",
    "      model=cv_models[fold], \n",
    "      optimizer=cv_optimizers[fold], criterion=cv_criterions[fold],\n",
    "      batch_size=batch_size,\n",
    "      train_dl=cv_train_dls[fold], val_dl=cv_val_dls[fold], test_dl=cv_test_dls[fold],\n",
    "      num_epochs=cv_num_epochs, \n",
    "      device=cv_device,\n",
    "      print_freq=cv_print_freq, ckp_freq=cv_ckp_freq, \n",
    "      ckp_dir=cv_ckp_fold_dir, ckp_name=f\"{cv_id}_fold_{fold}\",\n",
    "      should_close_tqdm_prog_bars_when_done=cv_should_close_tqdm_prog_bars_when_done,\n",
    "    )\n",
    "\n",
    "    cv_training_logs[str(fold)] = training_log\n",
    "\n",
    "    pbar_folds.update(1)\n",
    "\n",
    "  return cv_training_logs\n",
    "  \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c11ac632cac48e0b397800491e63ab1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1f4973b77c4465ca095cb597a782b22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03c180c378bf4142b93a025c37c30b4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/105 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55810158203f452499ae21b60fb29a76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/53 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 5\n",
      "      train loss: 2865.691900730133, train acc: 0.2767106890678406\n",
      "      val loss  : 1435.3710670471191, val acc  : 0.2589928209781647\n",
      "\n",
      "epoch: 10\n",
      "      train loss: 2802.216941356659, train acc: 0.3529411554336548\n",
      "      val loss  : 1425.364797592163, val acc  : 0.30215826630592346\n",
      "\n",
      "epoch: 15\n",
      "      train loss: 2760.5161814689636, train acc: 0.40096038579940796\n",
      "      val loss  : 1417.3666973114014, val acc  : 0.3117506206035614\n",
      "\n",
      "epoch: 20\n",
      "      train loss: 2737.557002544403, train acc: 0.4213685393333435\n",
      "      val loss  : 1404.5759601593018, val acc  : 0.3465227782726288\n",
      "\n",
      "epoch: 25\n",
      "      train loss: 2688.1250414848328, train acc: 0.47298917174339294\n",
      "      val loss  : 1411.1642217636108, val acc  : 0.33693045377731323\n",
      "\n",
      "epoch: 30\n",
      "      train loss: 2648.9542214870453, train acc: 0.5036014318466187\n",
      "      val loss  : 1400.5500745773315, val acc  : 0.3441247045993805\n",
      "\n",
      "epoch: 35\n",
      "      train loss: 2609.8220479488373, train acc: 0.5480191707611084\n",
      "      val loss  : 1401.5773603916168, val acc  : 0.3609112799167633\n",
      "\n",
      "epoch: 40\n",
      "      train loss: 2575.681945323944, train acc: 0.5678271055221558\n",
      "      val loss  : 1390.8282132148743, val acc  : 0.3752997815608978\n",
      "\n",
      "epoch: 45\n",
      "      train loss: 2536.1289825439453, train acc: 0.6056422591209412\n",
      "      val loss  : 1403.8705430030823, val acc  : 0.34892088174819946\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c3bf01c5f924969bef9c66808fdf22b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 50\n",
      "      train loss: 2509.552511692047, train acc: 0.6344537734985352\n",
      "      val loss  : 1385.4403748512268, val acc  : 0.3609112799167633\n",
      "\n",
      "      test loss : 467.13998651504517, test acc : 0.3057554066181183\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "221b2d9c93cf4ddc85a3b7bf6694a3a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a532dda767a040d299c6653eeec59362",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/105 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6be3442c93340fc943645a80985d97b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/53 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 5\n",
      "      train loss: 2843.6626554727554, train acc: 0.29274144768714905\n",
      "      val loss  : 1415.6984040737152, val acc  : 0.31092435121536255\n",
      "\n",
      "epoch: 10\n",
      "      train loss: 2802.2284297943115, train acc: 0.33833232522010803\n",
      "      val loss  : 1410.2507808208466, val acc  : 0.33253300189971924\n",
      "\n",
      "epoch: 15\n",
      "      train loss: 2764.7923772335052, train acc: 0.3833233118057251\n",
      "      val loss  : 1396.6739814281464, val acc  : 0.34693875908851624\n",
      "\n",
      "epoch: 20\n",
      "      train loss: 2726.8604683876038, train acc: 0.4199160039424896\n",
      "      val loss  : 1388.1588621139526, val acc  : 0.37575027346611023\n",
      "\n",
      "epoch: 25\n",
      "      train loss: 2696.170589566231, train acc: 0.4427114427089691\n",
      "      val loss  : 1382.5210319757462, val acc  : 0.3697478771209717\n",
      "\n",
      "epoch: 30\n",
      "      train loss: 2659.1684885025024, train acc: 0.47150567173957825\n",
      "      val loss  : 1387.9360805749893, val acc  : 0.394957959651947\n",
      "\n",
      "epoch: 35\n",
      "      train loss: 2607.6289899349213, train acc: 0.5410917401313782\n",
      "      val loss  : 1386.2552857398987, val acc  : 0.3925570249557495\n",
      "\n",
      "epoch: 40\n",
      "      train loss: 2578.734334230423, train acc: 0.5686862468719482\n",
      "      val loss  : 1384.7040696144104, val acc  : 0.38055220246315\n",
      "\n",
      "epoch: 45\n",
      "      train loss: 2547.4621028900146, train acc: 0.602279543876648\n",
      "      val loss  : 1381.4955874681473, val acc  : 0.4045618176460266\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b04cca340c7e420689c11e66872f110c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 50\n",
      "      train loss: 2512.7059338092804, train acc: 0.6184762716293335\n",
      "      val loss  : 1376.858373761177, val acc  : 0.38895556330680847\n",
      "\n",
      "      test loss : 469.822368144989, test acc : 0.3381294906139374\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e46089aaf4e3485ebb80f4c1410c439c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5e5003479ec4556ad248334b0d366a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/105 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a912c418ab2457da19643d067b119ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/53 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 5\n",
      "      train loss: 2848.1731390953064, train acc: 0.2939411997795105\n",
      "      val loss  : 1427.7052655220032, val acc  : 0.304921954870224\n",
      "\n",
      "epoch: 10\n",
      "      train loss: 2798.194926261902, train acc: 0.3533293306827545\n",
      "      val loss  : 1413.7291071414948, val acc  : 0.3313325345516205\n",
      "\n",
      "epoch: 15\n",
      "      train loss: 2762.613587975502, train acc: 0.3881223499774933\n",
      "      val loss  : 1406.9612481594086, val acc  : 0.3481392562389374\n",
      "\n",
      "epoch: 20\n",
      "      train loss: 2730.4877676963806, train acc: 0.39772045612335205\n",
      "      val loss  : 1406.8977580070496, val acc  : 0.33733493089675903\n",
      "\n",
      "epoch: 25\n",
      "      train loss: 2685.3711663484573, train acc: 0.4655068814754486\n",
      "      val loss  : 1398.3675383329391, val acc  : 0.3601440489292145\n",
      "\n",
      "epoch: 30\n",
      "      train loss: 2673.1147676706314, train acc: 0.4649069905281067\n",
      "      val loss  : 1385.7636787891388, val acc  : 0.3673469126224518\n",
      "\n",
      "epoch: 35\n",
      "      train loss: 2617.5842628479004, train acc: 0.5020995736122131\n",
      "      val loss  : 1387.150158882141, val acc  : 0.3625450134277344\n",
      "\n",
      "epoch: 40\n",
      "      train loss: 2578.0264143943787, train acc: 0.5740851759910583\n",
      "      val loss  : 1384.9369525909424, val acc  : 0.36374548077583313\n",
      "\n",
      "epoch: 45\n",
      "      train loss: 2547.059853553772, train acc: 0.603479266166687\n",
      "      val loss  : 1380.5933527946472, val acc  : 0.3697478771209717\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22dd8a5c2c874483b6294a46fe3b8e86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 50\n",
      "      train loss: 2524.9277789592743, train acc: 0.6088781952857971\n",
      "      val loss  : 1384.5257527828217, val acc  : 0.3685474097728729\n",
      "\n",
      "      test loss : 466.57611989974976, test acc : 0.34532374143600464\n"
     ]
    }
   ],
   "source": [
    "k_fold_cv_id = gen_train_id()\n",
    "\n",
    "k_fold_cv_training_logs = perform_k_fold_cv(\n",
    "  cv_id=k_fold_cv_id,\n",
    "  cv_num_folds=K_FOLD_CV_NUM_FOLDS,\n",
    "  cv_models=cv_models, cv_optimizers=cv_optimizers, cv_criterions=cv_criterions,\n",
    "  batch_size=K_FOLD_CV_BATCH_SIZE, \n",
    "  cv_train_dls=cv_train_dls, cv_val_dls=cv_val_dls, cv_test_dls=cv_test_dls,\n",
    "  cv_num_epochs=K_FOLD_CV_NUM_EPOCHS, \n",
    "  cv_device=device, \n",
    "  cv_print_freq=K_FOLD_CV_PRINT_FREQ, cv_ckp_freq=K_FOLD_CV_CKP_FREQ, \n",
    "  cv_ckp_dir=f\"{K_FOLD_CV_CKP_FOLDER}/{k_fold_cv_id}\",\n",
    "  cv_should_close_tqdm_prog_bars_when_done=K_FOLD_CV_SHOULD_CLOSE_TQDM_PROG_BARS_WHEN_DONE\n",
    ")\n",
    "\n",
    "k_fold_cv_stats = {\n",
    "  \"stats_type\": \"k_fold_cross_validation\",\n",
    "  \"k_folds_cv_num_folds\": K_FOLD_CV_NUM_FOLDS,\n",
    "  \"data_logs\": cv_data_logs,\n",
    "  \"optimizer_config\": cv_optimizers_configs[0], # all the same, one is enough\n",
    "  \"model_setup\": cv_models[0].get_model_setup(), # all the same, one is enough\n",
    "  \"training_logs\": k_fold_cv_training_logs,\n",
    "}\n",
    "\n",
    "save_dict_to_disk(\n",
    "  dict=k_fold_cv_stats,\n",
    "  full_path=f\"{K_FOLD_CV_LOGS_FOLDER}/{k_fold_cv_id}/{k_fold_cv_id}_stats.json\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform end-to-end training\n",
    "\n",
    "(using hyperparams found via k-fold cross validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = 0.001\n",
    "MOMENTUM = 0.9\n",
    "WEIGHT_DECAY = 1e-6\n",
    "OPTIMIZER_NAME = \"SGD\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
