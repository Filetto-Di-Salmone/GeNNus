{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> Convolutional layer size calculations\n",
    "\n",
    "Set of utilities to show \"sizes\" of a convolutional layer, including out shape and number of trainable parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "import torchaudio\n",
    "import torchaudio.transforms\n",
    "\n",
    "import torchvision\n",
    "\n",
    "\n",
    "import sys, os\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "from tqdm.autonotebook import tqdm\n",
    "\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import librosa\n",
    "import librosa.display\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import gc\n",
    "\n",
    "MANUAL_SEED = 69\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "from datetime import date\n",
    "from datetime import datetime\n",
    "\n",
    "import os.path\n",
    "from os import path\n",
    "  \n",
    "import json\n",
    "\n",
    "import time\n",
    "\n",
    "import copy\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "plt.rcParams['figure.dpi'] = 200\n",
    "plt.rcParams['savefig.dpi'] = 200\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import random\n",
    "\n",
    "from pprint import pformat\n",
    "\n",
    "import math\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_output_length(length_in, kernel_size, stride=1, padding=0, dilation=1):\n",
    "  return (\n",
    "    length_in + 2 * padding - dilation * (kernel_size - 1) - 1\n",
    "  ) // stride + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_pool_length(w, f, s):\n",
    "  return math.floor( ( ( w - f ) / s ) + 1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_num_params_conv_layer(\n",
    "  channels_in, kernel_width, kernel_height, channels_out\n",
    "):\n",
    "  return channels_in * kernel_width * kernel_height * channels_out + channels_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compr_out_0_out: 9914, num_params: 520\n",
      "compr_out_1_out: 411, num_params: 4112\n",
      "compr_out_2_out: 99, num_params: 8224\n",
      "compr_out_3_out: 12, num_params: 16448\n",
      "compr_out_4_out: 1, num_params: 1542\n",
      "\n",
      "\n",
      "total number of params: 30846\n"
     ]
    }
   ],
   "source": [
    "# kernel_sizes = [64, 32, 16,   8,   4]\n",
    "# pool_sizes   = [ 8,  8,  2,   2,   4]\n",
    "# strides      = [ 3,  3,  2,   2,   2]\n",
    "# pool_strides = [ 8,  8,  2,   4,   2]\n",
    "# num_filters  = [16, 32, 64, 128,   6]\n",
    "\n",
    "# kernel_sizes = [64, 32, 16,   8,   4]\n",
    "# pool_sizes   = [ 8,  8,  2,   2,   4]\n",
    "# strides      = [ 3,  3,  2,   2,   2]\n",
    "# pool_strides = [ 8,  8,  2,   4,   2]\n",
    "# num_filters  = [ 8, 16, 32,  64,   6]\n",
    "\n",
    "NUM_LAYERS = len(kernel_sizes)\n",
    "\n",
    "\n",
    "INITIAL_AUDIO_NUM_FRAMES = 238000 # --> 8 kHz\n",
    "compr_out_size = INITIAL_AUDIO_NUM_FRAMES\n",
    "\n",
    "channels_in = 1\n",
    "\n",
    "tot_num_params = 0\n",
    "\n",
    "for compr_id, kernel_size, stride, pool_size, pool_stride, channels_out in zip(\n",
    "  range(NUM_LAYERS), \n",
    "  kernel_sizes, strides, \n",
    "  pool_sizes, pool_strides,\n",
    "  num_filters\n",
    "):\n",
    "  \n",
    "  compr_out_size = calculate_output_length(\n",
    "    compr_out_size, kernel_size=kernel_size, stride=stride\n",
    "  )\n",
    "  \n",
    "  compr_out_size = calculate_pool_length(compr_out_size, pool_size, pool_stride)\n",
    "\n",
    "  num_params = calculate_num_params_conv_layer(\n",
    "    channels_in=channels_in, kernel_width=kernel_size, kernel_height=1, \n",
    "    channels_out=channels_out\n",
    "  )\n",
    "\n",
    "  channels_in = channels_out\n",
    "  \n",
    "  print(f\"compr_out_{compr_id}_out: {compr_out_size}, num_params: {num_params}\")\n",
    "\n",
    "  tot_num_params += num_params\n",
    "\n",
    "print(f\"\\n\\ntotal number of params: {tot_num_params}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "  def __init__(\n",
    "    self, \n",
    "    num_layers, \n",
    "    kernel_sizes, strides, \n",
    "    in_channels, num_filters,\n",
    "    pool_sizes, pool_strides,\n",
    "    dropout_p_conv, dropout_p_linear\n",
    "  ):\n",
    "    super().__init__()\n",
    "\n",
    "    self.num_layers = num_layers \n",
    "    self.kernel_sizes = kernel_sizes \n",
    "    self.strides = strides \n",
    "    self.in_channels = in_channels \n",
    "    self.num_filters = num_filters\n",
    "    self.pool_sizes = pool_sizes \n",
    "    self.pool_strides = pool_strides\n",
    "    \n",
    "    self.dropout_p_conv = dropout_p_conv\n",
    "    self.dropout_p_linear = dropout_p_linear\n",
    "\n",
    "\n",
    "    self.bns = {\n",
    "      \"1\": nn.BatchNorm2d(num_features=1),\n",
    "      \"2\": nn.BatchNorm2d(num_features=2),\n",
    "      \"4\": nn.BatchNorm2d(num_features=4),\n",
    "      \"6\": nn.BatchNorm2d(num_features=6),\n",
    "      \"8\": nn.BatchNorm2d(num_features=8),\n",
    "      \"16\": nn.BatchNorm2d(num_features=16),\n",
    "      \"32\": nn.BatchNorm2d(num_features=32),\n",
    "      \"64\": nn.BatchNorm2d(num_features=64),\n",
    "      \"128\": nn.BatchNorm2d(num_features=128),\n",
    "      \"256\": nn.BatchNorm2d(num_features=256),\n",
    "      \"512\": nn.BatchNorm2d(num_features=512)\n",
    "    }\n",
    "    \n",
    "    self.convs = nn.Sequential()\n",
    "    \n",
    "    for i in range(num_layers):\n",
    "      \n",
    "      conv_layer = nn.Conv2d(\n",
    "        kernel_size=self.kernel_sizes[i],\n",
    "        stride=self.strides[i],\n",
    "        in_channels=in_channels,\n",
    "        out_channels=self.num_filters[i]\n",
    "      )\n",
    "      torch.nn.init.xavier_uniform_(conv_layer.weight)\n",
    "\n",
    "      \n",
    "      pooling_layer = nn.MaxPool2d(\n",
    "        kernel_size=self.pool_sizes[i],\n",
    "        stride=self.pool_strides[i],\n",
    "      )\n",
    "      \n",
    "      in_channels = self.num_filters[i]\n",
    "      \n",
    "      self.convs.add_module(name=f\"conv_{i}\", module=conv_layer)\n",
    "      \n",
    "      self.convs.add_module(name=f\"pool_{i}\", module=pooling_layer)\n",
    "        \n",
    "      self.convs.add_module(\n",
    "        name=f\"batchnorm_{i}\", module=self.bns[str(self.num_filters[i])]\n",
    "      )\n",
    "      \n",
    "      self.convs.add_module(name=f\"activ_{i}\", module=nn.ReLU())\n",
    "\n",
    "\n",
    "    \n",
    "  \n",
    "  def forward(self, x):    \n",
    "    x = self.convs(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "  def get_model_setup(self):\n",
    "    \n",
    "    return {\n",
    "      \"num_layers\": self.num_layers, \n",
    "      \"kernel_sizes\": self.kernel_sizes, \n",
    "      \"strides\": self.strides, \n",
    "      \"in_channels\": self.in_channels, \n",
    "      \"num_filters\": self.num_filters,\n",
    "      \"pool_sizes\": self.pool_sizes, \n",
    "      \"pool_strides\": self.pool_strides,\n",
    "      \"dropout_p_conv\": self.dropout_p_conv,\n",
    "      \"dropout_p_linear\": self.dropout_p_linear,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_sizes =[ 2, 2,  2] #,  2]\n",
    "pool_sizes   =[ 2, 2,  2] #,  2]\n",
    "strides      =[ 2, 2,  1] #,  1]\n",
    "pool_strides =[ 2, 2,  1] #,  1]\n",
    "num_filters  =[ 1, 2,  4] #,  8]\n",
    "\n",
    "num_layers = len(kernel_sizes)\n",
    "\n",
    "in_channels   = 1 # we always use mono audio in both cases!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = CNN(\n",
    "  num_layers=num_layers,\n",
    "  kernel_sizes=kernel_sizes, \n",
    "  strides=strides, \n",
    "  in_channels=in_channels, \n",
    "  num_filters=num_filters,\n",
    "  pool_sizes=pool_sizes,\n",
    "  pool_strides=pool_strides,\n",
    "  dropout_p_conv=0.2,\n",
    "  dropout_p_linear=0.5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 4, 6, 114])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_cnn_input = torch.rand((16, 1, 128, 1860))\n",
    "# test_cnn_input = torch.rand((16, 1, 128, 5157))\n",
    "\n",
    "test_cnn_out = cnn(test_cnn_input)\n",
    "\n",
    "test_cnn_out.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4 (main, Apr  2 2022, 09:04:19) [GCC 11.2.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
