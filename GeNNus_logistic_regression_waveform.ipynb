{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> GeNNus\n",
    "### <center> Logistic Regression on Waveforms\n",
    "\n",
    "This is the code for the step 1, the one in which we experimented with Logistic Regression on Waveforms.\n",
    "\n",
    "See project report and presentation for deeper thoughts about this stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import tqdm\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot  as plt\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn import linear_model, decomposition, datasets\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import random \n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_SIZE = \"xs\"\n",
    "DATASET_TYPE = \"waveform\"\n",
    "\n",
    "DATASET_FOLDER = f\"./data/{DATASET_TYPE}\"\n",
    "\n",
    "DATASET_NUM_SAMPLES_PER_SECOND = 8000\n",
    "DATASET_NUM_CHANNELS = 1\n",
    "\n",
    "DATASET_NAME = f\"fma_{DATASET_SIZE}_resampled_{DATASET_NUM_SAMPLES_PER_SECOND}_rechanneled_{DATASET_NUM_CHANNELS}\"\n",
    "\n",
    "dataset_path = f\"{DATASET_FOLDER}/{DATASET_NAME}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_path_list = []\n",
    "\n",
    "for path, subdirs, files in os.walk(dataset_path):\n",
    "    for name in files:\n",
    "        file_audio_path = os.path.join(path, name)\n",
    "        print(file_audio_path)\n",
    "\n",
    "        if name != '.DS_Store':\n",
    "            audio_path_list.append(file_audio_path)\n",
    "\n",
    "audio_path_list = sorted(audio_path_list , reverse= True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_tensors = []\n",
    "labels = []\n",
    "for p in audio_path_list:\n",
    "    single_tensors.append(torch.load(p))\n",
    "    labels.append(p.split(\"/\")[-2])\n",
    "\n",
    "\n",
    "stacked_single_tensors = torch.cat(single_tensors).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(stacked_single_tensors)\n",
    "data.insert(0, \"Label\", labels, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split( dataset , perc_train , set_seed = 69):\n",
    "    train = dataset.sample(frac= perc_train,random_state = set_seed )\n",
    "    test  = dataset.drop(train.index)\n",
    "    return (train , test )\n",
    "#####   \n",
    "train_dataset , test_dataset = train_test_split( data , perc_train = .85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_dataset.iloc[: , 1:]      # ALL THE DATA POINTS\n",
    "y = train_dataset.iloc[: , :1]      # ALL THE LABELS\n",
    "\n",
    "std_slc = StandardScaler()          # STANDARDIZE\n",
    "\n",
    "pca = decomposition.PCA()           # PCA\n",
    "\n",
    "logistic_Reg = linear_model.LogisticRegression()    # LINEAR REGRESSION\n",
    "\n",
    "### \n",
    "pipe = Pipeline(steps=[('std_slc', std_slc),\n",
    "                ('pca', pca),\n",
    "                ('logistic_Reg', logistic_Reg)])\n",
    "\n",
    "\n",
    "n_components = list(range( int(.01 * X.shape[0]) ,  int(.25 * X.shape[0]) , 1))    # NUMBER OF PCA WE TEST\n",
    "# WE TRIED DIFFERENTS COMBINATIONS AND WE ENDED UP DISCOVERING THAT FEW PRINCIPAL COMPONENTS WERE ENOUGH\n",
    "# WE NOW TEST ONLY ON THE FIRST 25% OF THE POSSIBLE NUMBER OF PC's.\n",
    "\n",
    "C = [2., 20.]      # NUMBER OF C VALUE WE TEST\n",
    "\n",
    "penalty = ['l1', 'l2']    # PENALTY WE TEST\n",
    "\n",
    "# COMBINE ALL IN A DICTIONARY\n",
    "parameters = dict(pca__n_components=n_components,\n",
    "                    logistic_Reg__C=C,\n",
    "                    logistic_Reg__penalty=penalty)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### RUN THE KFOLD CROSS VALIDATION TO DISCOVER THE BEST HYPERPARAMETERS\n",
    "clf = GridSearchCV(pipe, parameters, n_jobs=2, verbose=3, cv=3)\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Best Penalty:', clf.best_estimator_.get_params()['logistic_Reg__penalty'])\n",
    "print('Best C:', clf.best_estimator_.get_params()['logistic_Reg__C'])\n",
    "print('Best Number Of Components:', clf.best_estimator_.get_params()['pca__n_components'])\n",
    "print(); print(clf.best_estimator_.get_params()['logistic_Reg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WE DON'T KNOW WHY IS HERE\n",
    "#CV_result = cross_val_score(clf , X , y , cv = 3 , n_jobs=2, verbose=3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the Logistcics regression with the best hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_dataset.iloc[: , 1:]      # ALL THE DATA POINTS for the training set \n",
    "y_train = train_dataset.iloc[: , :1]      # ALL THE LABELSfor the training set \n",
    "\n",
    "X_test =  test_dataset.iloc[: , 1:]       # ALL THE DATA POINTS for the test set \n",
    "y_test =  test_dataset.iloc[: , :1]       # ALL THE LABELS for the test set\n",
    "\n",
    "# [TODO]  do not arcoding but with the best hyperparameter\n",
    "\n",
    "pca = PCA(n_components= 11)               # PCA with the best number of components\n",
    "X_train_pca =  pd.DataFrame(pca.fit_transform(X_train))   # Transform the train dataset in pc\n",
    "X_test_pca  =  pd.DataFrame(pca.fit_transform(X_test ))   # Transform the test  dataset in pc\n",
    "\n",
    "### RUN THE LOGISTIC REGRESSION\n",
    "\n",
    "logistic = LogisticRegression(penalty= 'l2'  , C = 2)\n",
    "logistic.fit( X_train_pca  , y_train )\n",
    "\n",
    "### TEST THE MODEL\n",
    "LogisticPredictions = logistic.predict( X_test_pca )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Logistic_Accuracy = logistic.score(  X_test_pca , y_test ) \n",
    "Logistic_Accuracy =\"{: .0%}\".format(Logistic_Accuracy)\n",
    "print(f\"The accuracy of the logistic model is:{Logistic_Accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### CONFUSION MATRIX\n",
    "confusion = metrics.confusion_matrix( y_test , LogisticPredictions)\n",
    "plt.figure(figsize=(12,10))\n",
    "sns.heatmap(confusion , annot= True , fmt = 'd' , cmap= \"viridis\")\n",
    "plt.xlabel(\"Recognized Genres\")\n",
    "plt.ylabel(\"Actual Genre\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    " \n",
    "print('Shape before PCA: ', X.shape)\n",
    "print('Shape after PCA: ', pca_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (12,8)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "xi = np.arange(1, 61, step=1)\n",
    "y = np.cumsum(pca.explained_variance_ratio_)\n",
    "\n",
    "plt.ylim(0.0,1.1)\n",
    "plt.plot(xi, y, marker='o', linestyle='-', color='red')\n",
    "\n",
    "plt.xlabel('Number of Components')\n",
    "plt.xticks(np.arange(1, 61, step=1), rotation = 90) \n",
    "plt.ylabel('Cumulative variance (%)')\n",
    "plt.title('The number of components needed to explain variance')\n",
    "\n",
    "plt.axhline(y=0.7, color='darkgreen', linestyle='--')\n",
    "plt.text(1.1, 1, '70% cut-off threshold', color = 'darkgreen', fontsize=16)\n",
    "\n",
    "ax.grid()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset.iloc[: , 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components= 7  )\n",
    "dataset_pca = pca.fit_transform(train_dataset.iloc[: , 1:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = train_dataset.iloc[ : , :1 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_train =[]\n",
    "for x in label.values:\n",
    "    labels_train.append(_label_from_str_to_one_hot(x[0]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_pca = pd.DataFrame(dataset_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_test = PCA(n_components= 52 )\n",
    "test_dataset_pca = pca.fit_transform(test_dataset.iloc[: , 1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab_test = pd.get_dummies(test_dataset.iloc[ : , :1 ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic.predict(test_dataset_pca)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _label_from_str_to_one_hot(label_str: str): \n",
    "\n",
    "    if label_str == \"Pop\":\n",
    "        return [1, 0, 0, 0, 0, 0]\n",
    "    \n",
    "    if label_str == \"Hip-Hop\":\n",
    "        return [0, 1, 0, 0, 0, 0]\n",
    "    \n",
    "    if label_str == \"Electronic\":\n",
    "        return [0, 0, 1, 0, 0, 0]\n",
    "    \n",
    "    if label_str == \"Rock\":\n",
    "        return [0, 0, 0, 1, 0, 0]\n",
    "\n",
    "    if label_str == \"Folk\":\n",
    "        return [0, 0, 0, 0, 1, 0]\n",
    "\n",
    "    if label_str == \"Jazz\":\n",
    "        return [0, 0, 0, 0, 0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "LogisticPredictions = logistic.predict( test_dataset_pca )\n",
    "results = []\n",
    "for x in LogisticPredictions:\n",
    "    results.append(_label_from_str_to_one_hot(x))\n",
    "\n",
    "lab_test = []\n",
    "for x in label_test.values:\n",
    "    lab_test.append(_label_from_str_to_one_hot(x[0]))\n",
    "\n",
    "\n",
    "Logistic_Accuracy = logistic.score(  results , lab_test ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LogisticPredictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab_test = []\n",
    "for x in label_test.values:\n",
    "    lab_test.append(x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Logistic_Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix( Y_test , LogisticPredictions , labels = None, sample_weight=None, normalize=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "key_fold = KFold( n_splits=4 ) \n",
    "key_fold.get_n_splits(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(stacked_single_tensors)\n",
    "X = df.iloc[:,:-1]\n",
    "y = labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing required libraries\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import preprocessing\n",
    "from sklearn import utils\n",
    "from tqdm import tqdm\n",
    "set.seed(69)\n",
    "\n",
    "\n",
    "X = df.iloc[:,:-1]\n",
    "\n",
    "#convert y values to categorical values\n",
    "\n",
    "y = pd.DataFrame(labels)\n",
    "\n",
    "#Implementing cross validation\n",
    "\n",
    "k = 3\n",
    "kf = KFold(n_splits=k, random_state= None , shuffle= True )\n",
    "model = LogisticRegression()\n",
    "\n",
    "acc_score = []\n",
    "\n",
    "for train_index , test_index in tqdm( kf.split(X) ):\n",
    "\n",
    "    X_train , X_test = X.iloc[train_index,:],X.iloc[test_index,:]\n",
    "    y_train , y_test = y.iloc[train_index] , y.iloc[test_index]\n",
    "\n",
    "\n",
    "    model.fit(X_train,y_train)\n",
    "    pred_values = model.predict(X_test)\n",
    "\n",
    "    acc = accuracy_score( pred_values , y_test)\n",
    "    acc_score.append(acc)\n",
    "\n",
    "avg_acc_score = sum(acc_score)/k\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4 (main, Apr  2 2022, 09:04:19) [GCC 11.2.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
